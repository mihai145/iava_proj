{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4afc5434-f737-4e04-a4c2-72200051d9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StarGAN imports\n",
    "from data_loader import get_loader\n",
    "from solver import Solver\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3811a88-7792-4697-bbd0-40ad2ce4eaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "def get_default_config():\n",
    "    config = Config()\n",
    "    \n",
    "    # Model configuration.\n",
    "    config.c_dim = 5\n",
    "    config.c2_dim = 8\n",
    "    config.celeba_crop_size = 178\n",
    "    config.rafd_crop_size = 256\n",
    "    config.image_size = 128\n",
    "    config.g_conv_dim = 64\n",
    "    config.d_conv_dim = 64\n",
    "    config.g_repeat_num = 6\n",
    "    config.d_repeat_num = 6\n",
    "    config.lambda_cls = 1\n",
    "    config.lambda_rec = 10\n",
    "    config.lambda_gp = 10\n",
    "    \n",
    "    # Training configuration.\n",
    "    config.dataset = \"CelebA\"\n",
    "    config.batch_size = 4\n",
    "    config.num_iters = 200000\n",
    "    config.num_iters_decay = 100000\n",
    "    config.g_lr = 0.0001\n",
    "    config.d_lr = 0.0001\n",
    "    config.n_critic = 5\n",
    "    config.beta1 = 0.5\n",
    "    config.beta2 = 0.999\n",
    "    config.resume_iters = None\n",
    "    config.selected_attrs= ['Black_Hair', 'Blond_Hair', 'Brown_Hair', 'Male', 'Young']\n",
    "\n",
    "    # Test configuration.\n",
    "    config.test_iters = 200000\n",
    "\n",
    "    # Miscellaneous.\n",
    "    config.num_workers = 1\n",
    "    config.mode = \"test\"\n",
    "    config.use_tensorboard = False\n",
    "\n",
    "    # Directories.\n",
    "    config.celeba_image_dir = 'data/celeba/images'\n",
    "    config.attr_path = 'data/celeba/list_attr_celeba.txt'\n",
    "    config.rafd_image_dir = 'data/RaFD/train'\n",
    "    config.log_dir = 'stargan/logs'\n",
    "    config.model_save_dir = 'stargan_celeba_128/models'\n",
    "    config.sample_dir = 'stargan/samples'\n",
    "    config.result_dir = 'stargan_celeba_128/results'\n",
    "    \n",
    "    # Step size.\n",
    "    config.log_step = 10\n",
    "    config.sample_step = 1000\n",
    "    config.model_save_step = 10000\n",
    "    config.lr_update_step = 1000\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9ad5d6-aef6-4336-af8b-a0a6f4fe3fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_default_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d4aa1a-7cd1-4f09-8636-80e9ede050e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_solver(config):\n",
    "    celeba_loader = None\n",
    "    rafd_loader = None\n",
    "\n",
    "    if config.dataset in ['CelebA', 'Both']:\n",
    "        celeba_loader = get_loader(config.celeba_image_dir, config.attr_path, config.selected_attrs,\n",
    "                                   config.celeba_crop_size, config.image_size, config.batch_size,\n",
    "                                   'CelebA', config.mode, config.num_workers)\n",
    "    if config.dataset in ['RaFD', 'Both']:\n",
    "        rafd_loader = get_loader(config.rafd_image_dir, None, None,\n",
    "                                 config.rafd_crop_size, config.image_size, config.batch_size,\n",
    "                                 'RaFD', config.mode, config.num_workers)\n",
    "    \n",
    "    solver = Solver(celeba_loader, rafd_loader, config)\n",
    "    return solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "143d5a83-d974-40ab-b884-27c61450ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing the CelebA dataset...\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(8, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (22): Tanh()\n",
      "  )\n",
      ")\n",
      "G\n",
      "The number of parameters: 8430528\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (11): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(2048, 5, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      ")\n",
      "D\n",
      "The number of parameters: 44762048\n"
     ]
    }
   ],
   "source": [
    "solver = get_default_solver(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "477d999d-0657-4d4a-812e-6730a5cce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(solver, test_data_loader):\n",
    "    # Create results dir if not exists.\n",
    "    if not os.path.exists(solver.result_dir):\n",
    "        os.makedirs(solver.result_dir) \n",
    "    \n",
    "    # Load the trained generator.\n",
    "    solver.restore_model(solver.test_iters)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x_real, c_org) in enumerate(test_data_loader):\n",
    "\n",
    "            # Prepare input images and target domain labels.\n",
    "            x_real = x_real.to(solver.device)\n",
    "            c_trg_list = solver.create_labels(c_org, solver.c_dim, solver.dataset, solver.selected_attrs)\n",
    "\n",
    "            # Translate images.\n",
    "            x_fake_list = [x_real]\n",
    "            for c_trg in c_trg_list:\n",
    "                x_fake_list.append(solver.G(x_real, c_trg))\n",
    "\n",
    "            # Save the translated images.\n",
    "            x_concat = torch.cat(x_fake_list, dim=3)\n",
    "            result_path = os.path.join(solver.result_dir, '{}-images.jpg'.format(i+1))\n",
    "            save_image(solver.denorm(x_concat.data.cpu()), result_path, nrow=1, padding=0)\n",
    "            print('Saved real and fake images into {}...'.format(result_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b328bdfc-fdb5-469a-8e09-34e8df03ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing the CelebA dataset...\n"
     ]
    }
   ],
   "source": [
    "test_data_loader = get_loader(config.celeba_image_dir, config.attr_path, config.selected_attrs,\n",
    "                           config.celeba_crop_size, config.image_size, config.batch_size,\n",
    "                           'CelebASmall', config.mode, config.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5b73e7a-8cf5-49b8-bec3-0a348d2c8b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 128, 128])\n",
      "torch.Size([4, 5])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(test_data_loader))\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2697d703-5853-4d9c-af91-bee68cbebd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 200000...\n",
      "Saved real and fake images into stargan_celeba_128/results/1-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/2-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/3-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/4-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/5-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/6-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/7-images.jpg...\n",
      "Saved real and fake images into stargan_celeba_128/results/8-images.jpg...\n"
     ]
    }
   ],
   "source": [
    "test(solver, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4de0dcb-84f8-4c5b-9551-0748f3d6e919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f33e321-c076-43e1-967d-83d678e5c09c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1453d57c-d875-41c4-b213-ef3744ee409f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
