{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561},{"sourceId":8118479,"sourceType":"datasetVersion","datasetId":4796403},{"sourceId":8134901,"sourceType":"datasetVersion","datasetId":4800689},{"sourceId":8134967,"sourceType":"datasetVersion","datasetId":4808774}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\n# path-ul catre dataset-ul cu cod\nsys.path.insert(1, '/kaggle/input/pycode')","metadata":{"id":"x2pSeUdSvGP5","execution":{"iopub.status.busy":"2024-04-16T10:43:14.493984Z","iopub.execute_input":"2024-04-16T10:43:14.494606Z","iopub.status.idle":"2024-04-16T10:43:14.505792Z","shell.execute_reply.started":"2024-04-16T10:43:14.494574Z","shell.execute_reply":"2024-04-16T10:43:14.504792Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from generic_dataset import GenericDataset, VisualizationDataset, get_loader\nfrom generic_dataset import CELEBA_FORMAT_DATASET, RAFD_FORMAT_DATASET\nfrom custom_solver import CustomSolver","metadata":{"id":"MKzQjY89vGP5","execution":{"iopub.status.busy":"2024-04-16T10:43:17.061078Z","iopub.execute_input":"2024-04-16T10:43:17.061794Z","iopub.status.idle":"2024-04-16T10:43:23.127671Z","shell.execute_reply.started":"2024-04-16T10:43:17.061762Z","shell.execute_reply":"2024-04-16T10:43:23.126834Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\nceleba_dir =  Path(\"/kaggle/input/celeba-dataset\")\ncomic_dir = Path(\"/kaggle/input/comics-faces/comic-faces\")\nvisualization_dir = Path(\"/kaggle/input/visualization\")","metadata":{"id":"v0vgrPi7vGP5","execution":{"iopub.status.busy":"2024-04-16T10:43:50.685792Z","iopub.execute_input":"2024-04-16T10:43:50.686127Z","iopub.status.idle":"2024-04-16T10:43:50.690703Z","shell.execute_reply.started":"2024-04-16T10:43:50.686103Z","shell.execute_reply":"2024-04-16T10:43:50.689758Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Celeba dataset 1\nceleba_selected_attrs1 = [\"Male\", \"Young\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\"]\nceleba1 = GenericDataset(str(celeba_dir), CELEBA_FORMAT_DATASET, celeba_selected_attrs1, \"train\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0fK1VGDE48m","outputId":"e848b1aa-2cab-4a1d-abca-78b7b98c1775","execution":{"iopub.status.busy":"2024-04-16T10:43:25.139545Z","iopub.execute_input":"2024-04-16T10:43:25.139895Z","iopub.status.idle":"2024-04-16T10:43:27.354285Z","shell.execute_reply.started":"2024-04-16T10:43:25.139868Z","shell.execute_reply":"2024-04-16T10:43:27.353359Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Finished preprocessing CelebA-format dataset at /kaggle/input/celeba-dataset: 198548 train images, 4051 test images\n","output_type":"stream"}]},{"cell_type":"code","source":"# Celeba dataset 2\nceleba_selected_attrs2 = [\"Smiling\", \"Arched_Eyebrows\", \"Bangs\"]\nceleba2 = GenericDataset(str(celeba_dir), CELEBA_FORMAT_DATASET, celeba_selected_attrs2, \"train\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:43:30.822914Z","iopub.execute_input":"2024-04-16T10:43:30.823282Z","iopub.status.idle":"2024-04-16T10:43:32.506197Z","shell.execute_reply.started":"2024-04-16T10:43:30.823251Z","shell.execute_reply":"2024-04-16T10:43:32.505179Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Finished preprocessing CelebA-format dataset at /kaggle/input/celeba-dataset: 198548 train images, 4051 test images\n","output_type":"stream"}]},{"cell_type":"code","source":"# Comics dataset\ncomics_selected_attrs = [\"faces\", \"comics\"]\ncomics = GenericDataset(str(comic_dir), RAFD_FORMAT_DATASET, comics_selected_attrs, \"train\")","metadata":{"execution":{"iopub.status.busy":"2024-04-16T10:43:35.411786Z","iopub.execute_input":"2024-04-16T10:43:35.412533Z","iopub.status.idle":"2024-04-16T10:43:35.808595Z","shell.execute_reply.started":"2024-04-16T10:43:35.412503Z","shell.execute_reply":"2024-04-16T10:43:35.807615Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Finished preprocessing RAFD-format dataset at /kaggle/input/comics-faces/comic-faces: 20000 train images, 2 test images\n","output_type":"stream"}]},{"cell_type":"code","source":"# Visualization dataset\nvis_dataset = VisualizationDataset(visualization_dir)\nprint(len(vis_dataset))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1Ikqx-3FX-u","outputId":"90d5be80-a32d-4f9a-b9d8-b3936b93024d","execution":{"iopub.status.busy":"2024-04-16T10:43:54.276107Z","iopub.execute_input":"2024-04-16T10:43:54.276471Z","iopub.status.idle":"2024-04-16T10:43:54.295738Z","shell.execute_reply.started":"2024-04-16T10:43:54.276442Z","shell.execute_reply":"2024-04-16T10:43:54.294910Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"42\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nexperiments_path = \"/kaggle/working/exps/\"\nos.makedirs(experiments_path)","metadata":{"id":"bJanJkZkFP8S","execution":{"iopub.status.busy":"2024-04-16T10:43:57.564260Z","iopub.execute_input":"2024-04-16T10:43:57.564639Z","iopub.status.idle":"2024-04-16T10:43:57.569515Z","shell.execute_reply.started":"2024-04-16T10:43:57.564609Z","shell.execute_reply":"2024-04-16T10:43:57.568284Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"settings = {\n    \"num_iters\": 30000,\n    \"num_iters_decay\": 20000,\n    \"batch_size\": 64,\n    \"lr_update_step\": 10,\n    \"n_critic\": 5,\n    \"log_step\": 100,\n    \"vis_step\": 2000,\n    \"model_save_step\": 2000,\n}","metadata":{"id":"_yq6MAcC7jyI","execution":{"iopub.status.busy":"2024-04-16T10:44:00.116763Z","iopub.execute_input":"2024-04-16T10:44:00.117367Z","iopub.status.idle":"2024-04-16T10:44:00.122096Z","shell.execute_reply.started":"2024-04-16T10:44:00.117328Z","shell.execute_reply":"2024-04-16T10:44:00.121113Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"solver = CustomSolver([celeba1, celeba2, comics], vis_dataset, Path(experiments_path), **settings)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xKOVZZCPEjoJ","outputId":"e2ce18eb-f32e-4740-9bbb-3ca217e61d10","execution":{"iopub.status.busy":"2024-04-16T10:44:03.036034Z","iopub.execute_input":"2024-04-16T10:44:03.036707Z","iopub.status.idle":"2024-04-16T10:44:03.826074Z","shell.execute_reply.started":"2024-04-16T10:44:03.036678Z","shell.execute_reply":"2024-04-16T10:44:03.825192Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"sum_label_size: 10, mask_vector_size: 3\nZero padding left: [0, 5, 8]\nZero padding right: [5, 2, 0]\nWorkdir set at /kaggle/working/exps\nGenerator(\n  (main): Sequential(\n    (0): Conv2d(16, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n    (9): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (10): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (11): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (12): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (13): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (14): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n    (22): Tanh()\n  )\n)\nG\nThe number of parameters: 8455616\nDiscriminator(\n  (main): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.01)\n    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): LeakyReLU(negative_slope=0.01)\n    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (9): LeakyReLU(negative_slope=0.01)\n    (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (11): LeakyReLU(negative_slope=0.01)\n  )\n  (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (conv2): Conv2d(2048, 10, kernel_size=(2, 2), stride=(1, 1), bias=False)\n)\nD\nThe number of parameters: 44803008\n","output_type":"stream"}]},{"cell_type":"code","source":"# 16 apr 2024 13:45\nsolver.train_multi()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"flHvGVaNEjld","outputId":"da4a491f-d168-47ee-dec5-ad53fe0602e7","execution":{"iopub.status.busy":"2024-04-16T10:44:33.443972Z","iopub.execute_input":"2024-04-16T10:44:33.444712Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Start training...\nElapsed [0:03:08], Iteration [100/30000], Dataset [1], D/loss_real: -5.3854, D/loss_fake: -5.1942, D/loss_cls: 4.1805, D/loss_gp: 0.0636, G/loss_fake: -9.5204, G/loss_rec: 0.4125, G/loss_cls: 3.0236\nElapsed [0:03:09], Iteration [100/30000], Dataset [2], D/loss_real: -22.5184, D/loss_fake: 14.5342, D/loss_cls: 1.8826, D/loss_gp: 0.3956, G/loss_fake: 1.9088, G/loss_rec: 0.3575, G/loss_cls: 2.3508\nElapsed [0:03:10], Iteration [100/30000], Dataset [3], D/loss_real: -3.8156, D/loss_fake: 0.8412, D/loss_cls: 0.1890, D/loss_gp: 0.0173, G/loss_fake: 11.2157, G/loss_rec: 0.3443, G/loss_cls: 1.8343\nElapsed [0:06:17], Iteration [200/30000], Dataset [1], D/loss_real: -14.7957, D/loss_fake: 6.4571, D/loss_cls: 2.9694, D/loss_gp: 0.1524, G/loss_fake: -4.8838, G/loss_rec: 0.2882, G/loss_cls: 3.2105\nElapsed [0:06:18], Iteration [200/30000], Dataset [2], D/loss_real: -16.9056, D/loss_fake: 8.5775, D/loss_cls: 3.7718, D/loss_gp: 0.1396, G/loss_fake: -4.1345, G/loss_rec: 0.2976, G/loss_cls: 1.9263\nElapsed [0:06:19], Iteration [200/30000], Dataset [3], D/loss_real: -9.6362, D/loss_fake: 5.0644, D/loss_cls: 0.1462, D/loss_gp: 0.0950, G/loss_fake: -8.1136, G/loss_rec: 0.2356, G/loss_cls: 2.2628\nElapsed [0:09:26], Iteration [300/30000], Dataset [1], D/loss_real: -4.7291, D/loss_fake: -4.3580, D/loss_cls: 2.6379, D/loss_gp: 0.0819, G/loss_fake: 4.5871, G/loss_rec: 0.2969, G/loss_cls: 3.0289\nElapsed [0:09:27], Iteration [300/30000], Dataset [2], D/loss_real: -5.8624, D/loss_fake: -2.9919, D/loss_cls: 1.6711, D/loss_gp: 0.1671, G/loss_fake: 2.4875, G/loss_rec: 0.2808, G/loss_cls: 2.2273\nElapsed [0:09:29], Iteration [300/30000], Dataset [3], D/loss_real: -1.7008, D/loss_fake: -0.2648, D/loss_cls: 0.1270, D/loss_gp: 0.1171, G/loss_fake: -6.6409, G/loss_rec: 0.2348, G/loss_cls: 2.1063\nElapsed [0:12:35], Iteration [400/30000], Dataset [1], D/loss_real: -7.5630, D/loss_fake: -4.9065, D/loss_cls: 2.8859, D/loss_gp: 0.2536, G/loss_fake: 1.9829, G/loss_rec: 0.2723, G/loss_cls: 3.9628\nElapsed [0:12:36], Iteration [400/30000], Dataset [2], D/loss_real: -11.4085, D/loss_fake: 2.8972, D/loss_cls: 2.0187, D/loss_gp: 0.1952, G/loss_fake: 0.5895, G/loss_rec: 0.2593, G/loss_cls: 2.6659\nElapsed [0:12:38], Iteration [400/30000], Dataset [3], D/loss_real: 3.6917, D/loss_fake: -2.1256, D/loss_cls: 0.1630, D/loss_gp: 0.0578, G/loss_fake: 5.6276, G/loss_rec: 0.2036, G/loss_cls: 2.0441\nElapsed [0:15:44], Iteration [500/30000], Dataset [1], D/loss_real: -28.8058, D/loss_fake: 15.7729, D/loss_cls: 5.0637, D/loss_gp: 0.1955, G/loss_fake: -1.4314, G/loss_rec: 0.3123, G/loss_cls: 4.1657\nElapsed [0:15:46], Iteration [500/30000], Dataset [2], D/loss_real: -13.7289, D/loss_fake: 6.8907, D/loss_cls: 1.3083, D/loss_gp: 0.2161, G/loss_fake: 0.5846, G/loss_rec: 0.2496, G/loss_cls: 1.6391\nElapsed [0:15:47], Iteration [500/30000], Dataset [3], D/loss_real: -1.0221, D/loss_fake: 0.9054, D/loss_cls: 0.0753, D/loss_gp: 0.0650, G/loss_fake: -2.4387, G/loss_rec: 0.1916, G/loss_cls: 1.6686\nElapsed [0:18:53], Iteration [600/30000], Dataset [1], D/loss_real: -16.6928, D/loss_fake: 4.9907, D/loss_cls: 2.3115, D/loss_gp: 0.1311, G/loss_fake: -1.9024, G/loss_rec: 0.3124, G/loss_cls: 3.7077\nElapsed [0:18:55], Iteration [600/30000], Dataset [2], D/loss_real: -13.8915, D/loss_fake: 11.5536, D/loss_cls: 1.8948, D/loss_gp: 0.1963, G/loss_fake: 2.8493, G/loss_rec: 0.2550, G/loss_cls: 2.3894\nElapsed [0:18:56], Iteration [600/30000], Dataset [3], D/loss_real: 9.1978, D/loss_fake: -3.7237, D/loss_cls: 0.2401, D/loss_gp: 0.0065, G/loss_fake: 13.9322, G/loss_rec: 0.2395, G/loss_cls: 1.2352\nElapsed [0:22:02], Iteration [700/30000], Dataset [1], D/loss_real: -9.8589, D/loss_fake: 4.5546, D/loss_cls: 2.3334, D/loss_gp: 0.0839, G/loss_fake: -8.3990, G/loss_rec: 0.2508, G/loss_cls: 3.5710\nElapsed [0:22:04], Iteration [700/30000], Dataset [2], D/loss_real: -13.3334, D/loss_fake: 7.8788, D/loss_cls: 1.0803, D/loss_gp: 0.0599, G/loss_fake: -8.2796, G/loss_rec: 0.2478, G/loss_cls: 1.9040\nElapsed [0:22:05], Iteration [700/30000], Dataset [3], D/loss_real: -11.1934, D/loss_fake: 8.2945, D/loss_cls: 0.0462, D/loss_gp: 0.0572, G/loss_fake: -5.5668, G/loss_rec: 0.1875, G/loss_cls: 1.4859\nElapsed [0:25:12], Iteration [800/30000], Dataset [1], D/loss_real: -4.9731, D/loss_fake: -1.2980, D/loss_cls: 1.9926, D/loss_gp: 0.0581, G/loss_fake: -0.6880, G/loss_rec: 0.2456, G/loss_cls: 3.7544\nElapsed [0:25:13], Iteration [800/30000], Dataset [2], D/loss_real: -9.1575, D/loss_fake: 4.0808, D/loss_cls: 0.9576, D/loss_gp: 0.0643, G/loss_fake: -8.4443, G/loss_rec: 0.2449, G/loss_cls: 2.1829\nElapsed [0:25:14], Iteration [800/30000], Dataset [3], D/loss_real: -2.9634, D/loss_fake: -0.9172, D/loss_cls: 0.0232, D/loss_gp: 0.0397, G/loss_fake: -2.5608, G/loss_rec: 0.2005, G/loss_cls: 0.5651\nElapsed [0:28:21], Iteration [900/30000], Dataset [1], D/loss_real: -11.2425, D/loss_fake: 6.0609, D/loss_cls: 2.2829, D/loss_gp: 0.0527, G/loss_fake: -3.7528, G/loss_rec: 0.2613, G/loss_cls: 3.7310\nElapsed [0:28:22], Iteration [900/30000], Dataset [2], D/loss_real: -7.8826, D/loss_fake: 4.5294, D/loss_cls: 1.5521, D/loss_gp: 0.0620, G/loss_fake: -4.6659, G/loss_rec: 0.2466, G/loss_cls: 2.1711\nElapsed [0:28:23], Iteration [900/30000], Dataset [3], D/loss_real: -1.2709, D/loss_fake: 1.4684, D/loss_cls: 0.0151, D/loss_gp: 0.0228, G/loss_fake: 2.0997, G/loss_rec: 0.1790, G/loss_cls: 0.6341\nElapsed [0:31:30], Iteration [1000/30000], Dataset [1], D/loss_real: -4.3150, D/loss_fake: -2.2981, D/loss_cls: 1.6833, D/loss_gp: 0.0447, G/loss_fake: 4.5486, G/loss_rec: 0.2695, G/loss_cls: 4.0527\nElapsed [0:31:31], Iteration [1000/30000], Dataset [2], D/loss_real: -4.6690, D/loss_fake: -0.0274, D/loss_cls: 1.2079, D/loss_gp: 0.0737, G/loss_fake: 0.9517, G/loss_rec: 0.2413, G/loss_cls: 2.8488\nElapsed [0:31:33], Iteration [1000/30000], Dataset [3], D/loss_real: -6.6954, D/loss_fake: 6.6024, D/loss_cls: 0.0283, D/loss_gp: 0.0348, G/loss_fake: -7.7388, G/loss_rec: 0.1879, G/loss_cls: 0.2286\nElapsed [0:34:39], Iteration [1100/30000], Dataset [1], D/loss_real: -8.3564, D/loss_fake: 0.3930, D/loss_cls: 2.5888, D/loss_gp: 0.0809, G/loss_fake: -1.0929, G/loss_rec: 0.2666, G/loss_cls: 4.3181\nElapsed [0:34:40], Iteration [1100/30000], Dataset [2], D/loss_real: -12.0424, D/loss_fake: 5.2558, D/loss_cls: 1.3020, D/loss_gp: 0.1200, G/loss_fake: -3.5675, G/loss_rec: 0.2484, G/loss_cls: 2.8944\nElapsed [0:34:42], Iteration [1100/30000], Dataset [3], D/loss_real: 0.0306, D/loss_fake: -1.3509, D/loss_cls: 0.0565, D/loss_gp: 0.0385, G/loss_fake: 3.4858, G/loss_rec: 0.1826, G/loss_cls: 0.4966\nElapsed [0:37:48], Iteration [1200/30000], Dataset [1], D/loss_real: -7.4601, D/loss_fake: 2.2770, D/loss_cls: 1.5960, D/loss_gp: 0.0528, G/loss_fake: -3.8893, G/loss_rec: 0.2363, G/loss_cls: 3.4732\nElapsed [0:37:49], Iteration [1200/30000], Dataset [2], D/loss_real: -9.9268, D/loss_fake: 5.9090, D/loss_cls: 1.1751, D/loss_gp: 0.0393, G/loss_fake: -5.3457, G/loss_rec: 0.2413, G/loss_cls: 2.8818\nElapsed [0:37:51], Iteration [1200/30000], Dataset [3], D/loss_real: -8.1844, D/loss_fake: 6.4970, D/loss_cls: 0.0320, D/loss_gp: 0.0449, G/loss_fake: -2.2154, G/loss_rec: 0.1690, G/loss_cls: 0.0580\nElapsed [0:40:57], Iteration [1300/30000], Dataset [1], D/loss_real: -13.2860, D/loss_fake: 5.7043, D/loss_cls: 2.5823, D/loss_gp: 0.0623, G/loss_fake: -3.9343, G/loss_rec: 0.2659, G/loss_cls: 3.3313\nElapsed [0:40:58], Iteration [1300/30000], Dataset [2], D/loss_real: -12.3628, D/loss_fake: 8.0607, D/loss_cls: 1.0503, D/loss_gp: 0.0723, G/loss_fake: -4.7219, G/loss_rec: 0.2325, G/loss_cls: 2.3384\nElapsed [0:41:00], Iteration [1300/30000], Dataset [3], D/loss_real: -12.9709, D/loss_fake: 11.8565, D/loss_cls: 0.1017, D/loss_gp: 0.0293, G/loss_fake: -8.1041, G/loss_rec: 0.1711, G/loss_cls: 0.3341\nElapsed [0:44:06], Iteration [1400/30000], Dataset [1], D/loss_real: -16.6916, D/loss_fake: 7.5952, D/loss_cls: 2.0127, D/loss_gp: 0.1068, G/loss_fake: -1.5773, G/loss_rec: 0.2730, G/loss_cls: 3.0141\nElapsed [0:44:07], Iteration [1400/30000], Dataset [2], D/loss_real: -9.9870, D/loss_fake: 3.3215, D/loss_cls: 1.4277, D/loss_gp: 0.0919, G/loss_fake: -5.5271, G/loss_rec: 0.2593, G/loss_cls: 2.6022\nElapsed [0:44:08], Iteration [1400/30000], Dataset [3], D/loss_real: -23.7910, D/loss_fake: 20.1660, D/loss_cls: 0.0023, D/loss_gp: 0.1246, G/loss_fake: -13.9811, G/loss_rec: 0.1628, G/loss_cls: 0.0844\nElapsed [0:47:15], Iteration [1500/30000], Dataset [1], D/loss_real: -14.7380, D/loss_fake: 6.5840, D/loss_cls: 2.8676, D/loss_gp: 0.0680, G/loss_fake: -7.4657, G/loss_rec: 0.2631, G/loss_cls: 3.2692\nElapsed [0:47:16], Iteration [1500/30000], Dataset [2], D/loss_real: -18.6230, D/loss_fake: 13.1154, D/loss_cls: 0.9283, D/loss_gp: 0.1148, G/loss_fake: -11.9975, G/loss_rec: 0.2358, G/loss_cls: 2.2982\nElapsed [0:47:17], Iteration [1500/30000], Dataset [3], D/loss_real: -26.0380, D/loss_fake: 23.9613, D/loss_cls: 0.0496, D/loss_gp: 0.0625, G/loss_fake: -18.8821, G/loss_rec: 0.1531, G/loss_cls: 0.1105\nElapsed [0:50:23], Iteration [1600/30000], Dataset [1], D/loss_real: -5.5813, D/loss_fake: -0.4009, D/loss_cls: 1.6615, D/loss_gp: 0.0489, G/loss_fake: -0.9284, G/loss_rec: 0.2390, G/loss_cls: 2.6548\nElapsed [0:50:25], Iteration [1600/30000], Dataset [2], D/loss_real: -5.5993, D/loss_fake: 0.6474, D/loss_cls: 1.1283, D/loss_gp: 0.0617, G/loss_fake: 4.5354, G/loss_rec: 0.2206, G/loss_cls: 2.0432\nElapsed [0:50:26], Iteration [1600/30000], Dataset [3], D/loss_real: -8.3541, D/loss_fake: 3.9900, D/loss_cls: 0.0037, D/loss_gp: 0.0487, G/loss_fake: -5.4496, G/loss_rec: 0.1472, G/loss_cls: 0.4019\nElapsed [0:53:32], Iteration [1700/30000], Dataset [1], D/loss_real: -7.9119, D/loss_fake: 1.8777, D/loss_cls: 1.4855, D/loss_gp: 0.1145, G/loss_fake: -1.7090, G/loss_rec: 0.2270, G/loss_cls: 2.7720\nElapsed [0:53:34], Iteration [1700/30000], Dataset [2], D/loss_real: -8.6087, D/loss_fake: 4.5244, D/loss_cls: 1.1750, D/loss_gp: 0.0429, G/loss_fake: -6.5699, G/loss_rec: 0.2212, G/loss_cls: 2.1554\nElapsed [0:53:35], Iteration [1700/30000], Dataset [3], D/loss_real: -8.7763, D/loss_fake: 7.5066, D/loss_cls: 0.0102, D/loss_gp: 0.0227, G/loss_fake: -8.4723, G/loss_rec: 0.1555, G/loss_cls: 0.1407\nElapsed [0:56:41], Iteration [1800/30000], Dataset [1], D/loss_real: -12.8025, D/loss_fake: 7.2784, D/loss_cls: 1.7560, D/loss_gp: 0.0446, G/loss_fake: -10.0722, G/loss_rec: 0.2132, G/loss_cls: 2.5442\nElapsed [0:56:43], Iteration [1800/30000], Dataset [2], D/loss_real: -14.5147, D/loss_fake: 9.3105, D/loss_cls: 0.8369, D/loss_gp: 0.0553, G/loss_fake: -8.2093, G/loss_rec: 0.2192, G/loss_cls: 1.8361\nElapsed [0:56:44], Iteration [1800/30000], Dataset [3], D/loss_real: -15.5547, D/loss_fake: 12.3564, D/loss_cls: 0.0310, D/loss_gp: 0.0426, G/loss_fake: -10.2161, G/loss_rec: 0.1598, G/loss_cls: 0.3182\nElapsed [0:59:50], Iteration [1900/30000], Dataset [1], D/loss_real: -5.2323, D/loss_fake: -0.3544, D/loss_cls: 1.8460, D/loss_gp: 0.0702, G/loss_fake: -1.0182, G/loss_rec: 0.2411, G/loss_cls: 2.1794\nElapsed [0:59:52], Iteration [1900/30000], Dataset [2], D/loss_real: -10.4084, D/loss_fake: 5.1373, D/loss_cls: 1.1153, D/loss_gp: 0.0736, G/loss_fake: -5.8752, G/loss_rec: 0.2332, G/loss_cls: 1.6579\nElapsed [0:59:53], Iteration [1900/30000], Dataset [3], D/loss_real: -6.0524, D/loss_fake: 4.0011, D/loss_cls: 0.0221, D/loss_gp: 0.0094, G/loss_fake: -1.4499, G/loss_rec: 0.1578, G/loss_cls: 0.0769\nElapsed [1:02:59], Iteration [2000/30000], Dataset [1], D/loss_real: -21.5948, D/loss_fake: 12.0947, D/loss_cls: 1.9210, D/loss_gp: 0.1505, G/loss_fake: -12.6388, G/loss_rec: 0.2624, G/loss_cls: 2.7878\nElapsed [1:03:01], Iteration [2000/30000], Dataset [2], D/loss_real: -22.0306, D/loss_fake: 16.2546, D/loss_cls: 1.2314, D/loss_gp: 0.1282, G/loss_fake: -10.9329, G/loss_rec: 0.2264, G/loss_cls: 1.7647\nElapsed [1:03:02], Iteration [2000/30000], Dataset [3], D/loss_real: -25.0019, D/loss_fake: 22.7109, D/loss_cls: 4.5092, D/loss_gp: 0.0342, G/loss_fake: -12.0990, G/loss_rec: 0.1357, G/loss_cls: 6.4371\nSaved real and fake images into /kaggle/working/exps/visualization/2000...\nSaved model checkpoints at iteration 2000 into /kaggle/working/exps/checkpoints...\nElapsed [1:06:10], Iteration [2100/30000], Dataset [1], D/loss_real: -2.3566, D/loss_fake: -4.2002, D/loss_cls: 1.5941, D/loss_gp: 0.0310, G/loss_fake: 3.8636, G/loss_rec: 0.2391, G/loss_cls: 2.3883\nElapsed [1:06:12], Iteration [2100/30000], Dataset [2], D/loss_real: -4.1786, D/loss_fake: -0.6571, D/loss_cls: 1.1718, D/loss_gp: 0.0557, G/loss_fake: -0.2561, G/loss_rec: 0.2070, G/loss_cls: 1.8848\nElapsed [1:06:13], Iteration [2100/30000], Dataset [3], D/loss_real: 1.1366, D/loss_fake: -2.8608, D/loss_cls: 0.0230, D/loss_gp: 0.0261, G/loss_fake: -0.9222, G/loss_rec: 0.1508, G/loss_cls: 0.1168\nElapsed [1:09:20], Iteration [2200/30000], Dataset [1], D/loss_real: -3.4003, D/loss_fake: -2.1458, D/loss_cls: 1.4989, D/loss_gp: 0.0727, G/loss_fake: 0.9086, G/loss_rec: 0.2202, G/loss_cls: 2.4120\nElapsed [1:09:21], Iteration [2200/30000], Dataset [2], D/loss_real: -6.4188, D/loss_fake: 0.8261, D/loss_cls: 0.7162, D/loss_gp: 0.0612, G/loss_fake: -0.3641, G/loss_rec: 0.2252, G/loss_cls: 1.5148\nElapsed [1:09:22], Iteration [2200/30000], Dataset [3], D/loss_real: -6.6959, D/loss_fake: 3.7812, D/loss_cls: 0.0008, D/loss_gp: 0.0173, G/loss_fake: -4.9977, G/loss_rec: 0.1503, G/loss_cls: 0.0676\nElapsed [1:12:29], Iteration [2300/30000], Dataset [1], D/loss_real: -15.1240, D/loss_fake: 9.5367, D/loss_cls: 1.6858, D/loss_gp: 0.0670, G/loss_fake: -7.9780, G/loss_rec: 0.2310, G/loss_cls: 2.8696\nElapsed [1:12:30], Iteration [2300/30000], Dataset [2], D/loss_real: -14.6749, D/loss_fake: 12.0877, D/loss_cls: 0.8670, D/loss_gp: 0.0637, G/loss_fake: -9.3562, G/loss_rec: 0.2043, G/loss_cls: 1.4442\nElapsed [1:12:31], Iteration [2300/30000], Dataset [3], D/loss_real: -13.8122, D/loss_fake: 12.6470, D/loss_cls: 0.0072, D/loss_gp: 0.0300, G/loss_fake: -11.8360, G/loss_rec: 0.1571, G/loss_cls: 0.2174\nElapsed [1:15:38], Iteration [2400/30000], Dataset [1], D/loss_real: -14.5885, D/loss_fake: 8.3020, D/loss_cls: 1.7166, D/loss_gp: 0.0721, G/loss_fake: -3.9376, G/loss_rec: 0.2272, G/loss_cls: 2.5305\nElapsed [1:15:39], Iteration [2400/30000], Dataset [2], D/loss_real: -13.4140, D/loss_fake: 9.7931, D/loss_cls: 0.9583, D/loss_gp: 0.1150, G/loss_fake: -7.6031, G/loss_rec: 0.2010, G/loss_cls: 1.7319\nElapsed [1:15:40], Iteration [2400/30000], Dataset [3], D/loss_real: -13.4675, D/loss_fake: 11.1389, D/loss_cls: 0.0063, D/loss_gp: 0.0441, G/loss_fake: -11.2960, G/loss_rec: 0.1442, G/loss_cls: 0.1015\nElapsed [1:18:47], Iteration [2500/30000], Dataset [1], D/loss_real: -12.7550, D/loss_fake: 8.1242, D/loss_cls: 1.8006, D/loss_gp: 0.0579, G/loss_fake: -6.4208, G/loss_rec: 0.2140, G/loss_cls: 2.1785\nElapsed [1:18:48], Iteration [2500/30000], Dataset [2], D/loss_real: -12.5309, D/loss_fake: 10.0269, D/loss_cls: 0.9165, D/loss_gp: 0.0796, G/loss_fake: -6.0342, G/loss_rec: 0.2087, G/loss_cls: 1.3718\nElapsed [1:18:49], Iteration [2500/30000], Dataset [3], D/loss_real: -7.4409, D/loss_fake: 4.6416, D/loss_cls: 0.0013, D/loss_gp: 0.0184, G/loss_fake: -5.0981, G/loss_rec: 0.1332, G/loss_cls: 0.0438\nElapsed [1:21:56], Iteration [2600/30000], Dataset [1], D/loss_real: -9.0634, D/loss_fake: 4.5296, D/loss_cls: 2.0168, D/loss_gp: 0.0375, G/loss_fake: -4.7551, G/loss_rec: 0.2103, G/loss_cls: 2.2270\nElapsed [1:21:57], Iteration [2600/30000], Dataset [2], D/loss_real: -9.9295, D/loss_fake: 6.4534, D/loss_cls: 0.9303, D/loss_gp: 0.0501, G/loss_fake: -6.0470, G/loss_rec: 0.2038, G/loss_cls: 1.6144\nElapsed [1:21:58], Iteration [2600/30000], Dataset [3], D/loss_real: -8.3035, D/loss_fake: 6.4051, D/loss_cls: 0.0586, D/loss_gp: 0.0235, G/loss_fake: -5.4487, G/loss_rec: 0.1517, G/loss_cls: 0.0185\nElapsed [1:25:05], Iteration [2700/30000], Dataset [1], D/loss_real: -16.2217, D/loss_fake: 9.9959, D/loss_cls: 1.5078, D/loss_gp: 0.0677, G/loss_fake: -8.2993, G/loss_rec: 0.2243, G/loss_cls: 2.1006\nElapsed [1:25:06], Iteration [2700/30000], Dataset [2], D/loss_real: -12.6922, D/loss_fake: 7.6037, D/loss_cls: 1.4708, D/loss_gp: 0.0676, G/loss_fake: -10.7930, G/loss_rec: 0.2247, G/loss_cls: 1.3607\nElapsed [1:25:07], Iteration [2700/30000], Dataset [3], D/loss_real: -20.9670, D/loss_fake: 16.3892, D/loss_cls: 0.0020, D/loss_gp: 0.0565, G/loss_fake: -17.2587, G/loss_rec: 0.1475, G/loss_cls: 0.1728\nElapsed [1:28:14], Iteration [2800/30000], Dataset [1], D/loss_real: -9.3005, D/loss_fake: 4.8675, D/loss_cls: 1.5683, D/loss_gp: 0.0888, G/loss_fake: -5.9571, G/loss_rec: 0.2039, G/loss_cls: 2.0996\nElapsed [1:28:15], Iteration [2800/30000], Dataset [2], D/loss_real: -10.9173, D/loss_fake: 6.9986, D/loss_cls: 1.1483, D/loss_gp: 0.0634, G/loss_fake: -6.7961, G/loss_rec: 0.1960, G/loss_cls: 1.1752\nElapsed [1:28:16], Iteration [2800/30000], Dataset [3], D/loss_real: -8.3559, D/loss_fake: 6.4483, D/loss_cls: 0.0827, D/loss_gp: 0.0052, G/loss_fake: -5.0972, G/loss_rec: 0.1529, G/loss_cls: 0.0496\nElapsed [1:31:23], Iteration [2900/30000], Dataset [1], D/loss_real: -16.3921, D/loss_fake: 10.0413, D/loss_cls: 1.3611, D/loss_gp: 0.0766, G/loss_fake: -8.9505, G/loss_rec: 0.2183, G/loss_cls: 1.9897\nElapsed [1:31:24], Iteration [2900/30000], Dataset [2], D/loss_real: -14.7256, D/loss_fake: 9.1984, D/loss_cls: 1.1361, D/loss_gp: 0.1041, G/loss_fake: -7.3901, G/loss_rec: 0.2178, G/loss_cls: 1.0913\nElapsed [1:31:26], Iteration [2900/30000], Dataset [3], D/loss_real: -6.9246, D/loss_fake: 3.7393, D/loss_cls: 0.0246, D/loss_gp: 0.1248, G/loss_fake: -0.4872, G/loss_rec: 0.1427, G/loss_cls: 0.0041\nElapsed [1:34:32], Iteration [3000/30000], Dataset [1], D/loss_real: -9.0205, D/loss_fake: 3.5228, D/loss_cls: 1.3924, D/loss_gp: 0.0783, G/loss_fake: -2.3333, G/loss_rec: 0.2117, G/loss_cls: 1.8255\nElapsed [1:34:33], Iteration [3000/30000], Dataset [2], D/loss_real: -7.7292, D/loss_fake: 2.8430, D/loss_cls: 1.0695, D/loss_gp: 0.0423, G/loss_fake: -2.6364, G/loss_rec: 0.2107, G/loss_cls: 1.2628\nElapsed [1:34:35], Iteration [3000/30000], Dataset [3], D/loss_real: -5.8359, D/loss_fake: 3.5235, D/loss_cls: 0.0020, D/loss_gp: 0.0234, G/loss_fake: -4.6825, G/loss_rec: 0.1397, G/loss_cls: 0.0061\nElapsed [1:37:41], Iteration [3100/30000], Dataset [1], D/loss_real: -11.5910, D/loss_fake: 6.6277, D/loss_cls: 2.0024, D/loss_gp: 0.0456, G/loss_fake: -6.4285, G/loss_rec: 0.2266, G/loss_cls: 2.2877\nElapsed [1:37:42], Iteration [3100/30000], Dataset [2], D/loss_real: -12.4380, D/loss_fake: 8.6208, D/loss_cls: 1.2353, D/loss_gp: 0.0409, G/loss_fake: -6.1827, G/loss_rec: 0.2071, G/loss_cls: 1.2913\nElapsed [1:37:44], Iteration [3100/30000], Dataset [3], D/loss_real: -14.4573, D/loss_fake: 11.8914, D/loss_cls: 0.0004, D/loss_gp: 0.0100, G/loss_fake: -9.0549, G/loss_rec: 0.1343, G/loss_cls: 0.0700\nElapsed [1:40:50], Iteration [3200/30000], Dataset [1], D/loss_real: -8.4490, D/loss_fake: 3.0655, D/loss_cls: 1.6494, D/loss_gp: 0.0270, G/loss_fake: -4.0947, G/loss_rec: 0.2068, G/loss_cls: 2.4735\nElapsed [1:40:51], Iteration [3200/30000], Dataset [2], D/loss_real: -10.9891, D/loss_fake: 6.2223, D/loss_cls: 1.3116, D/loss_gp: 0.0654, G/loss_fake: -4.4763, G/loss_rec: 0.2093, G/loss_cls: 1.2685\nElapsed [1:40:52], Iteration [3200/30000], Dataset [3], D/loss_real: -16.0977, D/loss_fake: 11.5498, D/loss_cls: 0.0079, D/loss_gp: 0.0506, G/loss_fake: -13.9125, G/loss_rec: 0.1593, G/loss_cls: 0.0916\nElapsed [1:43:59], Iteration [3300/30000], Dataset [1], D/loss_real: -9.9552, D/loss_fake: 4.6404, D/loss_cls: 1.4624, D/loss_gp: 0.0345, G/loss_fake: -5.5338, G/loss_rec: 0.2082, G/loss_cls: 2.3910\nElapsed [1:44:00], Iteration [3300/30000], Dataset [2], D/loss_real: -10.1224, D/loss_fake: 6.9678, D/loss_cls: 1.1778, D/loss_gp: 0.0577, G/loss_fake: -6.7298, G/loss_rec: 0.1926, G/loss_cls: 1.0088\nElapsed [1:44:01], Iteration [3300/30000], Dataset [3], D/loss_real: -11.6944, D/loss_fake: 9.1905, D/loss_cls: 0.0080, D/loss_gp: 0.0213, G/loss_fake: -8.4461, G/loss_rec: 0.1329, G/loss_cls: 0.0173\nElapsed [1:47:08], Iteration [3400/30000], Dataset [1], D/loss_real: -13.2601, D/loss_fake: 7.1607, D/loss_cls: 1.6192, D/loss_gp: 0.0666, G/loss_fake: -8.0777, G/loss_rec: 0.2215, G/loss_cls: 2.0997\nElapsed [1:47:09], Iteration [3400/30000], Dataset [2], D/loss_real: -13.3337, D/loss_fake: 7.8759, D/loss_cls: 0.9647, D/loss_gp: 0.0841, G/loss_fake: -6.8802, G/loss_rec: 0.1986, G/loss_cls: 0.9893\nElapsed [1:47:11], Iteration [3400/30000], Dataset [3], D/loss_real: -7.8067, D/loss_fake: 4.1461, D/loss_cls: 0.0084, D/loss_gp: 0.0513, G/loss_fake: -2.6635, G/loss_rec: 0.1409, G/loss_cls: 0.0397\nElapsed [1:50:17], Iteration [3500/30000], Dataset [1], D/loss_real: -10.6915, D/loss_fake: 6.2288, D/loss_cls: 1.5248, D/loss_gp: 0.0678, G/loss_fake: -6.1058, G/loss_rec: 0.2088, G/loss_cls: 1.8374\nElapsed [1:50:18], Iteration [3500/30000], Dataset [2], D/loss_real: -10.4816, D/loss_fake: 6.7882, D/loss_cls: 0.8412, D/loss_gp: 0.0456, G/loss_fake: -7.4381, G/loss_rec: 0.2028, G/loss_cls: 0.8468\nElapsed [1:50:20], Iteration [3500/30000], Dataset [3], D/loss_real: -8.0776, D/loss_fake: 6.4149, D/loss_cls: 0.0052, D/loss_gp: 0.0120, G/loss_fake: -3.7393, G/loss_rec: 0.1291, G/loss_cls: 0.0871\nElapsed [1:53:26], Iteration [3600/30000], Dataset [1], D/loss_real: -11.7725, D/loss_fake: 6.3266, D/loss_cls: 1.4970, D/loss_gp: 0.0473, G/loss_fake: -4.1649, G/loss_rec: 0.2128, G/loss_cls: 1.9369\nElapsed [1:53:27], Iteration [3600/30000], Dataset [2], D/loss_real: -11.2047, D/loss_fake: 6.3941, D/loss_cls: 0.7466, D/loss_gp: 0.0493, G/loss_fake: -6.8465, G/loss_rec: 0.1937, G/loss_cls: 0.7940\nElapsed [1:53:29], Iteration [3600/30000], Dataset [3], D/loss_real: -6.8713, D/loss_fake: 5.1748, D/loss_cls: 0.0031, D/loss_gp: 0.0653, G/loss_fake: -2.2073, G/loss_rec: 0.1306, G/loss_cls: 0.0747\nElapsed [1:56:35], Iteration [3700/30000], Dataset [1], D/loss_real: -10.8305, D/loss_fake: 5.4149, D/loss_cls: 1.5005, D/loss_gp: 0.0290, G/loss_fake: -2.5948, G/loss_rec: 0.2072, G/loss_cls: 1.6910\nElapsed [1:56:36], Iteration [3700/30000], Dataset [2], D/loss_real: -6.9550, D/loss_fake: 1.8879, D/loss_cls: 0.8765, D/loss_gp: 0.0340, G/loss_fake: -1.7095, G/loss_rec: 0.1966, G/loss_cls: 0.9112\nElapsed [1:56:38], Iteration [3700/30000], Dataset [3], D/loss_real: -3.2845, D/loss_fake: 4.1032, D/loss_cls: 0.0016, D/loss_gp: 0.0471, G/loss_fake: -0.0643, G/loss_rec: 0.1419, G/loss_cls: 0.0216\nElapsed [1:59:44], Iteration [3800/30000], Dataset [1], D/loss_real: -15.2832, D/loss_fake: 10.9259, D/loss_cls: 1.5970, D/loss_gp: 0.1281, G/loss_fake: -8.1180, G/loss_rec: 0.2020, G/loss_cls: 1.4643\nElapsed [1:59:46], Iteration [3800/30000], Dataset [2], D/loss_real: -13.4042, D/loss_fake: 9.9716, D/loss_cls: 0.9010, D/loss_gp: 0.0469, G/loss_fake: -8.3817, G/loss_rec: 0.2073, G/loss_cls: 1.0499\nElapsed [1:59:47], Iteration [3800/30000], Dataset [3], D/loss_real: -7.1191, D/loss_fake: 4.3155, D/loss_cls: 0.0550, D/loss_gp: 0.0121, G/loss_fake: -2.9779, G/loss_rec: 0.1338, G/loss_cls: 0.1087\nElapsed [2:02:53], Iteration [3900/30000], Dataset [1], D/loss_real: -8.0046, D/loss_fake: 3.5366, D/loss_cls: 1.6276, D/loss_gp: 0.0245, G/loss_fake: -3.3013, G/loss_rec: 0.2148, G/loss_cls: 1.5578\nElapsed [2:02:55], Iteration [3900/30000], Dataset [2], D/loss_real: -8.0319, D/loss_fake: 5.2727, D/loss_cls: 0.8252, D/loss_gp: 0.0351, G/loss_fake: -4.5966, G/loss_rec: 0.1992, G/loss_cls: 0.9891\nElapsed [2:02:56], Iteration [3900/30000], Dataset [3], D/loss_real: -11.0005, D/loss_fake: 9.0559, D/loss_cls: 0.0010, D/loss_gp: 0.0101, G/loss_fake: -8.5897, G/loss_rec: 0.1318, G/loss_cls: 0.0788\nElapsed [2:06:02], Iteration [4000/30000], Dataset [1], D/loss_real: -5.7170, D/loss_fake: 1.7790, D/loss_cls: 1.4098, D/loss_gp: 0.0487, G/loss_fake: -0.9720, G/loss_rec: 0.1937, G/loss_cls: 1.5038\nElapsed [2:06:04], Iteration [4000/30000], Dataset [2], D/loss_real: -5.6221, D/loss_fake: 2.3791, D/loss_cls: 0.6891, D/loss_gp: 0.0229, G/loss_fake: -1.7234, G/loss_rec: 0.1853, G/loss_cls: 0.9136\nElapsed [2:06:05], Iteration [4000/30000], Dataset [3], D/loss_real: -2.6251, D/loss_fake: 0.9237, D/loss_cls: 0.0008, D/loss_gp: 0.0048, G/loss_fake: 0.2208, G/loss_rec: 0.1262, G/loss_cls: 0.0698\nSaved real and fake images into /kaggle/working/exps/visualization/4000...\nSaved model checkpoints at iteration 4000 into /kaggle/working/exps/checkpoints...\nElapsed [2:09:14], Iteration [4100/30000], Dataset [1], D/loss_real: -13.4819, D/loss_fake: 8.2486, D/loss_cls: 1.6889, D/loss_gp: 0.0575, G/loss_fake: -8.0496, G/loss_rec: 0.2230, G/loss_cls: 1.7857\nElapsed [2:09:15], Iteration [4100/30000], Dataset [2], D/loss_real: -13.1579, D/loss_fake: 10.3276, D/loss_cls: 1.0128, D/loss_gp: 0.0193, G/loss_fake: -9.2222, G/loss_rec: 0.2073, G/loss_cls: 0.8499\nElapsed [2:09:16], Iteration [4100/30000], Dataset [3], D/loss_real: -8.3364, D/loss_fake: 7.8157, D/loss_cls: 0.0037, D/loss_gp: 0.0091, G/loss_fake: -5.5637, G/loss_rec: 0.1301, G/loss_cls: 0.0075\nElapsed [2:12:23], Iteration [4200/30000], Dataset [1], D/loss_real: -5.0252, D/loss_fake: -1.1241, D/loss_cls: 1.7831, D/loss_gp: 0.0394, G/loss_fake: 2.3950, G/loss_rec: 0.2324, G/loss_cls: 2.4936\nElapsed [2:12:24], Iteration [4200/30000], Dataset [2], D/loss_real: -3.4375, D/loss_fake: -0.7988, D/loss_cls: 1.1852, D/loss_gp: 0.0600, G/loss_fake: -1.4028, G/loss_rec: 0.2104, G/loss_cls: 0.8985\nElapsed [2:12:25], Iteration [4200/30000], Dataset [3], D/loss_real: -15.7360, D/loss_fake: 13.8519, D/loss_cls: 0.0102, D/loss_gp: 0.0462, G/loss_fake: -12.8518, G/loss_rec: 0.1173, G/loss_cls: 0.1608\nElapsed [2:15:32], Iteration [4300/30000], Dataset [1], D/loss_real: -5.5599, D/loss_fake: 0.7680, D/loss_cls: 1.5872, D/loss_gp: 0.0803, G/loss_fake: 0.9879, G/loss_rec: 0.2207, G/loss_cls: 1.7172\nElapsed [2:15:33], Iteration [4300/30000], Dataset [2], D/loss_real: -3.5068, D/loss_fake: -0.2303, D/loss_cls: 1.1989, D/loss_gp: 0.0463, G/loss_fake: 0.1067, G/loss_rec: 0.2040, G/loss_cls: 0.9470\nElapsed [2:15:34], Iteration [4300/30000], Dataset [3], D/loss_real: -9.9911, D/loss_fake: 5.9035, D/loss_cls: 0.0014, D/loss_gp: 0.0200, G/loss_fake: -2.8843, G/loss_rec: 0.1392, G/loss_cls: 0.0664\nElapsed [2:18:41], Iteration [4400/30000], Dataset [1], D/loss_real: -10.5922, D/loss_fake: 5.4541, D/loss_cls: 1.4872, D/loss_gp: 0.0590, G/loss_fake: -6.3339, G/loss_rec: 0.2073, G/loss_cls: 1.9682\nElapsed [2:18:42], Iteration [4400/30000], Dataset [2], D/loss_real: -11.6121, D/loss_fake: 8.6115, D/loss_cls: 0.7184, D/loss_gp: 0.0887, G/loss_fake: -9.4810, G/loss_rec: 0.1817, G/loss_cls: 0.8060\nElapsed [2:18:43], Iteration [4400/30000], Dataset [3], D/loss_real: -8.0185, D/loss_fake: 6.7067, D/loss_cls: 0.0146, D/loss_gp: 0.0163, G/loss_fake: -5.2672, G/loss_rec: 0.1201, G/loss_cls: 0.0299\nElapsed [2:21:50], Iteration [4500/30000], Dataset [1], D/loss_real: -5.9596, D/loss_fake: 2.5790, D/loss_cls: 1.5815, D/loss_gp: 0.0406, G/loss_fake: -0.9139, G/loss_rec: 0.1999, G/loss_cls: 1.6427\nElapsed [2:21:51], Iteration [4500/30000], Dataset [2], D/loss_real: -4.4295, D/loss_fake: 1.3766, D/loss_cls: 0.6651, D/loss_gp: 0.0197, G/loss_fake: -0.8870, G/loss_rec: 0.2005, G/loss_cls: 0.6071\nElapsed [2:21:53], Iteration [4500/30000], Dataset [3], D/loss_real: -6.8192, D/loss_fake: 5.1380, D/loss_cls: 0.0246, D/loss_gp: 0.0163, G/loss_fake: -5.1988, G/loss_rec: 0.1358, G/loss_cls: 0.0039\nElapsed [2:24:59], Iteration [4600/30000], Dataset [1], D/loss_real: -11.0409, D/loss_fake: 5.3741, D/loss_cls: 1.3687, D/loss_gp: 0.0441, G/loss_fake: -4.5151, G/loss_rec: 0.1980, G/loss_cls: 1.7010\nElapsed [2:25:00], Iteration [4600/30000], Dataset [2], D/loss_real: -10.1461, D/loss_fake: 5.6333, D/loss_cls: 0.9359, D/loss_gp: 0.0466, G/loss_fake: -4.5622, G/loss_rec: 0.1823, G/loss_cls: 0.8603\nElapsed [2:25:02], Iteration [4600/30000], Dataset [3], D/loss_real: -1.9315, D/loss_fake: -0.7545, D/loss_cls: 0.0010, D/loss_gp: 0.0197, G/loss_fake: -0.4843, G/loss_rec: 0.1245, G/loss_cls: 0.0278\nElapsed [2:28:08], Iteration [4700/30000], Dataset [1], D/loss_real: -10.3116, D/loss_fake: 5.9574, D/loss_cls: 1.9299, D/loss_gp: 0.0720, G/loss_fake: -4.1752, G/loss_rec: 0.1921, G/loss_cls: 1.3774\nElapsed [2:28:09], Iteration [4700/30000], Dataset [2], D/loss_real: -8.1329, D/loss_fake: 6.5310, D/loss_cls: 0.9127, D/loss_gp: 0.0293, G/loss_fake: -5.2522, G/loss_rec: 0.1853, G/loss_cls: 0.8974\nElapsed [2:28:10], Iteration [4700/30000], Dataset [3], D/loss_real: -9.3151, D/loss_fake: 8.6194, D/loss_cls: 0.0001, D/loss_gp: 0.0029, G/loss_fake: -8.2397, G/loss_rec: 0.1202, G/loss_cls: 0.0159\nElapsed [2:31:17], Iteration [4800/30000], Dataset [1], D/loss_real: -2.1123, D/loss_fake: -2.3708, D/loss_cls: 1.3728, D/loss_gp: 0.0498, G/loss_fake: 2.8006, G/loss_rec: 0.2039, G/loss_cls: 1.5188\nElapsed [2:31:18], Iteration [4800/30000], Dataset [2], D/loss_real: -2.7323, D/loss_fake: 0.2593, D/loss_cls: 0.8529, D/loss_gp: 0.0513, G/loss_fake: -1.2403, G/loss_rec: 0.1731, G/loss_cls: 0.8120\nElapsed [2:31:19], Iteration [4800/30000], Dataset [3], D/loss_real: -4.5299, D/loss_fake: 3.1696, D/loss_cls: 0.0005, D/loss_gp: 0.0164, G/loss_fake: -3.3822, G/loss_rec: 0.1135, G/loss_cls: 0.0552\nElapsed [2:34:26], Iteration [4900/30000], Dataset [1], D/loss_real: -14.9285, D/loss_fake: 9.6268, D/loss_cls: 1.5478, D/loss_gp: 0.1171, G/loss_fake: -7.3276, G/loss_rec: 0.2035, G/loss_cls: 1.7187\nElapsed [2:34:27], Iteration [4900/30000], Dataset [2], D/loss_real: -11.8117, D/loss_fake: 7.9241, D/loss_cls: 0.8220, D/loss_gp: 0.0671, G/loss_fake: -4.3628, G/loss_rec: 0.1780, G/loss_cls: 0.7419\nElapsed [2:34:29], Iteration [4900/30000], Dataset [3], D/loss_real: -6.8386, D/loss_fake: 4.5692, D/loss_cls: 0.0012, D/loss_gp: 0.0228, G/loss_fake: -1.5734, G/loss_rec: 0.1155, G/loss_cls: 0.0032\nElapsed [2:37:35], Iteration [5000/30000], Dataset [1], D/loss_real: -9.9952, D/loss_fake: 5.0480, D/loss_cls: 1.0403, D/loss_gp: 0.0232, G/loss_fake: -3.4660, G/loss_rec: 0.2158, G/loss_cls: 1.2455\nElapsed [2:37:36], Iteration [5000/30000], Dataset [2], D/loss_real: -10.1504, D/loss_fake: 7.3985, D/loss_cls: 0.8296, D/loss_gp: 0.0532, G/loss_fake: -4.2108, G/loss_rec: 0.1959, G/loss_cls: 0.8124\nElapsed [2:37:38], Iteration [5000/30000], Dataset [3], D/loss_real: -14.6719, D/loss_fake: 13.7633, D/loss_cls: 0.0113, D/loss_gp: 0.0037, G/loss_fake: -11.9348, G/loss_rec: 0.1237, G/loss_cls: 0.0016\nElapsed [2:40:44], Iteration [5100/30000], Dataset [1], D/loss_real: -10.7942, D/loss_fake: 6.2348, D/loss_cls: 1.3549, D/loss_gp: 0.0638, G/loss_fake: -5.6934, G/loss_rec: 0.2036, G/loss_cls: 1.4288\nElapsed [2:40:46], Iteration [5100/30000], Dataset [2], D/loss_real: -9.7975, D/loss_fake: 6.2310, D/loss_cls: 1.3398, D/loss_gp: 0.0384, G/loss_fake: -4.7814, G/loss_rec: 0.1756, G/loss_cls: 0.4500\nElapsed [2:40:47], Iteration [5100/30000], Dataset [3], D/loss_real: -10.3411, D/loss_fake: 9.2924, D/loss_cls: 0.0018, D/loss_gp: 0.0118, G/loss_fake: -6.7095, G/loss_rec: 0.1316, G/loss_cls: 0.0423\nElapsed [2:43:53], Iteration [5200/30000], Dataset [1], D/loss_real: -7.7879, D/loss_fake: 4.3004, D/loss_cls: 1.4729, D/loss_gp: 0.0287, G/loss_fake: -4.5867, G/loss_rec: 0.1946, G/loss_cls: 1.3384\nElapsed [2:43:55], Iteration [5200/30000], Dataset [2], D/loss_real: -8.7089, D/loss_fake: 5.4430, D/loss_cls: 0.6774, D/loss_gp: 0.0342, G/loss_fake: -4.8357, G/loss_rec: 0.1844, G/loss_cls: 0.7430\nElapsed [2:43:56], Iteration [5200/30000], Dataset [3], D/loss_real: -9.4751, D/loss_fake: 8.3876, D/loss_cls: 0.0007, D/loss_gp: 0.0137, G/loss_fake: -8.0351, G/loss_rec: 0.1291, G/loss_cls: 0.0059\nElapsed [2:47:02], Iteration [5300/30000], Dataset [1], D/loss_real: -19.0125, D/loss_fake: 11.8415, D/loss_cls: 2.1931, D/loss_gp: 0.1683, G/loss_fake: -8.9470, G/loss_rec: 0.2190, G/loss_cls: 1.6990\nElapsed [2:47:04], Iteration [5300/30000], Dataset [2], D/loss_real: -16.2675, D/loss_fake: 10.7624, D/loss_cls: 2.4899, D/loss_gp: 0.0418, G/loss_fake: -6.9619, G/loss_rec: 0.1888, G/loss_cls: 0.7633\nElapsed [2:47:05], Iteration [5300/30000], Dataset [3], D/loss_real: -4.3716, D/loss_fake: 0.7126, D/loss_cls: 0.0005, D/loss_gp: 0.0252, G/loss_fake: 0.3584, G/loss_rec: 0.1243, G/loss_cls: 0.0080\nElapsed [2:50:11], Iteration [5400/30000], Dataset [1], D/loss_real: -5.5193, D/loss_fake: 2.1427, D/loss_cls: 1.5657, D/loss_gp: 0.0189, G/loss_fake: -1.4693, G/loss_rec: 0.1925, G/loss_cls: 1.7350\nElapsed [2:50:13], Iteration [5400/30000], Dataset [2], D/loss_real: -4.1414, D/loss_fake: 1.2811, D/loss_cls: 0.7938, D/loss_gp: 0.0161, G/loss_fake: -2.9802, G/loss_rec: 0.1816, G/loss_cls: 0.4577\nElapsed [2:50:14], Iteration [5400/30000], Dataset [3], D/loss_real: -5.6040, D/loss_fake: 4.0938, D/loss_cls: 0.0070, D/loss_gp: 0.0163, G/loss_fake: -3.6922, G/loss_rec: 0.1262, G/loss_cls: 0.0208\nElapsed [2:53:20], Iteration [5500/30000], Dataset [1], D/loss_real: -21.9906, D/loss_fake: 16.1839, D/loss_cls: 1.3116, D/loss_gp: 0.1507, G/loss_fake: -10.6332, G/loss_rec: 0.2007, G/loss_cls: 1.5485\nElapsed [2:53:22], Iteration [5500/30000], Dataset [2], D/loss_real: -15.5830, D/loss_fake: 11.4397, D/loss_cls: 0.9214, D/loss_gp: 0.0478, G/loss_fake: -7.4698, G/loss_rec: 0.1845, G/loss_cls: 0.8196\nElapsed [2:53:23], Iteration [5500/30000], Dataset [3], D/loss_real: -6.3056, D/loss_fake: 5.0406, D/loss_cls: 0.0001, D/loss_gp: 0.0226, G/loss_fake: -3.7853, G/loss_rec: 0.1162, G/loss_cls: 0.0361\nElapsed [2:56:29], Iteration [5600/30000], Dataset [1], D/loss_real: -8.7065, D/loss_fake: 5.4786, D/loss_cls: 1.3222, D/loss_gp: 0.0237, G/loss_fake: -4.5596, G/loss_rec: 0.2024, G/loss_cls: 1.7841\nElapsed [2:56:31], Iteration [5600/30000], Dataset [2], D/loss_real: -7.8927, D/loss_fake: 5.3031, D/loss_cls: 0.8627, D/loss_gp: 0.0180, G/loss_fake: -5.0033, G/loss_rec: 0.1709, G/loss_cls: 0.6015\nElapsed [2:56:32], Iteration [5600/30000], Dataset [3], D/loss_real: -5.3415, D/loss_fake: 3.0658, D/loss_cls: 0.0012, D/loss_gp: 0.0087, G/loss_fake: -1.3855, G/loss_rec: 0.1126, G/loss_cls: 0.0101\nElapsed [2:59:38], Iteration [5700/30000], Dataset [1], D/loss_real: -3.6729, D/loss_fake: 1.1390, D/loss_cls: 1.2916, D/loss_gp: 0.0186, G/loss_fake: -1.1335, G/loss_rec: 0.1913, G/loss_cls: 1.3418\nElapsed [2:59:40], Iteration [5700/30000], Dataset [2], D/loss_real: -5.3806, D/loss_fake: 1.6610, D/loss_cls: 0.7374, D/loss_gp: 0.0215, G/loss_fake: -2.2591, G/loss_rec: 0.1711, G/loss_cls: 0.5319\nElapsed [2:59:41], Iteration [5700/30000], Dataset [3], D/loss_real: -5.1230, D/loss_fake: 3.4283, D/loss_cls: 0.0003, D/loss_gp: 0.0145, G/loss_fake: -4.3179, G/loss_rec: 0.1149, G/loss_cls: 0.0364\nElapsed [3:02:47], Iteration [5800/30000], Dataset [1], D/loss_real: -14.3890, D/loss_fake: 9.0165, D/loss_cls: 2.9712, D/loss_gp: 0.0354, G/loss_fake: -2.0759, G/loss_rec: 0.2153, G/loss_cls: 1.9798\nElapsed [3:02:48], Iteration [5800/30000], Dataset [2], D/loss_real: -6.5494, D/loss_fake: 2.7133, D/loss_cls: 0.8830, D/loss_gp: 0.0108, G/loss_fake: -7.1261, G/loss_rec: 0.1903, G/loss_cls: 0.7444\nElapsed [3:02:50], Iteration [5800/30000], Dataset [3], D/loss_real: -13.7333, D/loss_fake: 11.3952, D/loss_cls: 0.0001, D/loss_gp: 0.0542, G/loss_fake: -7.0916, G/loss_rec: 0.1256, G/loss_cls: 0.0711\nElapsed [3:05:56], Iteration [5900/30000], Dataset [1], D/loss_real: -6.9242, D/loss_fake: 3.3231, D/loss_cls: 1.2737, D/loss_gp: 0.0334, G/loss_fake: -3.3677, G/loss_rec: 0.1817, G/loss_cls: 1.6070\nElapsed [3:05:57], Iteration [5900/30000], Dataset [2], D/loss_real: -8.3176, D/loss_fake: 4.3366, D/loss_cls: 0.6212, D/loss_gp: 0.0397, G/loss_fake: -4.6990, G/loss_rec: 0.1746, G/loss_cls: 0.5305\nElapsed [3:05:59], Iteration [5900/30000], Dataset [3], D/loss_real: -5.3287, D/loss_fake: 3.2797, D/loss_cls: 0.0011, D/loss_gp: 0.0134, G/loss_fake: -3.0396, G/loss_rec: 0.1238, G/loss_cls: 0.0740\nElapsed [3:09:05], Iteration [6000/30000], Dataset [1], D/loss_real: -6.3952, D/loss_fake: 2.3910, D/loss_cls: 1.6748, D/loss_gp: 0.0126, G/loss_fake: -2.7603, G/loss_rec: 0.1873, G/loss_cls: 1.4733\nElapsed [3:09:07], Iteration [6000/30000], Dataset [2], D/loss_real: -7.5834, D/loss_fake: 4.7350, D/loss_cls: 1.0241, D/loss_gp: 0.0375, G/loss_fake: -4.7121, G/loss_rec: 0.1772, G/loss_cls: 0.8272\nElapsed [3:09:08], Iteration [6000/30000], Dataset [3], D/loss_real: -10.6620, D/loss_fake: 8.4282, D/loss_cls: 0.0023, D/loss_gp: 0.0166, G/loss_fake: -8.7856, G/loss_rec: 0.1195, G/loss_cls: 0.0733\nSaved real and fake images into /kaggle/working/exps/visualization/6000...\nSaved model checkpoints at iteration 6000 into /kaggle/working/exps/checkpoints...\nElapsed [3:12:16], Iteration [6100/30000], Dataset [1], D/loss_real: -4.5106, D/loss_fake: -1.0395, D/loss_cls: 2.1684, D/loss_gp: 0.0520, G/loss_fake: 0.4765, G/loss_rec: 0.2208, G/loss_cls: 1.7916\nElapsed [3:12:18], Iteration [6100/30000], Dataset [2], D/loss_real: -5.6109, D/loss_fake: 1.3893, D/loss_cls: 0.8739, D/loss_gp: 0.0766, G/loss_fake: -5.1935, G/loss_rec: 0.1777, G/loss_cls: 0.5408\nElapsed [3:12:19], Iteration [6100/30000], Dataset [3], D/loss_real: -12.4085, D/loss_fake: 12.8647, D/loss_cls: 0.0010, D/loss_gp: 0.0217, G/loss_fake: -15.3380, G/loss_rec: 0.1201, G/loss_cls: 0.2158\nElapsed [3:15:25], Iteration [6200/30000], Dataset [1], D/loss_real: -2.2954, D/loss_fake: -2.3506, D/loss_cls: 1.2848, D/loss_gp: 0.0364, G/loss_fake: 2.9230, G/loss_rec: 0.2000, G/loss_cls: 1.7272\nElapsed [3:15:27], Iteration [6200/30000], Dataset [2], D/loss_real: -1.3113, D/loss_fake: -1.4081, D/loss_cls: 1.3752, D/loss_gp: 0.0554, G/loss_fake: 2.3141, G/loss_rec: 0.1727, G/loss_cls: 0.4405\nElapsed [3:15:28], Iteration [6200/30000], Dataset [3], D/loss_real: -3.3897, D/loss_fake: 2.5285, D/loss_cls: 0.0033, D/loss_gp: 0.0134, G/loss_fake: -1.9204, G/loss_rec: 0.1198, G/loss_cls: 0.0177\nElapsed [3:18:34], Iteration [6300/30000], Dataset [1], D/loss_real: -6.9896, D/loss_fake: 1.8501, D/loss_cls: 1.3609, D/loss_gp: 0.0652, G/loss_fake: -2.1388, G/loss_rec: 0.1933, G/loss_cls: 1.4529\nElapsed [3:18:35], Iteration [6300/30000], Dataset [2], D/loss_real: -9.2752, D/loss_fake: 4.7579, D/loss_cls: 0.8202, D/loss_gp: 0.0769, G/loss_fake: 1.0047, G/loss_rec: 0.1739, G/loss_cls: 0.5807\nElapsed [3:18:37], Iteration [6300/30000], Dataset [3], D/loss_real: 1.1639, D/loss_fake: -3.8197, D/loss_cls: 0.0001, D/loss_gp: 0.0283, G/loss_fake: 6.6446, G/loss_rec: 0.1250, G/loss_cls: 0.0167\nElapsed [3:21:43], Iteration [6400/30000], Dataset [1], D/loss_real: -4.4630, D/loss_fake: 1.5285, D/loss_cls: 1.2322, D/loss_gp: 0.0210, G/loss_fake: -1.2333, G/loss_rec: 0.1782, G/loss_cls: 1.5869\nElapsed [3:21:44], Iteration [6400/30000], Dataset [2], D/loss_real: -4.6633, D/loss_fake: 2.4836, D/loss_cls: 0.9849, D/loss_gp: 0.0314, G/loss_fake: -2.6378, G/loss_rec: 0.1597, G/loss_cls: 0.7837\nElapsed [3:21:46], Iteration [6400/30000], Dataset [3], D/loss_real: -4.8214, D/loss_fake: 3.5810, D/loss_cls: 0.0000, D/loss_gp: 0.0189, G/loss_fake: -3.4018, G/loss_rec: 0.1132, G/loss_cls: 0.0006\nElapsed [3:24:52], Iteration [6500/30000], Dataset [1], D/loss_real: -10.0107, D/loss_fake: 3.7054, D/loss_cls: 2.5943, D/loss_gp: 0.0501, G/loss_fake: -2.8768, G/loss_rec: 0.2097, G/loss_cls: 1.4007\nElapsed [3:24:54], Iteration [6500/30000], Dataset [2], D/loss_real: -10.1680, D/loss_fake: 6.4861, D/loss_cls: 1.8300, D/loss_gp: 0.0571, G/loss_fake: -2.8742, G/loss_rec: 0.1897, G/loss_cls: 0.6312\nElapsed [3:24:55], Iteration [6500/30000], Dataset [3], D/loss_real: -16.0526, D/loss_fake: 14.5918, D/loss_cls: 0.0003, D/loss_gp: 0.0345, G/loss_fake: -9.4688, G/loss_rec: 0.1111, G/loss_cls: 0.0186\nElapsed [3:28:01], Iteration [6600/30000], Dataset [1], D/loss_real: -9.5012, D/loss_fake: 4.2258, D/loss_cls: 1.7456, D/loss_gp: 0.0747, G/loss_fake: -4.6139, G/loss_rec: 0.1725, G/loss_cls: 1.5201\nElapsed [3:28:03], Iteration [6600/30000], Dataset [2], D/loss_real: -10.2166, D/loss_fake: 7.2997, D/loss_cls: 0.8729, D/loss_gp: 0.0631, G/loss_fake: -6.7702, G/loss_rec: 0.1687, G/loss_cls: 0.8775\nElapsed [3:28:04], Iteration [6600/30000], Dataset [3], D/loss_real: -11.9318, D/loss_fake: 10.5796, D/loss_cls: 0.0000, D/loss_gp: 0.0139, G/loss_fake: -9.4121, G/loss_rec: 0.1111, G/loss_cls: 0.0051\nElapsed [3:31:11], Iteration [6700/30000], Dataset [1], D/loss_real: -7.1654, D/loss_fake: 3.3478, D/loss_cls: 1.7595, D/loss_gp: 0.0308, G/loss_fake: -2.0082, G/loss_rec: 0.2002, G/loss_cls: 1.3478\nElapsed [3:31:12], Iteration [6700/30000], Dataset [2], D/loss_real: -6.1192, D/loss_fake: 3.7156, D/loss_cls: 0.7112, D/loss_gp: 0.0173, G/loss_fake: -2.4365, G/loss_rec: 0.1656, G/loss_cls: 0.5221\nElapsed [3:31:13], Iteration [6700/30000], Dataset [3], D/loss_real: -7.5328, D/loss_fake: 6.0765, D/loss_cls: 0.0000, D/loss_gp: 0.0145, G/loss_fake: -5.7979, G/loss_rec: 0.1066, G/loss_cls: 0.0014\nElapsed [3:34:20], Iteration [6800/30000], Dataset [1], D/loss_real: -10.2393, D/loss_fake: 5.6468, D/loss_cls: 1.3403, D/loss_gp: 0.0184, G/loss_fake: -4.6894, G/loss_rec: 0.1920, G/loss_cls: 1.4210\nElapsed [3:34:21], Iteration [6800/30000], Dataset [2], D/loss_real: -11.6031, D/loss_fake: 7.9847, D/loss_cls: 0.8205, D/loss_gp: 0.0582, G/loss_fake: -4.4419, G/loss_rec: 0.1964, G/loss_cls: 0.4723\nElapsed [3:34:22], Iteration [6800/30000], Dataset [3], D/loss_real: -16.0012, D/loss_fake: 13.5354, D/loss_cls: 0.0007, D/loss_gp: 0.0286, G/loss_fake: -7.5377, G/loss_rec: 0.1199, G/loss_cls: 0.0712\nElapsed [3:37:29], Iteration [6900/30000], Dataset [1], D/loss_real: -8.4644, D/loss_fake: 4.4379, D/loss_cls: 1.6382, D/loss_gp: 0.0210, G/loss_fake: -5.7595, G/loss_rec: 0.1813, G/loss_cls: 1.1774\nElapsed [3:37:30], Iteration [6900/30000], Dataset [2], D/loss_real: -11.3896, D/loss_fake: 8.2304, D/loss_cls: 0.8449, D/loss_gp: 0.0514, G/loss_fake: -7.3278, G/loss_rec: 0.1687, G/loss_cls: 0.3300\nElapsed [3:37:31], Iteration [6900/30000], Dataset [3], D/loss_real: -9.1662, D/loss_fake: 7.6006, D/loss_cls: 0.0007, D/loss_gp: 0.0254, G/loss_fake: -4.8655, G/loss_rec: 0.1212, G/loss_cls: 0.0575\nElapsed [3:40:38], Iteration [7000/30000], Dataset [1], D/loss_real: -14.4702, D/loss_fake: 10.8617, D/loss_cls: 1.6742, D/loss_gp: 0.0191, G/loss_fake: -10.4825, G/loss_rec: 0.1864, G/loss_cls: 1.3083\nElapsed [3:40:39], Iteration [7000/30000], Dataset [2], D/loss_real: -14.8790, D/loss_fake: 11.1364, D/loss_cls: 0.9114, D/loss_gp: 0.0367, G/loss_fake: -11.7370, G/loss_rec: 0.1883, G/loss_cls: 0.5275\nElapsed [3:40:41], Iteration [7000/30000], Dataset [3], D/loss_real: -15.5934, D/loss_fake: 14.5270, D/loss_cls: 0.0068, D/loss_gp: 0.0448, G/loss_fake: -10.7398, G/loss_rec: 0.1123, G/loss_cls: 0.0045\nElapsed [3:43:47], Iteration [7100/30000], Dataset [1], D/loss_real: -12.0677, D/loss_fake: 7.1729, D/loss_cls: 1.3433, D/loss_gp: 0.0320, G/loss_fake: -6.5048, G/loss_rec: 0.1901, G/loss_cls: 1.1920\nElapsed [3:43:48], Iteration [7100/30000], Dataset [2], D/loss_real: -11.6003, D/loss_fake: 7.6661, D/loss_cls: 0.9271, D/loss_gp: 0.0475, G/loss_fake: -7.3722, G/loss_rec: 0.1673, G/loss_cls: 0.5497\nElapsed [3:43:50], Iteration [7100/30000], Dataset [3], D/loss_real: -7.8205, D/loss_fake: 5.7297, D/loss_cls: 0.0086, D/loss_gp: 0.0804, G/loss_fake: -3.3824, G/loss_rec: 0.1126, G/loss_cls: 0.0050\nElapsed [3:46:56], Iteration [7200/30000], Dataset [1], D/loss_real: -6.1690, D/loss_fake: 2.8100, D/loss_cls: 1.3209, D/loss_gp: 0.0284, G/loss_fake: -1.5789, G/loss_rec: 0.1668, G/loss_cls: 1.3308\nElapsed [3:46:57], Iteration [7200/30000], Dataset [2], D/loss_real: -7.7079, D/loss_fake: 5.2523, D/loss_cls: 0.7952, D/loss_gp: 0.0188, G/loss_fake: -2.1501, G/loss_rec: 0.1741, G/loss_cls: 0.6236\nElapsed [3:46:59], Iteration [7200/30000], Dataset [3], D/loss_real: -8.2166, D/loss_fake: 7.1956, D/loss_cls: 0.0021, D/loss_gp: 0.0084, G/loss_fake: -4.3758, G/loss_rec: 0.1065, G/loss_cls: 0.0093\nElapsed [3:50:05], Iteration [7300/30000], Dataset [1], D/loss_real: -9.4601, D/loss_fake: 5.7297, D/loss_cls: 1.2515, D/loss_gp: 0.0335, G/loss_fake: -6.2178, G/loss_rec: 0.1725, G/loss_cls: 1.1295\nElapsed [3:50:06], Iteration [7300/30000], Dataset [2], D/loss_real: -10.2223, D/loss_fake: 6.9219, D/loss_cls: 0.9816, D/loss_gp: 0.0443, G/loss_fake: -6.6677, G/loss_rec: 0.1767, G/loss_cls: 0.6545\nElapsed [3:50:07], Iteration [7300/30000], Dataset [3], D/loss_real: -9.3400, D/loss_fake: 7.0357, D/loss_cls: 0.0694, D/loss_gp: 0.0134, G/loss_fake: -7.5791, G/loss_rec: 0.1118, G/loss_cls: 0.0000\nElapsed [3:53:14], Iteration [7400/30000], Dataset [1], D/loss_real: -3.3807, D/loss_fake: 0.6078, D/loss_cls: 1.4098, D/loss_gp: 0.0279, G/loss_fake: -1.9227, G/loss_rec: 0.1713, G/loss_cls: 1.1497\nElapsed [3:53:15], Iteration [7400/30000], Dataset [2], D/loss_real: -4.2622, D/loss_fake: 2.0792, D/loss_cls: 1.0916, D/loss_gp: 0.0240, G/loss_fake: -2.1002, G/loss_rec: 0.1724, G/loss_cls: 0.4971\nElapsed [3:53:17], Iteration [7400/30000], Dataset [3], D/loss_real: -4.2136, D/loss_fake: 2.7991, D/loss_cls: 0.0002, D/loss_gp: 0.0118, G/loss_fake: -4.5080, G/loss_rec: 0.1191, G/loss_cls: 0.0007\nElapsed [3:56:23], Iteration [7500/30000], Dataset [1], D/loss_real: -0.4551, D/loss_fake: -4.8277, D/loss_cls: 3.1004, D/loss_gp: 0.0998, G/loss_fake: -3.8141, G/loss_rec: 0.1920, G/loss_cls: 1.5027\nElapsed [3:56:24], Iteration [7500/30000], Dataset [2], D/loss_real: -9.8823, D/loss_fake: 6.5990, D/loss_cls: 1.2529, D/loss_gp: 0.0222, G/loss_fake: -6.5616, G/loss_rec: 0.1726, G/loss_cls: 0.6318\nElapsed [3:56:26], Iteration [7500/30000], Dataset [3], D/loss_real: -15.3522, D/loss_fake: 13.8848, D/loss_cls: 0.0009, D/loss_gp: 0.0425, G/loss_fake: -11.8640, G/loss_rec: 0.1170, G/loss_cls: 0.0833\nElapsed [3:59:32], Iteration [7600/30000], Dataset [1], D/loss_real: -13.5286, D/loss_fake: 10.1914, D/loss_cls: 1.2256, D/loss_gp: 0.0478, G/loss_fake: -10.1014, G/loss_rec: 0.1874, G/loss_cls: 0.8501\nElapsed [3:59:33], Iteration [7600/30000], Dataset [2], D/loss_real: -11.3315, D/loss_fake: 8.9769, D/loss_cls: 0.8497, D/loss_gp: 0.0362, G/loss_fake: -7.6661, G/loss_rec: 0.1802, G/loss_cls: 0.3237\nElapsed [3:59:35], Iteration [7600/30000], Dataset [3], D/loss_real: -12.7945, D/loss_fake: 12.2767, D/loss_cls: 0.0000, D/loss_gp: 0.0230, G/loss_fake: -8.2588, G/loss_rec: 0.1184, G/loss_cls: 0.0000\nElapsed [4:02:41], Iteration [7700/30000], Dataset [1], D/loss_real: -8.7875, D/loss_fake: 5.5705, D/loss_cls: 1.3815, D/loss_gp: 0.0387, G/loss_fake: -2.6490, G/loss_rec: 0.1691, G/loss_cls: 1.1359\nElapsed [4:02:42], Iteration [7700/30000], Dataset [2], D/loss_real: -8.6981, D/loss_fake: 6.1840, D/loss_cls: 0.7099, D/loss_gp: 0.0229, G/loss_fake: -5.4955, G/loss_rec: 0.1718, G/loss_cls: 0.5325\nElapsed [4:02:44], Iteration [7700/30000], Dataset [3], D/loss_real: -5.1714, D/loss_fake: 3.0635, D/loss_cls: 0.0001, D/loss_gp: 0.0196, G/loss_fake: -2.7268, G/loss_rec: 0.1193, G/loss_cls: 0.0191\nElapsed [4:05:50], Iteration [7800/30000], Dataset [1], D/loss_real: -8.1614, D/loss_fake: 4.7009, D/loss_cls: 1.3634, D/loss_gp: 0.0201, G/loss_fake: -4.9174, G/loss_rec: 0.1734, G/loss_cls: 1.2424\nElapsed [4:05:52], Iteration [7800/30000], Dataset [2], D/loss_real: -8.2845, D/loss_fake: 6.1709, D/loss_cls: 0.9846, D/loss_gp: 0.0265, G/loss_fake: -6.1459, G/loss_rec: 0.1478, G/loss_cls: 0.4557\nElapsed [4:05:53], Iteration [7800/30000], Dataset [3], D/loss_real: -13.4172, D/loss_fake: 12.6235, D/loss_cls: 0.0096, D/loss_gp: 0.0334, G/loss_fake: -11.0711, G/loss_rec: 0.1106, G/loss_cls: 0.0010\nElapsed [4:08:59], Iteration [7900/30000], Dataset [1], D/loss_real: -9.5944, D/loss_fake: 5.4894, D/loss_cls: 1.4302, D/loss_gp: 0.0239, G/loss_fake: -6.7974, G/loss_rec: 0.1798, G/loss_cls: 1.3915\nElapsed [4:09:00], Iteration [7900/30000], Dataset [2], D/loss_real: -10.3155, D/loss_fake: 7.7592, D/loss_cls: 1.0330, D/loss_gp: 0.0321, G/loss_fake: -7.9925, G/loss_rec: 0.1632, G/loss_cls: 0.5839\nElapsed [4:09:02], Iteration [7900/30000], Dataset [3], D/loss_real: -7.7896, D/loss_fake: 6.1212, D/loss_cls: 0.0001, D/loss_gp: 0.0210, G/loss_fake: -4.8864, G/loss_rec: 0.1088, G/loss_cls: 0.0001\nElapsed [4:12:08], Iteration [8000/30000], Dataset [1], D/loss_real: -9.7393, D/loss_fake: 6.7674, D/loss_cls: 1.5171, D/loss_gp: 0.0274, G/loss_fake: -5.2533, G/loss_rec: 0.1719, G/loss_cls: 1.1921\nElapsed [4:12:09], Iteration [8000/30000], Dataset [2], D/loss_real: -8.6031, D/loss_fake: 6.8016, D/loss_cls: 0.9160, D/loss_gp: 0.0173, G/loss_fake: -6.6539, G/loss_rec: 0.1573, G/loss_cls: 0.5552\nElapsed [4:12:11], Iteration [8000/30000], Dataset [3], D/loss_real: -10.3766, D/loss_fake: 8.9933, D/loss_cls: 0.0007, D/loss_gp: 0.0065, G/loss_fake: -9.3366, G/loss_rec: 0.1117, G/loss_cls: 0.0004\nSaved real and fake images into /kaggle/working/exps/visualization/8000...\nSaved model checkpoints at iteration 8000 into /kaggle/working/exps/checkpoints...\nElapsed [4:15:19], Iteration [8100/30000], Dataset [1], D/loss_real: -8.3108, D/loss_fake: 5.2968, D/loss_cls: 1.2943, D/loss_gp: 0.0251, G/loss_fake: -6.4175, G/loss_rec: 0.1822, G/loss_cls: 0.9190\nElapsed [4:15:20], Iteration [8100/30000], Dataset [2], D/loss_real: -9.4896, D/loss_fake: 6.1980, D/loss_cls: 0.8460, D/loss_gp: 0.0174, G/loss_fake: -7.2955, G/loss_rec: 0.1723, G/loss_cls: 0.4035\nElapsed [4:15:22], Iteration [8100/30000], Dataset [3], D/loss_real: -9.0513, D/loss_fake: 8.7917, D/loss_cls: 0.0000, D/loss_gp: 0.0085, G/loss_fake: -6.6658, G/loss_rec: 0.1116, G/loss_cls: 0.0051\nElapsed [4:18:28], Iteration [8200/30000], Dataset [1], D/loss_real: -7.9205, D/loss_fake: 3.7781, D/loss_cls: 1.1519, D/loss_gp: 0.0287, G/loss_fake: -2.7013, G/loss_rec: 0.1905, G/loss_cls: 0.9518\nElapsed [4:18:29], Iteration [8200/30000], Dataset [2], D/loss_real: -7.1312, D/loss_fake: 4.5148, D/loss_cls: 0.7684, D/loss_gp: 0.0422, G/loss_fake: -1.2931, G/loss_rec: 0.1756, G/loss_cls: 0.5092\nElapsed [4:18:31], Iteration [8200/30000], Dataset [3], D/loss_real: -10.6309, D/loss_fake: 9.1314, D/loss_cls: 0.0000, D/loss_gp: 0.0229, G/loss_fake: -5.0271, G/loss_rec: 0.1207, G/loss_cls: 0.0054\nElapsed [4:21:37], Iteration [8300/30000], Dataset [1], D/loss_real: -1.7990, D/loss_fake: -2.6289, D/loss_cls: 1.4160, D/loss_gp: 0.0371, G/loss_fake: 1.9765, G/loss_rec: 0.2062, G/loss_cls: 1.3709\nElapsed [4:21:38], Iteration [8300/30000], Dataset [2], D/loss_real: -3.6647, D/loss_fake: 0.1370, D/loss_cls: 0.8143, D/loss_gp: 0.0689, G/loss_fake: -4.8058, G/loss_rec: 0.1765, G/loss_cls: 0.4897\nElapsed [4:21:40], Iteration [8300/30000], Dataset [3], D/loss_real: -10.0910, D/loss_fake: 8.7490, D/loss_cls: 0.0002, D/loss_gp: 0.0175, G/loss_fake: -8.1655, G/loss_rec: 0.1156, G/loss_cls: 0.0023\nElapsed [4:24:46], Iteration [8400/30000], Dataset [1], D/loss_real: -4.4065, D/loss_fake: 1.6075, D/loss_cls: 1.5097, D/loss_gp: 0.0157, G/loss_fake: -0.4141, G/loss_rec: 0.1833, G/loss_cls: 1.0103\nElapsed [4:24:47], Iteration [8400/30000], Dataset [2], D/loss_real: -3.4528, D/loss_fake: 1.7079, D/loss_cls: 0.7541, D/loss_gp: 0.0068, G/loss_fake: -0.7558, G/loss_rec: 0.1667, G/loss_cls: 0.4627\nElapsed [4:24:49], Iteration [8400/30000], Dataset [3], D/loss_real: -4.2644, D/loss_fake: 2.9616, D/loss_cls: 0.0000, D/loss_gp: 0.0102, G/loss_fake: -1.4790, G/loss_rec: 0.1082, G/loss_cls: 0.0000\nElapsed [4:27:55], Iteration [8500/30000], Dataset [1], D/loss_real: -6.4414, D/loss_fake: 2.5494, D/loss_cls: 2.6740, D/loss_gp: 0.0353, G/loss_fake: -4.0668, G/loss_rec: 0.1793, G/loss_cls: 1.4850\nElapsed [4:27:56], Iteration [8500/30000], Dataset [2], D/loss_real: -9.7259, D/loss_fake: 6.4936, D/loss_cls: 0.7364, D/loss_gp: 0.0246, G/loss_fake: -6.5845, G/loss_rec: 0.1739, G/loss_cls: 0.2729\nElapsed [4:27:58], Iteration [8500/30000], Dataset [3], D/loss_real: -9.4756, D/loss_fake: 7.3833, D/loss_cls: 0.0170, D/loss_gp: 0.0255, G/loss_fake: -6.5284, G/loss_rec: 0.1055, G/loss_cls: 0.0141\nElapsed [4:31:04], Iteration [8600/30000], Dataset [1], D/loss_real: -4.7238, D/loss_fake: 0.8525, D/loss_cls: 1.4337, D/loss_gp: 0.0232, G/loss_fake: -0.4243, G/loss_rec: 0.1851, G/loss_cls: 0.9187\nElapsed [4:31:05], Iteration [8600/30000], Dataset [2], D/loss_real: -3.7869, D/loss_fake: 0.9643, D/loss_cls: 0.7734, D/loss_gp: 0.0351, G/loss_fake: -0.4717, G/loss_rec: 0.1597, G/loss_cls: 0.3132\nElapsed [4:31:07], Iteration [8600/30000], Dataset [3], D/loss_real: -5.4843, D/loss_fake: 3.0877, D/loss_cls: 0.0001, D/loss_gp: 0.0177, G/loss_fake: -3.1683, G/loss_rec: 0.1166, G/loss_cls: 0.0623\nElapsed [4:34:13], Iteration [8700/30000], Dataset [1], D/loss_real: -5.8136, D/loss_fake: 2.5462, D/loss_cls: 1.0907, D/loss_gp: 0.0326, G/loss_fake: -3.2690, G/loss_rec: 0.1618, G/loss_cls: 1.3583\nElapsed [4:34:14], Iteration [8700/30000], Dataset [2], D/loss_real: -7.4603, D/loss_fake: 4.3211, D/loss_cls: 0.6093, D/loss_gp: 0.0398, G/loss_fake: -3.7183, G/loss_rec: 0.1568, G/loss_cls: 0.3651\nElapsed [4:34:16], Iteration [8700/30000], Dataset [3], D/loss_real: -5.0949, D/loss_fake: 3.2104, D/loss_cls: 0.0000, D/loss_gp: 0.0054, G/loss_fake: -2.8042, G/loss_rec: 0.1175, G/loss_cls: 0.0002\nElapsed [4:37:22], Iteration [8800/30000], Dataset [1], D/loss_real: -15.4382, D/loss_fake: 9.8551, D/loss_cls: 1.9089, D/loss_gp: 0.0351, G/loss_fake: -6.9040, G/loss_rec: 0.1960, G/loss_cls: 1.2053\nElapsed [4:37:23], Iteration [8800/30000], Dataset [2], D/loss_real: -10.3899, D/loss_fake: 6.9868, D/loss_cls: 2.6117, D/loss_gp: 0.0383, G/loss_fake: -5.4735, G/loss_rec: 0.1714, G/loss_cls: 0.5923\nElapsed [4:37:25], Iteration [8800/30000], Dataset [3], D/loss_real: -3.3453, D/loss_fake: 2.5652, D/loss_cls: 0.0000, D/loss_gp: 0.0061, G/loss_fake: -3.8506, G/loss_rec: 0.1141, G/loss_cls: 0.0050\nElapsed [4:40:31], Iteration [8900/30000], Dataset [1], D/loss_real: -7.2272, D/loss_fake: 3.2237, D/loss_cls: 1.7362, D/loss_gp: 0.0337, G/loss_fake: -2.3286, G/loss_rec: 0.1827, G/loss_cls: 1.1156\nElapsed [4:40:32], Iteration [8900/30000], Dataset [2], D/loss_real: -6.4475, D/loss_fake: 3.5219, D/loss_cls: 0.6706, D/loss_gp: 0.0748, G/loss_fake: -3.7228, G/loss_rec: 0.1751, G/loss_cls: 0.5210\nElapsed [4:40:34], Iteration [8900/30000], Dataset [3], D/loss_real: -9.3840, D/loss_fake: 7.7515, D/loss_cls: 0.0014, D/loss_gp: 0.0122, G/loss_fake: -9.1914, G/loss_rec: 0.1066, G/loss_cls: 0.0026\nElapsed [4:43:40], Iteration [9000/30000], Dataset [1], D/loss_real: -9.1090, D/loss_fake: 5.6353, D/loss_cls: 1.0402, D/loss_gp: 0.0277, G/loss_fake: -5.3854, G/loss_rec: 0.1784, G/loss_cls: 1.2521\nElapsed [4:43:41], Iteration [9000/30000], Dataset [2], D/loss_real: -9.0863, D/loss_fake: 6.7850, D/loss_cls: 0.9274, D/loss_gp: 0.0291, G/loss_fake: -4.9728, G/loss_rec: 0.1626, G/loss_cls: 0.3607\nElapsed [4:43:43], Iteration [9000/30000], Dataset [3], D/loss_real: -7.2405, D/loss_fake: 5.4551, D/loss_cls: 0.0002, D/loss_gp: 0.0111, G/loss_fake: -4.1913, G/loss_rec: 0.1123, G/loss_cls: 0.0023\nElapsed [4:46:49], Iteration [9100/30000], Dataset [1], D/loss_real: -4.1724, D/loss_fake: 0.7451, D/loss_cls: 1.3344, D/loss_gp: 0.0251, G/loss_fake: -0.7750, G/loss_rec: 0.1606, G/loss_cls: 1.0878\nElapsed [4:46:50], Iteration [9100/30000], Dataset [2], D/loss_real: -4.8252, D/loss_fake: 1.7068, D/loss_cls: 1.0863, D/loss_gp: 0.0249, G/loss_fake: -0.5529, G/loss_rec: 0.1667, G/loss_cls: 0.4077\nElapsed [4:46:52], Iteration [9100/30000], Dataset [3], D/loss_real: -5.7608, D/loss_fake: 4.3484, D/loss_cls: 0.0002, D/loss_gp: 0.0102, G/loss_fake: -1.5814, G/loss_rec: 0.1043, G/loss_cls: 0.0020\nElapsed [4:49:58], Iteration [9200/30000], Dataset [1], D/loss_real: -2.8213, D/loss_fake: 0.0450, D/loss_cls: 1.2241, D/loss_gp: 0.0192, G/loss_fake: 0.1009, G/loss_rec: 0.1585, G/loss_cls: 1.1671\nElapsed [4:49:59], Iteration [9200/30000], Dataset [2], D/loss_real: -3.0089, D/loss_fake: 0.0198, D/loss_cls: 0.8378, D/loss_gp: 0.0137, G/loss_fake: 1.2191, G/loss_rec: 0.1676, G/loss_cls: 0.3377\nElapsed [4:50:01], Iteration [9200/30000], Dataset [3], D/loss_real: -1.1181, D/loss_fake: -0.7992, D/loss_cls: 0.0000, D/loss_gp: 0.0145, G/loss_fake: 2.3264, G/loss_rec: 0.1062, G/loss_cls: 0.0014\nElapsed [4:53:07], Iteration [9300/30000], Dataset [1], D/loss_real: -6.5784, D/loss_fake: 2.4437, D/loss_cls: 1.7095, D/loss_gp: 0.0386, G/loss_fake: -0.8706, G/loss_rec: 0.1846, G/loss_cls: 1.3582\nElapsed [4:53:08], Iteration [9300/30000], Dataset [2], D/loss_real: -5.3616, D/loss_fake: 3.6918, D/loss_cls: 0.8852, D/loss_gp: 0.0262, G/loss_fake: -2.3704, G/loss_rec: 0.1553, G/loss_cls: 0.4612\nElapsed [4:53:10], Iteration [9300/30000], Dataset [3], D/loss_real: -10.5861, D/loss_fake: 9.7931, D/loss_cls: 0.0000, D/loss_gp: 0.0078, G/loss_fake: -8.9668, G/loss_rec: 0.1038, G/loss_cls: 0.0008\nElapsed [4:56:16], Iteration [9400/30000], Dataset [1], D/loss_real: -12.1434, D/loss_fake: 8.9676, D/loss_cls: 1.1400, D/loss_gp: 0.0374, G/loss_fake: -6.7507, G/loss_rec: 0.1809, G/loss_cls: 0.9892\nElapsed [4:56:17], Iteration [9400/30000], Dataset [2], D/loss_real: -9.3728, D/loss_fake: 7.6466, D/loss_cls: 0.5789, D/loss_gp: 0.0097, G/loss_fake: -6.1205, G/loss_rec: 0.1552, G/loss_cls: 0.2595\nElapsed [4:56:19], Iteration [9400/30000], Dataset [3], D/loss_real: -8.5619, D/loss_fake: 6.6722, D/loss_cls: 0.0000, D/loss_gp: 0.0123, G/loss_fake: -3.4086, G/loss_rec: 0.1073, G/loss_cls: 0.0020\nElapsed [4:59:25], Iteration [9500/30000], Dataset [1], D/loss_real: -5.9829, D/loss_fake: 2.8341, D/loss_cls: 1.1907, D/loss_gp: 0.0209, G/loss_fake: -2.6619, G/loss_rec: 0.1777, G/loss_cls: 1.3022\nElapsed [4:59:26], Iteration [9500/30000], Dataset [2], D/loss_real: -5.8230, D/loss_fake: 3.1410, D/loss_cls: 0.7790, D/loss_gp: 0.0291, G/loss_fake: -2.8766, G/loss_rec: 0.1711, G/loss_cls: 0.4872\nElapsed [4:59:28], Iteration [9500/30000], Dataset [3], D/loss_real: -6.6545, D/loss_fake: 5.1278, D/loss_cls: 0.0000, D/loss_gp: 0.0075, G/loss_fake: -4.9287, G/loss_rec: 0.1071, G/loss_cls: 0.0003\nElapsed [5:02:34], Iteration [9600/30000], Dataset [1], D/loss_real: -6.2684, D/loss_fake: 4.2597, D/loss_cls: 1.1537, D/loss_gp: 0.0235, G/loss_fake: -3.4670, G/loss_rec: 0.1720, G/loss_cls: 1.0848\nElapsed [5:02:35], Iteration [9600/30000], Dataset [2], D/loss_real: -6.1497, D/loss_fake: 3.8331, D/loss_cls: 0.7958, D/loss_gp: 0.0156, G/loss_fake: -3.7606, G/loss_rec: 0.1552, G/loss_cls: 0.6184\nElapsed [5:02:37], Iteration [9600/30000], Dataset [3], D/loss_real: -6.1983, D/loss_fake: 4.5292, D/loss_cls: 0.1166, D/loss_gp: 0.0073, G/loss_fake: -4.0756, G/loss_rec: 0.1196, G/loss_cls: 0.0002\nElapsed [5:05:43], Iteration [9700/30000], Dataset [1], D/loss_real: -3.8809, D/loss_fake: -0.0208, D/loss_cls: 1.2000, D/loss_gp: 0.0076, G/loss_fake: -1.4278, G/loss_rec: 0.1749, G/loss_cls: 1.2631\nElapsed [5:05:44], Iteration [9700/30000], Dataset [2], D/loss_real: -8.8410, D/loss_fake: 5.9525, D/loss_cls: 0.9009, D/loss_gp: 0.0362, G/loss_fake: -4.7688, G/loss_rec: 0.1677, G/loss_cls: 0.5275\nElapsed [5:05:46], Iteration [9700/30000], Dataset [3], D/loss_real: -11.7453, D/loss_fake: 9.6167, D/loss_cls: 0.0001, D/loss_gp: 0.0150, G/loss_fake: -5.3998, G/loss_rec: 0.1083, G/loss_cls: 0.0125\nElapsed [5:08:52], Iteration [9800/30000], Dataset [1], D/loss_real: -4.3679, D/loss_fake: 1.4509, D/loss_cls: 1.0709, D/loss_gp: 0.0156, G/loss_fake: -2.5538, G/loss_rec: 0.1694, G/loss_cls: 0.9023\nElapsed [5:08:53], Iteration [9800/30000], Dataset [2], D/loss_real: -5.4940, D/loss_fake: 3.4348, D/loss_cls: 0.8836, D/loss_gp: 0.0339, G/loss_fake: -2.0904, G/loss_rec: 0.1554, G/loss_cls: 0.4029\nElapsed [5:08:55], Iteration [9800/30000], Dataset [3], D/loss_real: -5.9440, D/loss_fake: 4.7001, D/loss_cls: 0.0010, D/loss_gp: 0.0326, G/loss_fake: -2.4053, G/loss_rec: 0.1107, G/loss_cls: 0.0001\nElapsed [5:12:01], Iteration [9900/30000], Dataset [1], D/loss_real: -14.1245, D/loss_fake: 8.6269, D/loss_cls: 1.8095, D/loss_gp: 0.0786, G/loss_fake: -8.1083, G/loss_rec: 0.2023, G/loss_cls: 1.4306\nElapsed [5:12:03], Iteration [9900/30000], Dataset [2], D/loss_real: -14.5327, D/loss_fake: 9.6896, D/loss_cls: 1.1397, D/loss_gp: 0.0210, G/loss_fake: -9.0559, G/loss_rec: 0.1723, G/loss_cls: 0.4895\nElapsed [5:12:04], Iteration [9900/30000], Dataset [3], D/loss_real: -7.4050, D/loss_fake: 4.9334, D/loss_cls: 0.0000, D/loss_gp: 0.0215, G/loss_fake: -4.6142, G/loss_rec: 0.0978, G/loss_cls: 0.0000\nElapsed [5:15:10], Iteration [10000/30000], Dataset [1], D/loss_real: -13.3219, D/loss_fake: 8.2412, D/loss_cls: 1.5664, D/loss_gp: 0.0257, G/loss_fake: -9.7949, G/loss_rec: 0.1789, G/loss_cls: 1.0635\nElapsed [5:15:12], Iteration [10000/30000], Dataset [2], D/loss_real: -15.3705, D/loss_fake: 12.0102, D/loss_cls: 1.1973, D/loss_gp: 0.0385, G/loss_fake: -8.4626, G/loss_rec: 0.1697, G/loss_cls: 0.3573\nElapsed [5:15:13], Iteration [10000/30000], Dataset [3], D/loss_real: -5.3364, D/loss_fake: 4.2487, D/loss_cls: 0.0010, D/loss_gp: 0.0248, G/loss_fake: -1.1666, G/loss_rec: 0.1096, G/loss_cls: 0.0328\nSaved real and fake images into /kaggle/working/exps/visualization/10000...\nSaved model checkpoints at iteration 10000 into /kaggle/working/exps/checkpoints...\nDecayed learning rates, g_lr: 0.00010000, d_lr: 0.00010000.\nDecayed learning rates, g_lr: 0.00009999, d_lr: 0.00009999.\nDecayed learning rates, g_lr: 0.00009999, d_lr: 0.00009999.\nDecayed learning rates, g_lr: 0.00009998, d_lr: 0.00009998.\nDecayed learning rates, g_lr: 0.00009998, d_lr: 0.00009998.\nDecayed learning rates, g_lr: 0.00009997, d_lr: 0.00009997.\nDecayed learning rates, g_lr: 0.00009997, d_lr: 0.00009997.\nDecayed learning rates, g_lr: 0.00009996, d_lr: 0.00009996.\nDecayed learning rates, g_lr: 0.00009996, d_lr: 0.00009996.\nElapsed [5:18:22], Iteration [10100/30000], Dataset [1], D/loss_real: -4.1943, D/loss_fake: 1.6991, D/loss_cls: 1.5226, D/loss_gp: 0.0190, G/loss_fake: -1.9239, G/loss_rec: 0.1745, G/loss_cls: 0.9405\nElapsed [5:18:23], Iteration [10100/30000], Dataset [2], D/loss_real: -5.1774, D/loss_fake: 2.9698, D/loss_cls: 0.7093, D/loss_gp: 0.0113, G/loss_fake: -3.5041, G/loss_rec: 0.1668, G/loss_cls: 0.3067\nElapsed [5:18:24], Iteration [10100/30000], Dataset [3], D/loss_real: -2.8494, D/loss_fake: 1.0006, D/loss_cls: 0.0000, D/loss_gp: 0.0060, G/loss_fake: -2.1517, G/loss_rec: 0.1083, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009995, d_lr: 0.00009995.\nDecayed learning rates, g_lr: 0.00009995, d_lr: 0.00009995.\nDecayed learning rates, g_lr: 0.00009994, d_lr: 0.00009994.\nDecayed learning rates, g_lr: 0.00009994, d_lr: 0.00009994.\nDecayed learning rates, g_lr: 0.00009993, d_lr: 0.00009993.\nDecayed learning rates, g_lr: 0.00009993, d_lr: 0.00009993.\nDecayed learning rates, g_lr: 0.00009992, d_lr: 0.00009992.\nDecayed learning rates, g_lr: 0.00009992, d_lr: 0.00009992.\nDecayed learning rates, g_lr: 0.00009991, d_lr: 0.00009991.\nDecayed learning rates, g_lr: 0.00009991, d_lr: 0.00009991.\nElapsed [5:21:31], Iteration [10200/30000], Dataset [1], D/loss_real: -2.4063, D/loss_fake: -0.8638, D/loss_cls: 1.1094, D/loss_gp: 0.0337, G/loss_fake: 1.2432, G/loss_rec: 0.1600, G/loss_cls: 0.9524\nElapsed [5:21:32], Iteration [10200/30000], Dataset [2], D/loss_real: -4.0007, D/loss_fake: 1.4565, D/loss_cls: 0.9054, D/loss_gp: 0.0128, G/loss_fake: -1.6704, G/loss_rec: 0.1587, G/loss_cls: 0.4305\nElapsed [5:21:33], Iteration [10200/30000], Dataset [3], D/loss_real: -8.4402, D/loss_fake: 6.1296, D/loss_cls: 0.0006, D/loss_gp: 0.0070, G/loss_fake: -5.9358, G/loss_rec: 0.1097, G/loss_cls: 0.0013\nDecayed learning rates, g_lr: 0.00009990, d_lr: 0.00009990.\nDecayed learning rates, g_lr: 0.00009990, d_lr: 0.00009990.\nDecayed learning rates, g_lr: 0.00009989, d_lr: 0.00009989.\nDecayed learning rates, g_lr: 0.00009989, d_lr: 0.00009989.\nDecayed learning rates, g_lr: 0.00009988, d_lr: 0.00009988.\nDecayed learning rates, g_lr: 0.00009988, d_lr: 0.00009988.\nDecayed learning rates, g_lr: 0.00009987, d_lr: 0.00009987.\nDecayed learning rates, g_lr: 0.00009987, d_lr: 0.00009987.\nDecayed learning rates, g_lr: 0.00009986, d_lr: 0.00009986.\nDecayed learning rates, g_lr: 0.00009986, d_lr: 0.00009986.\nElapsed [5:24:40], Iteration [10300/30000], Dataset [1], D/loss_real: -9.1498, D/loss_fake: 5.9783, D/loss_cls: 1.3108, D/loss_gp: 0.0385, G/loss_fake: -3.2780, G/loss_rec: 0.1653, G/loss_cls: 0.8600\nElapsed [5:24:41], Iteration [10300/30000], Dataset [2], D/loss_real: -9.2570, D/loss_fake: 5.4283, D/loss_cls: 0.6191, D/loss_gp: 0.0377, G/loss_fake: -5.0930, G/loss_rec: 0.1813, G/loss_cls: 0.4434\nElapsed [5:24:43], Iteration [10300/30000], Dataset [3], D/loss_real: -3.1023, D/loss_fake: 1.2824, D/loss_cls: 0.0001, D/loss_gp: 0.0213, G/loss_fake: -2.3443, G/loss_rec: 0.1099, G/loss_cls: 0.0006\nDecayed learning rates, g_lr: 0.00009985, d_lr: 0.00009985.\nDecayed learning rates, g_lr: 0.00009985, d_lr: 0.00009985.\nDecayed learning rates, g_lr: 0.00009984, d_lr: 0.00009984.\nDecayed learning rates, g_lr: 0.00009984, d_lr: 0.00009984.\nDecayed learning rates, g_lr: 0.00009983, d_lr: 0.00009983.\nDecayed learning rates, g_lr: 0.00009983, d_lr: 0.00009983.\nDecayed learning rates, g_lr: 0.00009982, d_lr: 0.00009982.\nDecayed learning rates, g_lr: 0.00009982, d_lr: 0.00009982.\nDecayed learning rates, g_lr: 0.00009981, d_lr: 0.00009981.\nDecayed learning rates, g_lr: 0.00009981, d_lr: 0.00009981.\nElapsed [5:27:49], Iteration [10400/30000], Dataset [1], D/loss_real: -5.3311, D/loss_fake: 0.8422, D/loss_cls: 1.1125, D/loss_gp: 0.0418, G/loss_fake: 0.1409, G/loss_rec: 0.1902, G/loss_cls: 1.3245\nElapsed [5:27:50], Iteration [10400/30000], Dataset [2], D/loss_real: -4.4868, D/loss_fake: 1.0121, D/loss_cls: 0.7732, D/loss_gp: 0.0689, G/loss_fake: -0.8263, G/loss_rec: 0.1653, G/loss_cls: 0.2933\nElapsed [5:27:52], Iteration [10400/30000], Dataset [3], D/loss_real: 1.8286, D/loss_fake: -3.3565, D/loss_cls: 0.0001, D/loss_gp: 0.0177, G/loss_fake: 1.8744, G/loss_rec: 0.0986, G/loss_cls: 0.0008\nDecayed learning rates, g_lr: 0.00009980, d_lr: 0.00009980.\nDecayed learning rates, g_lr: 0.00009980, d_lr: 0.00009980.\nDecayed learning rates, g_lr: 0.00009979, d_lr: 0.00009979.\nDecayed learning rates, g_lr: 0.00009979, d_lr: 0.00009979.\nDecayed learning rates, g_lr: 0.00009978, d_lr: 0.00009978.\nDecayed learning rates, g_lr: 0.00009978, d_lr: 0.00009978.\nDecayed learning rates, g_lr: 0.00009977, d_lr: 0.00009977.\nDecayed learning rates, g_lr: 0.00009977, d_lr: 0.00009977.\nDecayed learning rates, g_lr: 0.00009976, d_lr: 0.00009976.\nDecayed learning rates, g_lr: 0.00009976, d_lr: 0.00009976.\nElapsed [5:30:58], Iteration [10500/30000], Dataset [1], D/loss_real: -4.2623, D/loss_fake: 1.2072, D/loss_cls: 1.1837, D/loss_gp: 0.0322, G/loss_fake: -1.2360, G/loss_rec: 0.1693, G/loss_cls: 1.0030\nElapsed [5:31:00], Iteration [10500/30000], Dataset [2], D/loss_real: -4.2818, D/loss_fake: 1.5957, D/loss_cls: 0.7656, D/loss_gp: 0.0333, G/loss_fake: -2.6188, G/loss_rec: 0.1637, G/loss_cls: 0.3619\nElapsed [5:31:01], Iteration [10500/30000], Dataset [3], D/loss_real: -1.3911, D/loss_fake: 0.0584, D/loss_cls: 0.0249, D/loss_gp: 0.0118, G/loss_fake: -0.3050, G/loss_rec: 0.1000, G/loss_cls: 0.0812\nDecayed learning rates, g_lr: 0.00009975, d_lr: 0.00009975.\nDecayed learning rates, g_lr: 0.00009975, d_lr: 0.00009975.\nDecayed learning rates, g_lr: 0.00009974, d_lr: 0.00009974.\nDecayed learning rates, g_lr: 0.00009974, d_lr: 0.00009974.\nDecayed learning rates, g_lr: 0.00009973, d_lr: 0.00009973.\nDecayed learning rates, g_lr: 0.00009973, d_lr: 0.00009973.\nDecayed learning rates, g_lr: 0.00009972, d_lr: 0.00009972.\nDecayed learning rates, g_lr: 0.00009972, d_lr: 0.00009972.\nDecayed learning rates, g_lr: 0.00009971, d_lr: 0.00009971.\nDecayed learning rates, g_lr: 0.00009971, d_lr: 0.00009971.\nElapsed [5:34:08], Iteration [10600/30000], Dataset [1], D/loss_real: -4.6641, D/loss_fake: 2.4800, D/loss_cls: 1.3924, D/loss_gp: 0.0246, G/loss_fake: -2.7988, G/loss_rec: 0.1628, G/loss_cls: 1.1327\nElapsed [5:34:09], Iteration [10600/30000], Dataset [2], D/loss_real: -5.7337, D/loss_fake: 4.0500, D/loss_cls: 0.7604, D/loss_gp: 0.0170, G/loss_fake: -2.8741, G/loss_rec: 0.1439, G/loss_cls: 0.4490\nElapsed [5:34:10], Iteration [10600/30000], Dataset [3], D/loss_real: -3.3579, D/loss_fake: 1.9989, D/loss_cls: 0.0008, D/loss_gp: 0.0074, G/loss_fake: -1.4892, G/loss_rec: 0.1018, G/loss_cls: 0.0049\nDecayed learning rates, g_lr: 0.00009970, d_lr: 0.00009970.\nDecayed learning rates, g_lr: 0.00009970, d_lr: 0.00009970.\nDecayed learning rates, g_lr: 0.00009969, d_lr: 0.00009969.\nDecayed learning rates, g_lr: 0.00009969, d_lr: 0.00009969.\nDecayed learning rates, g_lr: 0.00009968, d_lr: 0.00009968.\nDecayed learning rates, g_lr: 0.00009968, d_lr: 0.00009968.\nDecayed learning rates, g_lr: 0.00009967, d_lr: 0.00009967.\nDecayed learning rates, g_lr: 0.00009967, d_lr: 0.00009967.\nDecayed learning rates, g_lr: 0.00009966, d_lr: 0.00009966.\nDecayed learning rates, g_lr: 0.00009966, d_lr: 0.00009966.\nElapsed [5:37:17], Iteration [10700/30000], Dataset [1], D/loss_real: -3.8040, D/loss_fake: 1.9700, D/loss_cls: 1.3763, D/loss_gp: 0.0108, G/loss_fake: -2.0147, G/loss_rec: 0.1560, G/loss_cls: 0.8142\nElapsed [5:37:18], Iteration [10700/30000], Dataset [2], D/loss_real: -4.1833, D/loss_fake: 2.4386, D/loss_cls: 0.9494, D/loss_gp: 0.0096, G/loss_fake: -2.6599, G/loss_rec: 0.1374, G/loss_cls: 0.5154\nElapsed [5:37:19], Iteration [10700/30000], Dataset [3], D/loss_real: -1.1641, D/loss_fake: -0.1463, D/loss_cls: 0.0002, D/loss_gp: 0.0098, G/loss_fake: 0.0933, G/loss_rec: 0.0968, G/loss_cls: 0.0902\nDecayed learning rates, g_lr: 0.00009965, d_lr: 0.00009965.\nDecayed learning rates, g_lr: 0.00009965, d_lr: 0.00009965.\nDecayed learning rates, g_lr: 0.00009964, d_lr: 0.00009964.\nDecayed learning rates, g_lr: 0.00009964, d_lr: 0.00009964.\nDecayed learning rates, g_lr: 0.00009963, d_lr: 0.00009963.\nDecayed learning rates, g_lr: 0.00009963, d_lr: 0.00009963.\nDecayed learning rates, g_lr: 0.00009962, d_lr: 0.00009962.\nDecayed learning rates, g_lr: 0.00009962, d_lr: 0.00009962.\nDecayed learning rates, g_lr: 0.00009961, d_lr: 0.00009961.\nDecayed learning rates, g_lr: 0.00009961, d_lr: 0.00009961.\nElapsed [5:40:26], Iteration [10800/30000], Dataset [1], D/loss_real: -4.2986, D/loss_fake: 1.8691, D/loss_cls: 1.1366, D/loss_gp: 0.0081, G/loss_fake: -2.2188, G/loss_rec: 0.1660, G/loss_cls: 1.0366\nElapsed [5:40:27], Iteration [10800/30000], Dataset [2], D/loss_real: -5.3061, D/loss_fake: 3.0761, D/loss_cls: 0.8962, D/loss_gp: 0.0145, G/loss_fake: -2.4275, G/loss_rec: 0.1617, G/loss_cls: 0.3906\nElapsed [5:40:29], Iteration [10800/30000], Dataset [3], D/loss_real: -4.0414, D/loss_fake: 2.1571, D/loss_cls: 0.0002, D/loss_gp: 0.0288, G/loss_fake: -0.9105, G/loss_rec: 0.1033, G/loss_cls: 0.0003\nDecayed learning rates, g_lr: 0.00009960, d_lr: 0.00009960.\nDecayed learning rates, g_lr: 0.00009960, d_lr: 0.00009960.\nDecayed learning rates, g_lr: 0.00009959, d_lr: 0.00009959.\nDecayed learning rates, g_lr: 0.00009959, d_lr: 0.00009959.\nDecayed learning rates, g_lr: 0.00009958, d_lr: 0.00009958.\nDecayed learning rates, g_lr: 0.00009958, d_lr: 0.00009958.\nDecayed learning rates, g_lr: 0.00009957, d_lr: 0.00009957.\nDecayed learning rates, g_lr: 0.00009957, d_lr: 0.00009957.\nDecayed learning rates, g_lr: 0.00009956, d_lr: 0.00009956.\nDecayed learning rates, g_lr: 0.00009956, d_lr: 0.00009956.\nElapsed [5:43:35], Iteration [10900/30000], Dataset [1], D/loss_real: -4.2903, D/loss_fake: 0.5625, D/loss_cls: 1.5040, D/loss_gp: 0.0545, G/loss_fake: -1.4030, G/loss_rec: 0.1667, G/loss_cls: 0.9408\nElapsed [5:43:36], Iteration [10900/30000], Dataset [2], D/loss_real: -5.8173, D/loss_fake: 2.7615, D/loss_cls: 0.8442, D/loss_gp: 0.0266, G/loss_fake: -2.6428, G/loss_rec: 0.1553, G/loss_cls: 0.4105\nElapsed [5:43:38], Iteration [10900/30000], Dataset [3], D/loss_real: -1.8540, D/loss_fake: 0.4123, D/loss_cls: 0.0005, D/loss_gp: 0.0079, G/loss_fake: -0.4824, G/loss_rec: 0.1030, G/loss_cls: 0.0393\nDecayed learning rates, g_lr: 0.00009955, d_lr: 0.00009955.\nDecayed learning rates, g_lr: 0.00009955, d_lr: 0.00009955.\nDecayed learning rates, g_lr: 0.00009954, d_lr: 0.00009954.\nDecayed learning rates, g_lr: 0.00009954, d_lr: 0.00009954.\nDecayed learning rates, g_lr: 0.00009953, d_lr: 0.00009953.\nDecayed learning rates, g_lr: 0.00009953, d_lr: 0.00009953.\nDecayed learning rates, g_lr: 0.00009952, d_lr: 0.00009952.\nDecayed learning rates, g_lr: 0.00009952, d_lr: 0.00009952.\nDecayed learning rates, g_lr: 0.00009951, d_lr: 0.00009951.\nDecayed learning rates, g_lr: 0.00009951, d_lr: 0.00009951.\nElapsed [5:46:44], Iteration [11000/30000], Dataset [1], D/loss_real: 0.8359, D/loss_fake: -4.3360, D/loss_cls: 1.3457, D/loss_gp: 0.0227, G/loss_fake: 3.7075, G/loss_rec: 0.1880, G/loss_cls: 0.9476\nElapsed [5:46:45], Iteration [11000/30000], Dataset [2], D/loss_real: -0.0676, D/loss_fake: -2.5046, D/loss_cls: 0.8688, D/loss_gp: 0.0151, G/loss_fake: 1.2750, G/loss_rec: 0.1646, G/loss_cls: 0.2555\nElapsed [5:46:46], Iteration [11000/30000], Dataset [3], D/loss_real: -6.1015, D/loss_fake: 3.4890, D/loss_cls: 0.0013, D/loss_gp: 0.0275, G/loss_fake: -3.6606, G/loss_rec: 0.1091, G/loss_cls: 0.0049\nDecayed learning rates, g_lr: 0.00009950, d_lr: 0.00009950.\nDecayed learning rates, g_lr: 0.00009950, d_lr: 0.00009950.\nDecayed learning rates, g_lr: 0.00009949, d_lr: 0.00009949.\nDecayed learning rates, g_lr: 0.00009949, d_lr: 0.00009949.\nDecayed learning rates, g_lr: 0.00009948, d_lr: 0.00009948.\nDecayed learning rates, g_lr: 0.00009948, d_lr: 0.00009948.\nDecayed learning rates, g_lr: 0.00009947, d_lr: 0.00009947.\nDecayed learning rates, g_lr: 0.00009947, d_lr: 0.00009947.\nDecayed learning rates, g_lr: 0.00009946, d_lr: 0.00009946.\nDecayed learning rates, g_lr: 0.00009946, d_lr: 0.00009946.\nElapsed [5:49:53], Iteration [11100/30000], Dataset [1], D/loss_real: -2.7564, D/loss_fake: 0.1384, D/loss_cls: 1.3031, D/loss_gp: 0.0525, G/loss_fake: 0.5017, G/loss_rec: 0.1572, G/loss_cls: 0.9562\nElapsed [5:49:54], Iteration [11100/30000], Dataset [2], D/loss_real: -2.8769, D/loss_fake: 0.3603, D/loss_cls: 0.7278, D/loss_gp: 0.0215, G/loss_fake: -0.6235, G/loss_rec: 0.1650, G/loss_cls: 0.4378\nElapsed [5:49:56], Iteration [11100/30000], Dataset [3], D/loss_real: -1.7285, D/loss_fake: 0.4020, D/loss_cls: 0.0000, D/loss_gp: 0.0058, G/loss_fake: -1.0244, G/loss_rec: 0.1113, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009945, d_lr: 0.00009945.\nDecayed learning rates, g_lr: 0.00009945, d_lr: 0.00009945.\nDecayed learning rates, g_lr: 0.00009944, d_lr: 0.00009944.\nDecayed learning rates, g_lr: 0.00009944, d_lr: 0.00009944.\nDecayed learning rates, g_lr: 0.00009943, d_lr: 0.00009943.\nDecayed learning rates, g_lr: 0.00009943, d_lr: 0.00009943.\nDecayed learning rates, g_lr: 0.00009942, d_lr: 0.00009942.\nDecayed learning rates, g_lr: 0.00009942, d_lr: 0.00009942.\nDecayed learning rates, g_lr: 0.00009941, d_lr: 0.00009941.\nDecayed learning rates, g_lr: 0.00009941, d_lr: 0.00009941.\nElapsed [5:53:02], Iteration [11200/30000], Dataset [1], D/loss_real: -7.2091, D/loss_fake: 3.9829, D/loss_cls: 1.2186, D/loss_gp: 0.0508, G/loss_fake: -4.3820, G/loss_rec: 0.1709, G/loss_cls: 0.9648\nElapsed [5:53:03], Iteration [11200/30000], Dataset [2], D/loss_real: -7.2622, D/loss_fake: 4.8241, D/loss_cls: 0.7362, D/loss_gp: 0.0199, G/loss_fake: -5.2401, G/loss_rec: 0.1495, G/loss_cls: 0.3977\nElapsed [5:53:05], Iteration [11200/30000], Dataset [3], D/loss_real: -4.4299, D/loss_fake: 3.2141, D/loss_cls: 0.0000, D/loss_gp: 0.0042, G/loss_fake: -2.7905, G/loss_rec: 0.0998, G/loss_cls: 0.0003\nDecayed learning rates, g_lr: 0.00009940, d_lr: 0.00009940.\nDecayed learning rates, g_lr: 0.00009940, d_lr: 0.00009940.\nDecayed learning rates, g_lr: 0.00009939, d_lr: 0.00009939.\nDecayed learning rates, g_lr: 0.00009939, d_lr: 0.00009939.\nDecayed learning rates, g_lr: 0.00009938, d_lr: 0.00009938.\nDecayed learning rates, g_lr: 0.00009938, d_lr: 0.00009938.\nDecayed learning rates, g_lr: 0.00009937, d_lr: 0.00009937.\nDecayed learning rates, g_lr: 0.00009937, d_lr: 0.00009937.\nDecayed learning rates, g_lr: 0.00009936, d_lr: 0.00009936.\nDecayed learning rates, g_lr: 0.00009936, d_lr: 0.00009936.\nElapsed [5:56:11], Iteration [11300/30000], Dataset [1], D/loss_real: 7.8384, D/loss_fake: -12.2528, D/loss_cls: 1.5750, D/loss_gp: 0.0324, G/loss_fake: 13.5557, G/loss_rec: 0.1829, G/loss_cls: 1.8420\nElapsed [5:56:13], Iteration [11300/30000], Dataset [2], D/loss_real: 8.0546, D/loss_fake: -11.0373, D/loss_cls: 1.2103, D/loss_gp: 0.0411, G/loss_fake: 5.7575, G/loss_rec: 0.1711, G/loss_cls: 0.8216\nElapsed [5:56:14], Iteration [11300/30000], Dataset [3], D/loss_real: -1.1274, D/loss_fake: -0.0874, D/loss_cls: 0.0001, D/loss_gp: 0.0108, G/loss_fake: -0.6117, G/loss_rec: 0.1019, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009935, d_lr: 0.00009935.\nDecayed learning rates, g_lr: 0.00009935, d_lr: 0.00009935.\nDecayed learning rates, g_lr: 0.00009934, d_lr: 0.00009934.\nDecayed learning rates, g_lr: 0.00009934, d_lr: 0.00009934.\nDecayed learning rates, g_lr: 0.00009933, d_lr: 0.00009933.\nDecayed learning rates, g_lr: 0.00009933, d_lr: 0.00009933.\nDecayed learning rates, g_lr: 0.00009932, d_lr: 0.00009932.\nDecayed learning rates, g_lr: 0.00009932, d_lr: 0.00009932.\nDecayed learning rates, g_lr: 0.00009931, d_lr: 0.00009931.\nDecayed learning rates, g_lr: 0.00009931, d_lr: 0.00009931.\nElapsed [5:59:20], Iteration [11400/30000], Dataset [1], D/loss_real: -2.6000, D/loss_fake: -0.3382, D/loss_cls: 0.9095, D/loss_gp: 0.0300, G/loss_fake: -0.2113, G/loss_rec: 0.1653, G/loss_cls: 0.6846\nElapsed [5:59:22], Iteration [11400/30000], Dataset [2], D/loss_real: -3.4592, D/loss_fake: 1.5455, D/loss_cls: 0.8310, D/loss_gp: 0.0252, G/loss_fake: -1.4901, G/loss_rec: 0.1431, G/loss_cls: 0.4422\nElapsed [5:59:23], Iteration [11400/30000], Dataset [3], D/loss_real: -0.1670, D/loss_fake: -0.6029, D/loss_cls: 0.0000, D/loss_gp: 0.0099, G/loss_fake: 0.5416, G/loss_rec: 0.0945, G/loss_cls: 0.0006\nDecayed learning rates, g_lr: 0.00009930, d_lr: 0.00009930.\nDecayed learning rates, g_lr: 0.00009930, d_lr: 0.00009930.\nDecayed learning rates, g_lr: 0.00009929, d_lr: 0.00009929.\nDecayed learning rates, g_lr: 0.00009929, d_lr: 0.00009929.\nDecayed learning rates, g_lr: 0.00009928, d_lr: 0.00009928.\nDecayed learning rates, g_lr: 0.00009928, d_lr: 0.00009928.\nDecayed learning rates, g_lr: 0.00009927, d_lr: 0.00009927.\nDecayed learning rates, g_lr: 0.00009927, d_lr: 0.00009927.\nDecayed learning rates, g_lr: 0.00009926, d_lr: 0.00009926.\nDecayed learning rates, g_lr: 0.00009926, d_lr: 0.00009926.\nElapsed [6:02:29], Iteration [11500/30000], Dataset [1], D/loss_real: -4.9047, D/loss_fake: 2.5913, D/loss_cls: 1.2854, D/loss_gp: 0.0131, G/loss_fake: -2.1765, G/loss_rec: 0.1574, G/loss_cls: 0.9475\nElapsed [6:02:31], Iteration [11500/30000], Dataset [2], D/loss_real: -5.3131, D/loss_fake: 3.6225, D/loss_cls: 0.7671, D/loss_gp: 0.0127, G/loss_fake: -3.0409, G/loss_rec: 0.1453, G/loss_cls: 0.3837\nElapsed [6:02:32], Iteration [11500/30000], Dataset [3], D/loss_real: -7.2219, D/loss_fake: 5.8161, D/loss_cls: 0.0003, D/loss_gp: 0.0112, G/loss_fake: -4.6550, G/loss_rec: 0.0942, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009925, d_lr: 0.00009925.\nDecayed learning rates, g_lr: 0.00009925, d_lr: 0.00009925.\nDecayed learning rates, g_lr: 0.00009924, d_lr: 0.00009924.\nDecayed learning rates, g_lr: 0.00009924, d_lr: 0.00009924.\nDecayed learning rates, g_lr: 0.00009923, d_lr: 0.00009923.\nDecayed learning rates, g_lr: 0.00009923, d_lr: 0.00009923.\nDecayed learning rates, g_lr: 0.00009922, d_lr: 0.00009922.\nDecayed learning rates, g_lr: 0.00009922, d_lr: 0.00009922.\nDecayed learning rates, g_lr: 0.00009921, d_lr: 0.00009921.\nDecayed learning rates, g_lr: 0.00009921, d_lr: 0.00009921.\nElapsed [6:05:38], Iteration [11600/30000], Dataset [1], D/loss_real: -5.7511, D/loss_fake: 3.3700, D/loss_cls: 1.3522, D/loss_gp: 0.0249, G/loss_fake: -3.8505, G/loss_rec: 0.1604, G/loss_cls: 0.8616\nElapsed [6:05:40], Iteration [11600/30000], Dataset [2], D/loss_real: -6.0665, D/loss_fake: 4.4972, D/loss_cls: 0.5229, D/loss_gp: 0.0415, G/loss_fake: -3.7729, G/loss_rec: 0.1549, G/loss_cls: 0.3310\nElapsed [6:05:41], Iteration [11600/30000], Dataset [3], D/loss_real: -3.4840, D/loss_fake: 2.0715, D/loss_cls: 0.0000, D/loss_gp: 0.0147, G/loss_fake: -1.0529, G/loss_rec: 0.1107, G/loss_cls: 0.0006\nDecayed learning rates, g_lr: 0.00009920, d_lr: 0.00009920.\nDecayed learning rates, g_lr: 0.00009920, d_lr: 0.00009920.\nDecayed learning rates, g_lr: 0.00009919, d_lr: 0.00009919.\nDecayed learning rates, g_lr: 0.00009919, d_lr: 0.00009919.\nDecayed learning rates, g_lr: 0.00009918, d_lr: 0.00009918.\nDecayed learning rates, g_lr: 0.00009918, d_lr: 0.00009918.\nDecayed learning rates, g_lr: 0.00009917, d_lr: 0.00009917.\nDecayed learning rates, g_lr: 0.00009917, d_lr: 0.00009917.\nDecayed learning rates, g_lr: 0.00009916, d_lr: 0.00009916.\nDecayed learning rates, g_lr: 0.00009916, d_lr: 0.00009916.\nElapsed [6:08:48], Iteration [11700/30000], Dataset [1], D/loss_real: 0.2039, D/loss_fake: -3.8721, D/loss_cls: 1.5469, D/loss_gp: 0.0114, G/loss_fake: 4.1604, G/loss_rec: 0.1596, G/loss_cls: 1.0823\nElapsed [6:08:49], Iteration [11700/30000], Dataset [2], D/loss_real: -2.5401, D/loss_fake: 0.9203, D/loss_cls: 0.9495, D/loss_gp: 0.0334, G/loss_fake: -3.1828, G/loss_rec: 0.1482, G/loss_cls: 0.4311\nElapsed [6:08:50], Iteration [11700/30000], Dataset [3], D/loss_real: -7.2991, D/loss_fake: 5.6732, D/loss_cls: 0.0000, D/loss_gp: 0.0261, G/loss_fake: -6.3712, G/loss_rec: 0.0989, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009915, d_lr: 0.00009915.\nDecayed learning rates, g_lr: 0.00009915, d_lr: 0.00009915.\nDecayed learning rates, g_lr: 0.00009914, d_lr: 0.00009914.\nDecayed learning rates, g_lr: 0.00009914, d_lr: 0.00009914.\nDecayed learning rates, g_lr: 0.00009913, d_lr: 0.00009913.\nDecayed learning rates, g_lr: 0.00009913, d_lr: 0.00009913.\nDecayed learning rates, g_lr: 0.00009912, d_lr: 0.00009912.\nDecayed learning rates, g_lr: 0.00009912, d_lr: 0.00009912.\nDecayed learning rates, g_lr: 0.00009911, d_lr: 0.00009911.\nDecayed learning rates, g_lr: 0.00009911, d_lr: 0.00009911.\nElapsed [6:11:57], Iteration [11800/30000], Dataset [1], D/loss_real: -2.9806, D/loss_fake: 0.8667, D/loss_cls: 1.2684, D/loss_gp: 0.0100, G/loss_fake: -0.5386, G/loss_rec: 0.1837, G/loss_cls: 1.1062\nElapsed [6:11:58], Iteration [11800/30000], Dataset [2], D/loss_real: -3.0163, D/loss_fake: 1.3164, D/loss_cls: 0.7266, D/loss_gp: 0.0169, G/loss_fake: -1.7005, G/loss_rec: 0.1474, G/loss_cls: 0.5509\nElapsed [6:11:59], Iteration [11800/30000], Dataset [3], D/loss_real: -3.7251, D/loss_fake: 2.6736, D/loss_cls: 0.0000, D/loss_gp: 0.0164, G/loss_fake: -2.5203, G/loss_rec: 0.1021, G/loss_cls: 0.0032\nDecayed learning rates, g_lr: 0.00009910, d_lr: 0.00009910.\nDecayed learning rates, g_lr: 0.00009910, d_lr: 0.00009910.\nDecayed learning rates, g_lr: 0.00009909, d_lr: 0.00009909.\nDecayed learning rates, g_lr: 0.00009909, d_lr: 0.00009909.\nDecayed learning rates, g_lr: 0.00009908, d_lr: 0.00009908.\nDecayed learning rates, g_lr: 0.00009908, d_lr: 0.00009908.\nDecayed learning rates, g_lr: 0.00009907, d_lr: 0.00009907.\nDecayed learning rates, g_lr: 0.00009907, d_lr: 0.00009907.\nDecayed learning rates, g_lr: 0.00009906, d_lr: 0.00009906.\nDecayed learning rates, g_lr: 0.00009906, d_lr: 0.00009906.\nElapsed [6:15:06], Iteration [11900/30000], Dataset [1], D/loss_real: -4.5203, D/loss_fake: 1.5006, D/loss_cls: 1.2773, D/loss_gp: 0.0141, G/loss_fake: -1.5042, G/loss_rec: 0.1728, G/loss_cls: 0.8700\nElapsed [6:15:07], Iteration [11900/30000], Dataset [2], D/loss_real: -5.1839, D/loss_fake: 2.4694, D/loss_cls: 0.7903, D/loss_gp: 0.0226, G/loss_fake: -1.3042, G/loss_rec: 0.1790, G/loss_cls: 0.2752\nElapsed [6:15:08], Iteration [11900/30000], Dataset [3], D/loss_real: -3.9675, D/loss_fake: 2.1806, D/loss_cls: 0.0000, D/loss_gp: 0.0284, G/loss_fake: -0.9383, G/loss_rec: 0.0980, G/loss_cls: 0.0028\nDecayed learning rates, g_lr: 0.00009905, d_lr: 0.00009905.\nDecayed learning rates, g_lr: 0.00009905, d_lr: 0.00009905.\nDecayed learning rates, g_lr: 0.00009904, d_lr: 0.00009904.\nDecayed learning rates, g_lr: 0.00009904, d_lr: 0.00009904.\nDecayed learning rates, g_lr: 0.00009903, d_lr: 0.00009903.\nDecayed learning rates, g_lr: 0.00009903, d_lr: 0.00009903.\nDecayed learning rates, g_lr: 0.00009902, d_lr: 0.00009902.\nDecayed learning rates, g_lr: 0.00009902, d_lr: 0.00009902.\nDecayed learning rates, g_lr: 0.00009901, d_lr: 0.00009901.\nDecayed learning rates, g_lr: 0.00009901, d_lr: 0.00009901.\nElapsed [6:18:15], Iteration [12000/30000], Dataset [1], D/loss_real: -6.3693, D/loss_fake: 2.5101, D/loss_cls: 1.2025, D/loss_gp: 0.0287, G/loss_fake: -2.9136, G/loss_rec: 0.1756, G/loss_cls: 0.8453\nElapsed [6:18:16], Iteration [12000/30000], Dataset [2], D/loss_real: -4.1989, D/loss_fake: 1.9995, D/loss_cls: 0.8459, D/loss_gp: 0.0281, G/loss_fake: -1.7039, G/loss_rec: 0.1483, G/loss_cls: 0.3237\nElapsed [6:18:17], Iteration [12000/30000], Dataset [3], D/loss_real: -3.0685, D/loss_fake: 2.2500, D/loss_cls: 0.0000, D/loss_gp: 0.0484, G/loss_fake: 0.3671, G/loss_rec: 0.0975, G/loss_cls: 0.0000\nSaved real and fake images into /kaggle/working/exps/visualization/12000...\nSaved model checkpoints at iteration 12000 into /kaggle/working/exps/checkpoints...\nDecayed learning rates, g_lr: 0.00009900, d_lr: 0.00009900.\nDecayed learning rates, g_lr: 0.00009900, d_lr: 0.00009900.\nDecayed learning rates, g_lr: 0.00009899, d_lr: 0.00009899.\nDecayed learning rates, g_lr: 0.00009899, d_lr: 0.00009899.\nDecayed learning rates, g_lr: 0.00009898, d_lr: 0.00009898.\nDecayed learning rates, g_lr: 0.00009898, d_lr: 0.00009898.\nDecayed learning rates, g_lr: 0.00009897, d_lr: 0.00009897.\nDecayed learning rates, g_lr: 0.00009897, d_lr: 0.00009897.\nDecayed learning rates, g_lr: 0.00009896, d_lr: 0.00009896.\nDecayed learning rates, g_lr: 0.00009896, d_lr: 0.00009896.\nElapsed [6:21:26], Iteration [12100/30000], Dataset [1], D/loss_real: -6.0156, D/loss_fake: 3.4089, D/loss_cls: 1.1285, D/loss_gp: 0.0223, G/loss_fake: -2.9810, G/loss_rec: 0.1748, G/loss_cls: 0.7463\nElapsed [6:21:27], Iteration [12100/30000], Dataset [2], D/loss_real: -5.8181, D/loss_fake: 3.5702, D/loss_cls: 1.4642, D/loss_gp: 0.0175, G/loss_fake: -2.7397, G/loss_rec: 0.1545, G/loss_cls: 0.3495\nElapsed [6:21:29], Iteration [12100/30000], Dataset [3], D/loss_real: -11.3766, D/loss_fake: 9.2538, D/loss_cls: 0.0034, D/loss_gp: 0.0179, G/loss_fake: -8.5131, G/loss_rec: 0.1029, G/loss_cls: 0.0139\nDecayed learning rates, g_lr: 0.00009895, d_lr: 0.00009895.\nDecayed learning rates, g_lr: 0.00009895, d_lr: 0.00009895.\nDecayed learning rates, g_lr: 0.00009894, d_lr: 0.00009894.\nDecayed learning rates, g_lr: 0.00009894, d_lr: 0.00009894.\nDecayed learning rates, g_lr: 0.00009893, d_lr: 0.00009893.\nDecayed learning rates, g_lr: 0.00009893, d_lr: 0.00009893.\nDecayed learning rates, g_lr: 0.00009892, d_lr: 0.00009892.\nDecayed learning rates, g_lr: 0.00009892, d_lr: 0.00009892.\nDecayed learning rates, g_lr: 0.00009891, d_lr: 0.00009891.\nDecayed learning rates, g_lr: 0.00009891, d_lr: 0.00009891.\nElapsed [6:24:35], Iteration [12200/30000], Dataset [1], D/loss_real: -5.0155, D/loss_fake: 2.8242, D/loss_cls: 1.1831, D/loss_gp: 0.0224, G/loss_fake: -3.0478, G/loss_rec: 0.1769, G/loss_cls: 0.9913\nElapsed [6:24:36], Iteration [12200/30000], Dataset [2], D/loss_real: -6.3103, D/loss_fake: 4.3880, D/loss_cls: 0.6883, D/loss_gp: 0.0231, G/loss_fake: -3.8596, G/loss_rec: 0.1502, G/loss_cls: 0.3862\nElapsed [6:24:38], Iteration [12200/30000], Dataset [3], D/loss_real: -7.4899, D/loss_fake: 6.3354, D/loss_cls: 0.0010, D/loss_gp: 0.0090, G/loss_fake: -5.3705, G/loss_rec: 0.1068, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009890, d_lr: 0.00009890.\nDecayed learning rates, g_lr: 0.00009890, d_lr: 0.00009890.\nDecayed learning rates, g_lr: 0.00009889, d_lr: 0.00009889.\nDecayed learning rates, g_lr: 0.00009889, d_lr: 0.00009889.\nDecayed learning rates, g_lr: 0.00009888, d_lr: 0.00009888.\nDecayed learning rates, g_lr: 0.00009888, d_lr: 0.00009888.\nDecayed learning rates, g_lr: 0.00009887, d_lr: 0.00009887.\nDecayed learning rates, g_lr: 0.00009887, d_lr: 0.00009887.\nDecayed learning rates, g_lr: 0.00009886, d_lr: 0.00009886.\nDecayed learning rates, g_lr: 0.00009886, d_lr: 0.00009886.\nElapsed [6:27:44], Iteration [12300/30000], Dataset [1], D/loss_real: -4.8610, D/loss_fake: 1.9656, D/loss_cls: 1.2214, D/loss_gp: 0.0132, G/loss_fake: -2.1161, G/loss_rec: 0.1648, G/loss_cls: 1.1000\nElapsed [6:27:45], Iteration [12300/30000], Dataset [2], D/loss_real: -5.7738, D/loss_fake: 4.1353, D/loss_cls: 0.5557, D/loss_gp: 0.0151, G/loss_fake: -3.6955, G/loss_rec: 0.1545, G/loss_cls: 0.2912\nElapsed [6:27:47], Iteration [12300/30000], Dataset [3], D/loss_real: -7.0544, D/loss_fake: 5.0545, D/loss_cls: 0.0000, D/loss_gp: 0.0108, G/loss_fake: -4.5771, G/loss_rec: 0.1015, G/loss_cls: 0.0048\nDecayed learning rates, g_lr: 0.00009885, d_lr: 0.00009885.\nDecayed learning rates, g_lr: 0.00009885, d_lr: 0.00009885.\nDecayed learning rates, g_lr: 0.00009884, d_lr: 0.00009884.\nDecayed learning rates, g_lr: 0.00009884, d_lr: 0.00009884.\nDecayed learning rates, g_lr: 0.00009883, d_lr: 0.00009883.\nDecayed learning rates, g_lr: 0.00009883, d_lr: 0.00009883.\nDecayed learning rates, g_lr: 0.00009882, d_lr: 0.00009882.\nDecayed learning rates, g_lr: 0.00009882, d_lr: 0.00009882.\nDecayed learning rates, g_lr: 0.00009881, d_lr: 0.00009881.\nDecayed learning rates, g_lr: 0.00009881, d_lr: 0.00009881.\nElapsed [6:30:53], Iteration [12400/30000], Dataset [1], D/loss_real: -13.8766, D/loss_fake: 11.3736, D/loss_cls: 1.6139, D/loss_gp: 0.0409, G/loss_fake: -9.8848, G/loss_rec: 0.1625, G/loss_cls: 1.0231\nElapsed [6:30:55], Iteration [12400/30000], Dataset [2], D/loss_real: -12.8896, D/loss_fake: 9.8318, D/loss_cls: 1.5238, D/loss_gp: 0.0143, G/loss_fake: -8.1610, G/loss_rec: 0.1580, G/loss_cls: 0.3846\nElapsed [6:30:56], Iteration [12400/30000], Dataset [3], D/loss_real: -9.3355, D/loss_fake: 7.2197, D/loss_cls: 0.0000, D/loss_gp: 0.0122, G/loss_fake: -6.1543, G/loss_rec: 0.1009, G/loss_cls: 0.0621\nDecayed learning rates, g_lr: 0.00009880, d_lr: 0.00009880.\nDecayed learning rates, g_lr: 0.00009880, d_lr: 0.00009880.\nDecayed learning rates, g_lr: 0.00009879, d_lr: 0.00009879.\nDecayed learning rates, g_lr: 0.00009879, d_lr: 0.00009879.\nDecayed learning rates, g_lr: 0.00009878, d_lr: 0.00009878.\nDecayed learning rates, g_lr: 0.00009878, d_lr: 0.00009878.\nDecayed learning rates, g_lr: 0.00009877, d_lr: 0.00009877.\nDecayed learning rates, g_lr: 0.00009877, d_lr: 0.00009877.\nDecayed learning rates, g_lr: 0.00009876, d_lr: 0.00009876.\nDecayed learning rates, g_lr: 0.00009876, d_lr: 0.00009876.\nElapsed [6:34:02], Iteration [12500/30000], Dataset [1], D/loss_real: -4.5216, D/loss_fake: 1.2509, D/loss_cls: 1.4144, D/loss_gp: 0.0243, G/loss_fake: 0.0359, G/loss_rec: 0.1688, G/loss_cls: 1.0229\nElapsed [6:34:04], Iteration [12500/30000], Dataset [2], D/loss_real: -3.3420, D/loss_fake: 0.7616, D/loss_cls: 0.7508, D/loss_gp: 0.0264, G/loss_fake: 1.2631, G/loss_rec: 0.1623, G/loss_cls: 0.5097\nElapsed [6:34:05], Iteration [12500/30000], Dataset [3], D/loss_real: 4.8067, D/loss_fake: -5.9547, D/loss_cls: 0.0000, D/loss_gp: 0.0180, G/loss_fake: 6.1775, G/loss_rec: 0.0940, G/loss_cls: 0.0011\nDecayed learning rates, g_lr: 0.00009875, d_lr: 0.00009875.\nDecayed learning rates, g_lr: 0.00009875, d_lr: 0.00009875.\nDecayed learning rates, g_lr: 0.00009874, d_lr: 0.00009874.\nDecayed learning rates, g_lr: 0.00009874, d_lr: 0.00009874.\nDecayed learning rates, g_lr: 0.00009873, d_lr: 0.00009873.\nDecayed learning rates, g_lr: 0.00009873, d_lr: 0.00009873.\nDecayed learning rates, g_lr: 0.00009872, d_lr: 0.00009872.\nDecayed learning rates, g_lr: 0.00009872, d_lr: 0.00009872.\nDecayed learning rates, g_lr: 0.00009871, d_lr: 0.00009871.\nDecayed learning rates, g_lr: 0.00009871, d_lr: 0.00009871.\nElapsed [6:37:11], Iteration [12600/30000], Dataset [1], D/loss_real: -3.8676, D/loss_fake: 0.6297, D/loss_cls: 1.0605, D/loss_gp: 0.0157, G/loss_fake: -0.6161, G/loss_rec: 0.1651, G/loss_cls: 0.6931\nElapsed [6:37:12], Iteration [12600/30000], Dataset [2], D/loss_real: -3.8772, D/loss_fake: 2.1387, D/loss_cls: 1.1469, D/loss_gp: 0.0253, G/loss_fake: -0.4936, G/loss_rec: 0.1524, G/loss_cls: 0.4192\nElapsed [6:37:14], Iteration [12600/30000], Dataset [3], D/loss_real: -3.0519, D/loss_fake: 1.9971, D/loss_cls: 0.0000, D/loss_gp: 0.0131, G/loss_fake: -0.9654, G/loss_rec: 0.0968, G/loss_cls: 0.0014\nDecayed learning rates, g_lr: 0.00009870, d_lr: 0.00009870.\nDecayed learning rates, g_lr: 0.00009870, d_lr: 0.00009870.\nDecayed learning rates, g_lr: 0.00009869, d_lr: 0.00009869.\nDecayed learning rates, g_lr: 0.00009869, d_lr: 0.00009869.\nDecayed learning rates, g_lr: 0.00009868, d_lr: 0.00009868.\nDecayed learning rates, g_lr: 0.00009868, d_lr: 0.00009868.\nDecayed learning rates, g_lr: 0.00009867, d_lr: 0.00009867.\nDecayed learning rates, g_lr: 0.00009867, d_lr: 0.00009867.\nDecayed learning rates, g_lr: 0.00009866, d_lr: 0.00009866.\nDecayed learning rates, g_lr: 0.00009866, d_lr: 0.00009866.\nElapsed [6:40:20], Iteration [12700/30000], Dataset [1], D/loss_real: -5.0023, D/loss_fake: 1.2196, D/loss_cls: 1.0303, D/loss_gp: 0.0339, G/loss_fake: -2.1222, G/loss_rec: 0.1632, G/loss_cls: 1.0460\nElapsed [6:40:21], Iteration [12700/30000], Dataset [2], D/loss_real: -6.9090, D/loss_fake: 3.9309, D/loss_cls: 0.8633, D/loss_gp: 0.0250, G/loss_fake: -3.4318, G/loss_rec: 0.1521, G/loss_cls: 0.3361\nElapsed [6:40:23], Iteration [12700/30000], Dataset [3], D/loss_real: 0.6788, D/loss_fake: -1.8669, D/loss_cls: 0.0061, D/loss_gp: 0.0090, G/loss_fake: 2.1041, G/loss_rec: 0.0968, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009865, d_lr: 0.00009865.\nDecayed learning rates, g_lr: 0.00009865, d_lr: 0.00009865.\nDecayed learning rates, g_lr: 0.00009864, d_lr: 0.00009864.\nDecayed learning rates, g_lr: 0.00009864, d_lr: 0.00009864.\nDecayed learning rates, g_lr: 0.00009863, d_lr: 0.00009863.\nDecayed learning rates, g_lr: 0.00009863, d_lr: 0.00009863.\nDecayed learning rates, g_lr: 0.00009862, d_lr: 0.00009862.\nDecayed learning rates, g_lr: 0.00009862, d_lr: 0.00009862.\nDecayed learning rates, g_lr: 0.00009861, d_lr: 0.00009861.\nDecayed learning rates, g_lr: 0.00009861, d_lr: 0.00009861.\nElapsed [6:43:29], Iteration [12800/30000], Dataset [1], D/loss_real: -9.7882, D/loss_fake: 7.0954, D/loss_cls: 1.2361, D/loss_gp: 0.0247, G/loss_fake: -5.8017, G/loss_rec: 0.1625, G/loss_cls: 1.4057\nElapsed [6:43:31], Iteration [12800/30000], Dataset [2], D/loss_real: -9.6233, D/loss_fake: 6.5542, D/loss_cls: 0.9277, D/loss_gp: 0.0281, G/loss_fake: -6.6529, G/loss_rec: 0.1633, G/loss_cls: 0.3570\nElapsed [6:43:32], Iteration [12800/30000], Dataset [3], D/loss_real: -7.6136, D/loss_fake: 4.5414, D/loss_cls: 0.0000, D/loss_gp: 0.0337, G/loss_fake: -4.1251, G/loss_rec: 0.1124, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009860, d_lr: 0.00009860.\nDecayed learning rates, g_lr: 0.00009860, d_lr: 0.00009860.\nDecayed learning rates, g_lr: 0.00009859, d_lr: 0.00009859.\nDecayed learning rates, g_lr: 0.00009859, d_lr: 0.00009859.\nDecayed learning rates, g_lr: 0.00009858, d_lr: 0.00009858.\nDecayed learning rates, g_lr: 0.00009858, d_lr: 0.00009858.\nDecayed learning rates, g_lr: 0.00009857, d_lr: 0.00009857.\nDecayed learning rates, g_lr: 0.00009857, d_lr: 0.00009857.\nDecayed learning rates, g_lr: 0.00009856, d_lr: 0.00009856.\nDecayed learning rates, g_lr: 0.00009856, d_lr: 0.00009856.\nElapsed [6:46:38], Iteration [12900/30000], Dataset [1], D/loss_real: -4.8144, D/loss_fake: 2.0351, D/loss_cls: 1.1743, D/loss_gp: 0.0240, G/loss_fake: -2.3841, G/loss_rec: 0.1651, G/loss_cls: 0.6479\nElapsed [6:46:40], Iteration [12900/30000], Dataset [2], D/loss_real: -3.4011, D/loss_fake: 1.5885, D/loss_cls: 0.6531, D/loss_gp: 0.0176, G/loss_fake: -0.9409, G/loss_rec: 0.1510, G/loss_cls: 0.2636\nElapsed [6:46:41], Iteration [12900/30000], Dataset [3], D/loss_real: -5.2166, D/loss_fake: 2.9903, D/loss_cls: 0.0000, D/loss_gp: 0.0301, G/loss_fake: -1.9012, G/loss_rec: 0.1018, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009855, d_lr: 0.00009855.\nDecayed learning rates, g_lr: 0.00009855, d_lr: 0.00009855.\nDecayed learning rates, g_lr: 0.00009854, d_lr: 0.00009854.\nDecayed learning rates, g_lr: 0.00009854, d_lr: 0.00009854.\nDecayed learning rates, g_lr: 0.00009853, d_lr: 0.00009853.\nDecayed learning rates, g_lr: 0.00009853, d_lr: 0.00009853.\nDecayed learning rates, g_lr: 0.00009852, d_lr: 0.00009852.\nDecayed learning rates, g_lr: 0.00009852, d_lr: 0.00009852.\nDecayed learning rates, g_lr: 0.00009851, d_lr: 0.00009851.\nDecayed learning rates, g_lr: 0.00009851, d_lr: 0.00009851.\nElapsed [6:49:48], Iteration [13000/30000], Dataset [1], D/loss_real: -7.3833, D/loss_fake: 4.7258, D/loss_cls: 1.2663, D/loss_gp: 0.0173, G/loss_fake: -5.4887, G/loss_rec: 0.1652, G/loss_cls: 0.8355\nElapsed [6:49:49], Iteration [13000/30000], Dataset [2], D/loss_real: -6.9164, D/loss_fake: 5.0179, D/loss_cls: 0.5333, D/loss_gp: 0.0271, G/loss_fake: -5.1590, G/loss_rec: 0.1449, G/loss_cls: 0.3352\nElapsed [6:49:50], Iteration [13000/30000], Dataset [3], D/loss_real: -6.0922, D/loss_fake: 4.6090, D/loss_cls: 0.0000, D/loss_gp: 0.0128, G/loss_fake: -3.0399, G/loss_rec: 0.0925, G/loss_cls: 0.0030\nDecayed learning rates, g_lr: 0.00009850, d_lr: 0.00009850.\nDecayed learning rates, g_lr: 0.00009850, d_lr: 0.00009850.\nDecayed learning rates, g_lr: 0.00009849, d_lr: 0.00009849.\nDecayed learning rates, g_lr: 0.00009849, d_lr: 0.00009849.\nDecayed learning rates, g_lr: 0.00009848, d_lr: 0.00009848.\nDecayed learning rates, g_lr: 0.00009848, d_lr: 0.00009848.\nDecayed learning rates, g_lr: 0.00009847, d_lr: 0.00009847.\nDecayed learning rates, g_lr: 0.00009847, d_lr: 0.00009847.\nDecayed learning rates, g_lr: 0.00009846, d_lr: 0.00009846.\nDecayed learning rates, g_lr: 0.00009846, d_lr: 0.00009846.\nElapsed [6:52:57], Iteration [13100/30000], Dataset [1], D/loss_real: -14.2496, D/loss_fake: 10.3264, D/loss_cls: 1.0489, D/loss_gp: 0.0445, G/loss_fake: -9.7487, G/loss_rec: 0.1802, G/loss_cls: 0.7131\nElapsed [6:52:58], Iteration [13100/30000], Dataset [2], D/loss_real: -11.9729, D/loss_fake: 9.8442, D/loss_cls: 0.8549, D/loss_gp: 0.0342, G/loss_fake: -6.4811, G/loss_rec: 0.1460, G/loss_cls: 0.2669\nElapsed [6:52:59], Iteration [13100/30000], Dataset [3], D/loss_real: -14.5449, D/loss_fake: 13.6324, D/loss_cls: 0.0001, D/loss_gp: 0.0202, G/loss_fake: -11.1730, G/loss_rec: 0.0916, G/loss_cls: 0.0115\nDecayed learning rates, g_lr: 0.00009845, d_lr: 0.00009845.\nDecayed learning rates, g_lr: 0.00009845, d_lr: 0.00009845.\nDecayed learning rates, g_lr: 0.00009844, d_lr: 0.00009844.\nDecayed learning rates, g_lr: 0.00009844, d_lr: 0.00009844.\nDecayed learning rates, g_lr: 0.00009843, d_lr: 0.00009843.\nDecayed learning rates, g_lr: 0.00009843, d_lr: 0.00009843.\nDecayed learning rates, g_lr: 0.00009842, d_lr: 0.00009842.\nDecayed learning rates, g_lr: 0.00009842, d_lr: 0.00009842.\nDecayed learning rates, g_lr: 0.00009841, d_lr: 0.00009841.\nDecayed learning rates, g_lr: 0.00009841, d_lr: 0.00009841.\nElapsed [6:56:06], Iteration [13200/30000], Dataset [1], D/loss_real: -5.8134, D/loss_fake: 3.2187, D/loss_cls: 1.2967, D/loss_gp: 0.0178, G/loss_fake: -3.7707, G/loss_rec: 0.1771, G/loss_cls: 0.9105\nElapsed [6:56:07], Iteration [13200/30000], Dataset [2], D/loss_real: -5.3329, D/loss_fake: 3.9956, D/loss_cls: 0.8165, D/loss_gp: 0.0297, G/loss_fake: -3.8402, G/loss_rec: 0.1467, G/loss_cls: 0.4258\nElapsed [6:56:08], Iteration [13200/30000], Dataset [3], D/loss_real: -7.0741, D/loss_fake: 6.0811, D/loss_cls: 0.0000, D/loss_gp: 0.0102, G/loss_fake: -4.2624, G/loss_rec: 0.1072, G/loss_cls: 0.0028\nDecayed learning rates, g_lr: 0.00009840, d_lr: 0.00009840.\nDecayed learning rates, g_lr: 0.00009840, d_lr: 0.00009840.\nDecayed learning rates, g_lr: 0.00009839, d_lr: 0.00009839.\nDecayed learning rates, g_lr: 0.00009839, d_lr: 0.00009839.\nDecayed learning rates, g_lr: 0.00009838, d_lr: 0.00009838.\nDecayed learning rates, g_lr: 0.00009838, d_lr: 0.00009838.\nDecayed learning rates, g_lr: 0.00009837, d_lr: 0.00009837.\nDecayed learning rates, g_lr: 0.00009837, d_lr: 0.00009837.\nDecayed learning rates, g_lr: 0.00009836, d_lr: 0.00009836.\nDecayed learning rates, g_lr: 0.00009836, d_lr: 0.00009836.\nElapsed [6:59:15], Iteration [13300/30000], Dataset [1], D/loss_real: -6.9710, D/loss_fake: 2.8615, D/loss_cls: 1.5202, D/loss_gp: 0.0217, G/loss_fake: -3.7784, G/loss_rec: 0.2005, G/loss_cls: 0.8438\nElapsed [6:59:16], Iteration [13300/30000], Dataset [2], D/loss_real: -7.8436, D/loss_fake: 5.1729, D/loss_cls: 0.8058, D/loss_gp: 0.0408, G/loss_fake: -5.7364, G/loss_rec: 0.1687, G/loss_cls: 0.3074\nElapsed [6:59:17], Iteration [13300/30000], Dataset [3], D/loss_real: -12.1917, D/loss_fake: 9.6162, D/loss_cls: 0.0001, D/loss_gp: 0.0223, G/loss_fake: -4.0152, G/loss_rec: 0.1092, G/loss_cls: 0.0010\nDecayed learning rates, g_lr: 0.00009835, d_lr: 0.00009835.\nDecayed learning rates, g_lr: 0.00009835, d_lr: 0.00009835.\nDecayed learning rates, g_lr: 0.00009834, d_lr: 0.00009834.\nDecayed learning rates, g_lr: 0.00009834, d_lr: 0.00009834.\nDecayed learning rates, g_lr: 0.00009833, d_lr: 0.00009833.\nDecayed learning rates, g_lr: 0.00009833, d_lr: 0.00009833.\nDecayed learning rates, g_lr: 0.00009832, d_lr: 0.00009832.\nDecayed learning rates, g_lr: 0.00009832, d_lr: 0.00009832.\nDecayed learning rates, g_lr: 0.00009831, d_lr: 0.00009831.\nDecayed learning rates, g_lr: 0.00009831, d_lr: 0.00009831.\nElapsed [7:02:24], Iteration [13400/30000], Dataset [1], D/loss_real: -3.0672, D/loss_fake: 0.7550, D/loss_cls: 1.4244, D/loss_gp: 0.0159, G/loss_fake: -1.6923, G/loss_rec: 0.1539, G/loss_cls: 0.9115\nElapsed [7:02:25], Iteration [13400/30000], Dataset [2], D/loss_real: -4.3116, D/loss_fake: 2.5829, D/loss_cls: 0.7695, D/loss_gp: 0.0100, G/loss_fake: -3.2257, G/loss_rec: 0.1501, G/loss_cls: 0.2630\nElapsed [7:02:26], Iteration [13400/30000], Dataset [3], D/loss_real: -2.8128, D/loss_fake: 1.8415, D/loss_cls: 0.0000, D/loss_gp: 0.0099, G/loss_fake: -1.7515, G/loss_rec: 0.1024, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009830, d_lr: 0.00009830.\nDecayed learning rates, g_lr: 0.00009830, d_lr: 0.00009830.\nDecayed learning rates, g_lr: 0.00009829, d_lr: 0.00009829.\nDecayed learning rates, g_lr: 0.00009829, d_lr: 0.00009829.\nDecayed learning rates, g_lr: 0.00009828, d_lr: 0.00009828.\nDecayed learning rates, g_lr: 0.00009828, d_lr: 0.00009828.\nDecayed learning rates, g_lr: 0.00009827, d_lr: 0.00009827.\nDecayed learning rates, g_lr: 0.00009827, d_lr: 0.00009827.\nDecayed learning rates, g_lr: 0.00009826, d_lr: 0.00009826.\nDecayed learning rates, g_lr: 0.00009826, d_lr: 0.00009826.\nElapsed [7:05:33], Iteration [13500/30000], Dataset [1], D/loss_real: -7.0675, D/loss_fake: 4.7314, D/loss_cls: 1.4289, D/loss_gp: 0.0160, G/loss_fake: -3.8103, G/loss_rec: 0.1825, G/loss_cls: 0.6546\nElapsed [7:05:34], Iteration [13500/30000], Dataset [2], D/loss_real: -5.0051, D/loss_fake: 4.2474, D/loss_cls: 0.5757, D/loss_gp: 0.0169, G/loss_fake: -3.0556, G/loss_rec: 0.1416, G/loss_cls: 0.2272\nElapsed [7:05:36], Iteration [13500/30000], Dataset [3], D/loss_real: -3.2811, D/loss_fake: 1.6013, D/loss_cls: 0.0000, D/loss_gp: 0.0058, G/loss_fake: -1.8695, G/loss_rec: 0.1000, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009825, d_lr: 0.00009825.\nDecayed learning rates, g_lr: 0.00009825, d_lr: 0.00009825.\nDecayed learning rates, g_lr: 0.00009824, d_lr: 0.00009824.\nDecayed learning rates, g_lr: 0.00009824, d_lr: 0.00009824.\nDecayed learning rates, g_lr: 0.00009823, d_lr: 0.00009823.\nDecayed learning rates, g_lr: 0.00009823, d_lr: 0.00009823.\nDecayed learning rates, g_lr: 0.00009822, d_lr: 0.00009822.\nDecayed learning rates, g_lr: 0.00009822, d_lr: 0.00009822.\nDecayed learning rates, g_lr: 0.00009821, d_lr: 0.00009821.\nDecayed learning rates, g_lr: 0.00009821, d_lr: 0.00009821.\nElapsed [7:08:42], Iteration [13600/30000], Dataset [1], D/loss_real: -4.8589, D/loss_fake: 2.5289, D/loss_cls: 1.0909, D/loss_gp: 0.0216, G/loss_fake: -2.1059, G/loss_rec: 0.1583, G/loss_cls: 0.5434\nElapsed [7:08:43], Iteration [13600/30000], Dataset [2], D/loss_real: -4.4051, D/loss_fake: 2.9254, D/loss_cls: 0.4775, D/loss_gp: 0.0173, G/loss_fake: -1.8116, G/loss_rec: 0.1343, G/loss_cls: 0.2820\nElapsed [7:08:45], Iteration [13600/30000], Dataset [3], D/loss_real: -2.9180, D/loss_fake: 1.3346, D/loss_cls: 0.0000, D/loss_gp: 0.0061, G/loss_fake: -0.7625, G/loss_rec: 0.0926, G/loss_cls: 0.0013\nDecayed learning rates, g_lr: 0.00009820, d_lr: 0.00009820.\nDecayed learning rates, g_lr: 0.00009820, d_lr: 0.00009820.\nDecayed learning rates, g_lr: 0.00009819, d_lr: 0.00009819.\nDecayed learning rates, g_lr: 0.00009819, d_lr: 0.00009819.\nDecayed learning rates, g_lr: 0.00009818, d_lr: 0.00009818.\nDecayed learning rates, g_lr: 0.00009818, d_lr: 0.00009818.\nDecayed learning rates, g_lr: 0.00009817, d_lr: 0.00009817.\nDecayed learning rates, g_lr: 0.00009817, d_lr: 0.00009817.\nDecayed learning rates, g_lr: 0.00009816, d_lr: 0.00009816.\nDecayed learning rates, g_lr: 0.00009816, d_lr: 0.00009816.\nElapsed [7:11:51], Iteration [13700/30000], Dataset [1], D/loss_real: -5.6119, D/loss_fake: 2.5084, D/loss_cls: 1.2891, D/loss_gp: 0.0136, G/loss_fake: -2.0926, G/loss_rec: 0.1565, G/loss_cls: 0.8017\nElapsed [7:11:52], Iteration [13700/30000], Dataset [2], D/loss_real: -3.9489, D/loss_fake: 1.9101, D/loss_cls: 0.8217, D/loss_gp: 0.0175, G/loss_fake: -1.5996, G/loss_rec: 0.1446, G/loss_cls: 0.2736\nElapsed [7:11:54], Iteration [13700/30000], Dataset [3], D/loss_real: -3.8948, D/loss_fake: 3.3499, D/loss_cls: 0.0000, D/loss_gp: 0.0191, G/loss_fake: -2.3822, G/loss_rec: 0.1016, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009815, d_lr: 0.00009815.\nDecayed learning rates, g_lr: 0.00009815, d_lr: 0.00009815.\nDecayed learning rates, g_lr: 0.00009814, d_lr: 0.00009814.\nDecayed learning rates, g_lr: 0.00009814, d_lr: 0.00009814.\nDecayed learning rates, g_lr: 0.00009813, d_lr: 0.00009813.\nDecayed learning rates, g_lr: 0.00009813, d_lr: 0.00009813.\nDecayed learning rates, g_lr: 0.00009812, d_lr: 0.00009812.\nDecayed learning rates, g_lr: 0.00009812, d_lr: 0.00009812.\nDecayed learning rates, g_lr: 0.00009811, d_lr: 0.00009811.\nDecayed learning rates, g_lr: 0.00009811, d_lr: 0.00009811.\nElapsed [7:15:00], Iteration [13800/30000], Dataset [1], D/loss_real: -3.0967, D/loss_fake: 1.0577, D/loss_cls: 1.1436, D/loss_gp: 0.0194, G/loss_fake: -1.2960, G/loss_rec: 0.1776, G/loss_cls: 0.8148\nElapsed [7:15:01], Iteration [13800/30000], Dataset [2], D/loss_real: -4.0470, D/loss_fake: 1.7620, D/loss_cls: 0.4763, D/loss_gp: 0.0133, G/loss_fake: -0.4480, G/loss_rec: 0.1544, G/loss_cls: 0.2780\nElapsed [7:15:03], Iteration [13800/30000], Dataset [3], D/loss_real: -1.2026, D/loss_fake: -0.4063, D/loss_cls: 0.0000, D/loss_gp: 0.0130, G/loss_fake: 1.4192, G/loss_rec: 0.1054, G/loss_cls: 0.0658\nDecayed learning rates, g_lr: 0.00009810, d_lr: 0.00009810.\nDecayed learning rates, g_lr: 0.00009810, d_lr: 0.00009810.\nDecayed learning rates, g_lr: 0.00009809, d_lr: 0.00009809.\nDecayed learning rates, g_lr: 0.00009809, d_lr: 0.00009809.\nDecayed learning rates, g_lr: 0.00009808, d_lr: 0.00009808.\nDecayed learning rates, g_lr: 0.00009808, d_lr: 0.00009808.\nDecayed learning rates, g_lr: 0.00009807, d_lr: 0.00009807.\nDecayed learning rates, g_lr: 0.00009807, d_lr: 0.00009807.\nDecayed learning rates, g_lr: 0.00009806, d_lr: 0.00009806.\nDecayed learning rates, g_lr: 0.00009806, d_lr: 0.00009806.\nElapsed [7:18:09], Iteration [13900/30000], Dataset [1], D/loss_real: -4.2886, D/loss_fake: 1.5947, D/loss_cls: 1.1514, D/loss_gp: 0.0309, G/loss_fake: -1.9888, G/loss_rec: 0.1515, G/loss_cls: 0.7994\nElapsed [7:18:11], Iteration [13900/30000], Dataset [2], D/loss_real: -5.2958, D/loss_fake: 2.8496, D/loss_cls: 0.6488, D/loss_gp: 0.0257, G/loss_fake: -2.9279, G/loss_rec: 0.1349, G/loss_cls: 0.3418\nElapsed [7:18:12], Iteration [13900/30000], Dataset [3], D/loss_real: -2.0948, D/loss_fake: 1.1095, D/loss_cls: 0.0000, D/loss_gp: 0.0122, G/loss_fake: 0.0471, G/loss_rec: 0.0850, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009805, d_lr: 0.00009805.\nDecayed learning rates, g_lr: 0.00009805, d_lr: 0.00009805.\nDecayed learning rates, g_lr: 0.00009804, d_lr: 0.00009804.\nDecayed learning rates, g_lr: 0.00009804, d_lr: 0.00009804.\nDecayed learning rates, g_lr: 0.00009803, d_lr: 0.00009803.\nDecayed learning rates, g_lr: 0.00009803, d_lr: 0.00009803.\nDecayed learning rates, g_lr: 0.00009802, d_lr: 0.00009802.\nDecayed learning rates, g_lr: 0.00009802, d_lr: 0.00009802.\nDecayed learning rates, g_lr: 0.00009801, d_lr: 0.00009801.\nDecayed learning rates, g_lr: 0.00009801, d_lr: 0.00009801.\nElapsed [7:21:18], Iteration [14000/30000], Dataset [1], D/loss_real: -2.8960, D/loss_fake: 0.7768, D/loss_cls: 1.0569, D/loss_gp: 0.0149, G/loss_fake: -0.7734, G/loss_rec: 0.1551, G/loss_cls: 0.7996\nElapsed [7:21:20], Iteration [14000/30000], Dataset [2], D/loss_real: -2.4325, D/loss_fake: 0.6644, D/loss_cls: 0.8527, D/loss_gp: 0.0122, G/loss_fake: 0.0766, G/loss_rec: 0.1384, G/loss_cls: 0.4067\nElapsed [7:21:21], Iteration [14000/30000], Dataset [3], D/loss_real: 0.3433, D/loss_fake: -1.3588, D/loss_cls: 0.0000, D/loss_gp: 0.0104, G/loss_fake: 1.4914, G/loss_rec: 0.0911, G/loss_cls: 0.0000\nSaved real and fake images into /kaggle/working/exps/visualization/14000...\nSaved model checkpoints at iteration 14000 into /kaggle/working/exps/checkpoints...\nDecayed learning rates, g_lr: 0.00009800, d_lr: 0.00009800.\nDecayed learning rates, g_lr: 0.00009800, d_lr: 0.00009800.\nDecayed learning rates, g_lr: 0.00009799, d_lr: 0.00009799.\nDecayed learning rates, g_lr: 0.00009799, d_lr: 0.00009799.\nDecayed learning rates, g_lr: 0.00009798, d_lr: 0.00009798.\nDecayed learning rates, g_lr: 0.00009798, d_lr: 0.00009798.\nDecayed learning rates, g_lr: 0.00009797, d_lr: 0.00009797.\nDecayed learning rates, g_lr: 0.00009797, d_lr: 0.00009797.\nDecayed learning rates, g_lr: 0.00009796, d_lr: 0.00009796.\nDecayed learning rates, g_lr: 0.00009796, d_lr: 0.00009796.\nElapsed [7:24:29], Iteration [14100/30000], Dataset [1], D/loss_real: -7.7047, D/loss_fake: 3.9876, D/loss_cls: 1.4391, D/loss_gp: 0.0367, G/loss_fake: -5.0901, G/loss_rec: 0.1759, G/loss_cls: 0.7669\nElapsed [7:24:30], Iteration [14100/30000], Dataset [2], D/loss_real: -7.5995, D/loss_fake: 5.2881, D/loss_cls: 0.6654, D/loss_gp: 0.0261, G/loss_fake: -6.1877, G/loss_rec: 0.1384, G/loss_cls: 0.2784\nElapsed [7:24:32], Iteration [14100/30000], Dataset [3], D/loss_real: -4.3242, D/loss_fake: 1.4892, D/loss_cls: 0.0000, D/loss_gp: 0.0253, G/loss_fake: -2.0763, G/loss_rec: 0.1005, G/loss_cls: 0.0357\nDecayed learning rates, g_lr: 0.00009795, d_lr: 0.00009795.\nDecayed learning rates, g_lr: 0.00009795, d_lr: 0.00009795.\nDecayed learning rates, g_lr: 0.00009794, d_lr: 0.00009794.\nDecayed learning rates, g_lr: 0.00009794, d_lr: 0.00009794.\nDecayed learning rates, g_lr: 0.00009793, d_lr: 0.00009793.\nDecayed learning rates, g_lr: 0.00009793, d_lr: 0.00009793.\nDecayed learning rates, g_lr: 0.00009792, d_lr: 0.00009792.\nDecayed learning rates, g_lr: 0.00009792, d_lr: 0.00009792.\nDecayed learning rates, g_lr: 0.00009791, d_lr: 0.00009791.\nDecayed learning rates, g_lr: 0.00009791, d_lr: 0.00009791.\nElapsed [7:27:38], Iteration [14200/30000], Dataset [1], D/loss_real: -1.4857, D/loss_fake: -0.9632, D/loss_cls: 1.2279, D/loss_gp: 0.0202, G/loss_fake: 0.9594, G/loss_rec: 0.1681, G/loss_cls: 1.1484\nElapsed [7:27:39], Iteration [14200/30000], Dataset [2], D/loss_real: -2.3047, D/loss_fake: 0.3108, D/loss_cls: 0.7923, D/loss_gp: 0.0234, G/loss_fake: -0.2501, G/loss_rec: 0.1484, G/loss_cls: 0.4260\nElapsed [7:27:41], Iteration [14200/30000], Dataset [3], D/loss_real: -7.1886, D/loss_fake: 5.8893, D/loss_cls: 0.0002, D/loss_gp: 0.0100, G/loss_fake: -5.2155, G/loss_rec: 0.1065, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009790, d_lr: 0.00009790.\nDecayed learning rates, g_lr: 0.00009790, d_lr: 0.00009790.\nDecayed learning rates, g_lr: 0.00009789, d_lr: 0.00009789.\nDecayed learning rates, g_lr: 0.00009789, d_lr: 0.00009789.\nDecayed learning rates, g_lr: 0.00009788, d_lr: 0.00009788.\nDecayed learning rates, g_lr: 0.00009788, d_lr: 0.00009788.\nDecayed learning rates, g_lr: 0.00009787, d_lr: 0.00009787.\nDecayed learning rates, g_lr: 0.00009787, d_lr: 0.00009787.\nDecayed learning rates, g_lr: 0.00009786, d_lr: 0.00009786.\nDecayed learning rates, g_lr: 0.00009786, d_lr: 0.00009786.\nElapsed [7:30:47], Iteration [14300/30000], Dataset [1], D/loss_real: -15.5433, D/loss_fake: 10.6163, D/loss_cls: 3.0327, D/loss_gp: 0.0405, G/loss_fake: -10.2272, G/loss_rec: 0.1642, G/loss_cls: 0.8070\nElapsed [7:30:48], Iteration [14300/30000], Dataset [2], D/loss_real: -14.0031, D/loss_fake: 9.8626, D/loss_cls: 0.9014, D/loss_gp: 0.0239, G/loss_fake: -11.2120, G/loss_rec: 0.1611, G/loss_cls: 0.3874\nElapsed [7:30:50], Iteration [14300/30000], Dataset [3], D/loss_real: -13.3039, D/loss_fake: 10.2958, D/loss_cls: 0.0000, D/loss_gp: 0.0774, G/loss_fake: -6.8400, G/loss_rec: 0.1006, G/loss_cls: 0.0114\nDecayed learning rates, g_lr: 0.00009785, d_lr: 0.00009785.\nDecayed learning rates, g_lr: 0.00009785, d_lr: 0.00009785.\nDecayed learning rates, g_lr: 0.00009784, d_lr: 0.00009784.\nDecayed learning rates, g_lr: 0.00009784, d_lr: 0.00009784.\nDecayed learning rates, g_lr: 0.00009783, d_lr: 0.00009783.\nDecayed learning rates, g_lr: 0.00009783, d_lr: 0.00009783.\nDecayed learning rates, g_lr: 0.00009782, d_lr: 0.00009782.\nDecayed learning rates, g_lr: 0.00009782, d_lr: 0.00009782.\nDecayed learning rates, g_lr: 0.00009781, d_lr: 0.00009781.\nDecayed learning rates, g_lr: 0.00009781, d_lr: 0.00009781.\nElapsed [7:33:56], Iteration [14400/30000], Dataset [1], D/loss_real: -3.7468, D/loss_fake: 0.8730, D/loss_cls: 1.2402, D/loss_gp: 0.0141, G/loss_fake: -0.7901, G/loss_rec: 0.1624, G/loss_cls: 0.9518\nElapsed [7:33:58], Iteration [14400/30000], Dataset [2], D/loss_real: -3.8990, D/loss_fake: 0.0476, D/loss_cls: 1.0774, D/loss_gp: 0.0196, G/loss_fake: -0.5612, G/loss_rec: 0.1768, G/loss_cls: 0.5279\nElapsed [7:33:59], Iteration [14400/30000], Dataset [3], D/loss_real: -8.0975, D/loss_fake: 6.1012, D/loss_cls: 0.0003, D/loss_gp: 0.0493, G/loss_fake: -5.6519, G/loss_rec: 0.1009, G/loss_cls: 0.0058\nDecayed learning rates, g_lr: 0.00009780, d_lr: 0.00009780.\nDecayed learning rates, g_lr: 0.00009780, d_lr: 0.00009780.\nDecayed learning rates, g_lr: 0.00009779, d_lr: 0.00009779.\nDecayed learning rates, g_lr: 0.00009779, d_lr: 0.00009779.\nDecayed learning rates, g_lr: 0.00009778, d_lr: 0.00009778.\nDecayed learning rates, g_lr: 0.00009778, d_lr: 0.00009778.\nDecayed learning rates, g_lr: 0.00009777, d_lr: 0.00009777.\nDecayed learning rates, g_lr: 0.00009777, d_lr: 0.00009777.\nDecayed learning rates, g_lr: 0.00009776, d_lr: 0.00009776.\nDecayed learning rates, g_lr: 0.00009776, d_lr: 0.00009776.\nElapsed [7:37:05], Iteration [14500/30000], Dataset [1], D/loss_real: -8.3692, D/loss_fake: 4.6656, D/loss_cls: 1.8650, D/loss_gp: 0.0344, G/loss_fake: -3.1747, G/loss_rec: 0.1547, G/loss_cls: 0.7590\nElapsed [7:37:07], Iteration [14500/30000], Dataset [2], D/loss_real: -7.5578, D/loss_fake: 4.7868, D/loss_cls: 1.2911, D/loss_gp: 0.0180, G/loss_fake: -2.6750, G/loss_rec: 0.1481, G/loss_cls: 0.2500\nElapsed [7:37:08], Iteration [14500/30000], Dataset [3], D/loss_real: 0.4674, D/loss_fake: 0.1539, D/loss_cls: 0.0000, D/loss_gp: 0.0140, G/loss_fake: 3.0851, G/loss_rec: 0.0968, G/loss_cls: 0.0042\nDecayed learning rates, g_lr: 0.00009775, d_lr: 0.00009775.\nDecayed learning rates, g_lr: 0.00009775, d_lr: 0.00009775.\nDecayed learning rates, g_lr: 0.00009774, d_lr: 0.00009774.\nDecayed learning rates, g_lr: 0.00009774, d_lr: 0.00009774.\nDecayed learning rates, g_lr: 0.00009773, d_lr: 0.00009773.\nDecayed learning rates, g_lr: 0.00009773, d_lr: 0.00009773.\nDecayed learning rates, g_lr: 0.00009772, d_lr: 0.00009772.\nDecayed learning rates, g_lr: 0.00009772, d_lr: 0.00009772.\nDecayed learning rates, g_lr: 0.00009771, d_lr: 0.00009771.\nDecayed learning rates, g_lr: 0.00009771, d_lr: 0.00009771.\nElapsed [7:40:14], Iteration [14600/30000], Dataset [1], D/loss_real: -1.3672, D/loss_fake: -1.5562, D/loss_cls: 1.3835, D/loss_gp: 0.0181, G/loss_fake: 1.8887, G/loss_rec: 0.1517, G/loss_cls: 0.9889\nElapsed [7:40:16], Iteration [14600/30000], Dataset [2], D/loss_real: -3.6897, D/loss_fake: 0.3025, D/loss_cls: 0.9001, D/loss_gp: 0.0237, G/loss_fake: 0.3001, G/loss_rec: 0.1486, G/loss_cls: 0.3458\nElapsed [7:40:17], Iteration [14600/30000], Dataset [3], D/loss_real: -1.1570, D/loss_fake: -1.2782, D/loss_cls: 0.0000, D/loss_gp: 0.0218, G/loss_fake: 2.4333, G/loss_rec: 0.0979, G/loss_cls: 0.0012\nDecayed learning rates, g_lr: 0.00009770, d_lr: 0.00009770.\nDecayed learning rates, g_lr: 0.00009770, d_lr: 0.00009770.\nDecayed learning rates, g_lr: 0.00009769, d_lr: 0.00009769.\nDecayed learning rates, g_lr: 0.00009769, d_lr: 0.00009769.\nDecayed learning rates, g_lr: 0.00009768, d_lr: 0.00009768.\nDecayed learning rates, g_lr: 0.00009768, d_lr: 0.00009768.\nDecayed learning rates, g_lr: 0.00009767, d_lr: 0.00009767.\nDecayed learning rates, g_lr: 0.00009767, d_lr: 0.00009767.\nDecayed learning rates, g_lr: 0.00009766, d_lr: 0.00009766.\nDecayed learning rates, g_lr: 0.00009766, d_lr: 0.00009766.\nElapsed [7:43:23], Iteration [14700/30000], Dataset [1], D/loss_real: -8.0186, D/loss_fake: 6.1467, D/loss_cls: 1.3457, D/loss_gp: 0.0298, G/loss_fake: -4.6008, G/loss_rec: 0.1504, G/loss_cls: 0.7268\nElapsed [7:43:25], Iteration [14700/30000], Dataset [2], D/loss_real: -6.7497, D/loss_fake: 5.1731, D/loss_cls: 0.5639, D/loss_gp: 0.0113, G/loss_fake: -3.7685, G/loss_rec: 0.1386, G/loss_cls: 0.4200\nElapsed [7:43:26], Iteration [14700/30000], Dataset [3], D/loss_real: -8.6297, D/loss_fake: 7.1486, D/loss_cls: 0.0000, D/loss_gp: 0.0078, G/loss_fake: -5.7594, G/loss_rec: 0.1007, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009765, d_lr: 0.00009765.\nDecayed learning rates, g_lr: 0.00009765, d_lr: 0.00009765.\nDecayed learning rates, g_lr: 0.00009764, d_lr: 0.00009764.\nDecayed learning rates, g_lr: 0.00009764, d_lr: 0.00009764.\nDecayed learning rates, g_lr: 0.00009763, d_lr: 0.00009763.\nDecayed learning rates, g_lr: 0.00009763, d_lr: 0.00009763.\nDecayed learning rates, g_lr: 0.00009762, d_lr: 0.00009762.\nDecayed learning rates, g_lr: 0.00009762, d_lr: 0.00009762.\nDecayed learning rates, g_lr: 0.00009761, d_lr: 0.00009761.\nDecayed learning rates, g_lr: 0.00009761, d_lr: 0.00009761.\nElapsed [7:46:32], Iteration [14800/30000], Dataset [1], D/loss_real: -1.6484, D/loss_fake: -1.0360, D/loss_cls: 1.0091, D/loss_gp: 0.0153, G/loss_fake: 1.7161, G/loss_rec: 0.1499, G/loss_cls: 0.7067\nElapsed [7:46:34], Iteration [14800/30000], Dataset [2], D/loss_real: -2.1900, D/loss_fake: -0.3462, D/loss_cls: 0.6061, D/loss_gp: 0.0163, G/loss_fake: 1.1162, G/loss_rec: 0.1435, G/loss_cls: 0.2958\nElapsed [7:46:35], Iteration [14800/30000], Dataset [3], D/loss_real: -0.9498, D/loss_fake: -0.9227, D/loss_cls: 0.0000, D/loss_gp: 0.0141, G/loss_fake: 1.3816, G/loss_rec: 0.0899, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009760, d_lr: 0.00009760.\nDecayed learning rates, g_lr: 0.00009760, d_lr: 0.00009760.\nDecayed learning rates, g_lr: 0.00009759, d_lr: 0.00009759.\nDecayed learning rates, g_lr: 0.00009759, d_lr: 0.00009759.\nDecayed learning rates, g_lr: 0.00009758, d_lr: 0.00009758.\nDecayed learning rates, g_lr: 0.00009758, d_lr: 0.00009758.\nDecayed learning rates, g_lr: 0.00009757, d_lr: 0.00009757.\nDecayed learning rates, g_lr: 0.00009757, d_lr: 0.00009757.\nDecayed learning rates, g_lr: 0.00009756, d_lr: 0.00009756.\nDecayed learning rates, g_lr: 0.00009756, d_lr: 0.00009756.\nElapsed [7:49:42], Iteration [14900/30000], Dataset [1], D/loss_real: -2.6834, D/loss_fake: -1.0654, D/loss_cls: 1.2195, D/loss_gp: 0.0349, G/loss_fake: 0.9415, G/loss_rec: 0.1712, G/loss_cls: 0.9322\nElapsed [7:49:43], Iteration [14900/30000], Dataset [2], D/loss_real: -3.3959, D/loss_fake: 1.3566, D/loss_cls: 0.7809, D/loss_gp: 0.0281, G/loss_fake: -0.0896, G/loss_rec: 0.1495, G/loss_cls: 0.2816\nElapsed [7:49:44], Iteration [14900/30000], Dataset [3], D/loss_real: -2.3154, D/loss_fake: 0.7654, D/loss_cls: 0.0000, D/loss_gp: 0.0137, G/loss_fake: 1.9577, G/loss_rec: 0.0913, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009755, d_lr: 0.00009755.\nDecayed learning rates, g_lr: 0.00009755, d_lr: 0.00009755.\nDecayed learning rates, g_lr: 0.00009754, d_lr: 0.00009754.\nDecayed learning rates, g_lr: 0.00009754, d_lr: 0.00009754.\nDecayed learning rates, g_lr: 0.00009753, d_lr: 0.00009753.\nDecayed learning rates, g_lr: 0.00009753, d_lr: 0.00009753.\nDecayed learning rates, g_lr: 0.00009752, d_lr: 0.00009752.\nDecayed learning rates, g_lr: 0.00009752, d_lr: 0.00009752.\nDecayed learning rates, g_lr: 0.00009751, d_lr: 0.00009751.\nDecayed learning rates, g_lr: 0.00009751, d_lr: 0.00009751.\nElapsed [7:52:51], Iteration [15000/30000], Dataset [1], D/loss_real: 0.5326, D/loss_fake: -2.2128, D/loss_cls: 1.7078, D/loss_gp: 0.0160, G/loss_fake: 2.0468, G/loss_rec: 0.1524, G/loss_cls: 0.9839\nElapsed [7:52:52], Iteration [15000/30000], Dataset [2], D/loss_real: 0.1035, D/loss_fake: -2.2988, D/loss_cls: 0.7852, D/loss_gp: 0.0189, G/loss_fake: 2.4838, G/loss_rec: 0.1433, G/loss_cls: 0.2039\nElapsed [7:52:53], Iteration [15000/30000], Dataset [3], D/loss_real: 0.2861, D/loss_fake: -1.5520, D/loss_cls: 0.0000, D/loss_gp: 0.0160, G/loss_fake: 1.7000, G/loss_rec: 0.0965, G/loss_cls: 0.0042\nDecayed learning rates, g_lr: 0.00009750, d_lr: 0.00009750.\nDecayed learning rates, g_lr: 0.00009750, d_lr: 0.00009750.\nDecayed learning rates, g_lr: 0.00009749, d_lr: 0.00009749.\nDecayed learning rates, g_lr: 0.00009749, d_lr: 0.00009749.\nDecayed learning rates, g_lr: 0.00009748, d_lr: 0.00009748.\nDecayed learning rates, g_lr: 0.00009748, d_lr: 0.00009748.\nDecayed learning rates, g_lr: 0.00009747, d_lr: 0.00009747.\nDecayed learning rates, g_lr: 0.00009747, d_lr: 0.00009747.\nDecayed learning rates, g_lr: 0.00009746, d_lr: 0.00009746.\nDecayed learning rates, g_lr: 0.00009746, d_lr: 0.00009746.\nElapsed [7:56:00], Iteration [15100/30000], Dataset [1], D/loss_real: -3.7659, D/loss_fake: 1.0872, D/loss_cls: 1.2308, D/loss_gp: 0.0285, G/loss_fake: -1.5272, G/loss_rec: 0.1480, G/loss_cls: 0.7618\nElapsed [7:56:01], Iteration [15100/30000], Dataset [2], D/loss_real: -4.0716, D/loss_fake: 1.9001, D/loss_cls: 0.7208, D/loss_gp: 0.0222, G/loss_fake: -1.7678, G/loss_rec: 0.1383, G/loss_cls: 0.3165\nElapsed [7:56:02], Iteration [15100/30000], Dataset [3], D/loss_real: -3.9792, D/loss_fake: 2.3374, D/loss_cls: 0.1419, D/loss_gp: 0.0128, G/loss_fake: -2.1468, G/loss_rec: 0.0952, G/loss_cls: 0.0003\nDecayed learning rates, g_lr: 0.00009745, d_lr: 0.00009745.\nDecayed learning rates, g_lr: 0.00009745, d_lr: 0.00009745.\nDecayed learning rates, g_lr: 0.00009744, d_lr: 0.00009744.\nDecayed learning rates, g_lr: 0.00009744, d_lr: 0.00009744.\nDecayed learning rates, g_lr: 0.00009743, d_lr: 0.00009743.\nDecayed learning rates, g_lr: 0.00009743, d_lr: 0.00009743.\nDecayed learning rates, g_lr: 0.00009742, d_lr: 0.00009742.\nDecayed learning rates, g_lr: 0.00009742, d_lr: 0.00009742.\nDecayed learning rates, g_lr: 0.00009741, d_lr: 0.00009741.\nDecayed learning rates, g_lr: 0.00009741, d_lr: 0.00009741.\nElapsed [7:59:09], Iteration [15200/30000], Dataset [1], D/loss_real: -5.8027, D/loss_fake: 3.5841, D/loss_cls: 1.3124, D/loss_gp: 0.0184, G/loss_fake: -3.4925, G/loss_rec: 0.1441, G/loss_cls: 0.8566\nElapsed [7:59:10], Iteration [15200/30000], Dataset [2], D/loss_real: -5.8500, D/loss_fake: 4.8223, D/loss_cls: 0.7413, D/loss_gp: 0.0218, G/loss_fake: -3.2422, G/loss_rec: 0.1500, G/loss_cls: 0.2585\nElapsed [7:59:11], Iteration [15200/30000], Dataset [3], D/loss_real: -4.2900, D/loss_fake: 3.7432, D/loss_cls: 0.0000, D/loss_gp: 0.0068, G/loss_fake: -1.0650, G/loss_rec: 0.1076, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009740, d_lr: 0.00009740.\nDecayed learning rates, g_lr: 0.00009740, d_lr: 0.00009740.\nDecayed learning rates, g_lr: 0.00009739, d_lr: 0.00009739.\nDecayed learning rates, g_lr: 0.00009739, d_lr: 0.00009739.\nDecayed learning rates, g_lr: 0.00009738, d_lr: 0.00009738.\nDecayed learning rates, g_lr: 0.00009738, d_lr: 0.00009738.\nDecayed learning rates, g_lr: 0.00009737, d_lr: 0.00009737.\nDecayed learning rates, g_lr: 0.00009737, d_lr: 0.00009737.\nDecayed learning rates, g_lr: 0.00009736, d_lr: 0.00009736.\nDecayed learning rates, g_lr: 0.00009736, d_lr: 0.00009736.\nElapsed [8:02:18], Iteration [15300/30000], Dataset [1], D/loss_real: -4.3577, D/loss_fake: 0.5701, D/loss_cls: 1.8112, D/loss_gp: 0.0360, G/loss_fake: -1.8823, G/loss_rec: 0.1636, G/loss_cls: 1.2288\nElapsed [8:02:19], Iteration [15300/30000], Dataset [2], D/loss_real: -5.9257, D/loss_fake: 3.2349, D/loss_cls: 1.5591, D/loss_gp: 0.0267, G/loss_fake: -2.7162, G/loss_rec: 0.1454, G/loss_cls: 0.3231\nElapsed [8:02:21], Iteration [15300/30000], Dataset [3], D/loss_real: -2.9343, D/loss_fake: 2.0130, D/loss_cls: 0.0002, D/loss_gp: 0.0131, G/loss_fake: 0.3839, G/loss_rec: 0.0938, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009735, d_lr: 0.00009735.\nDecayed learning rates, g_lr: 0.00009735, d_lr: 0.00009735.\nDecayed learning rates, g_lr: 0.00009734, d_lr: 0.00009734.\nDecayed learning rates, g_lr: 0.00009734, d_lr: 0.00009734.\nDecayed learning rates, g_lr: 0.00009733, d_lr: 0.00009733.\nDecayed learning rates, g_lr: 0.00009733, d_lr: 0.00009733.\nDecayed learning rates, g_lr: 0.00009732, d_lr: 0.00009732.\nDecayed learning rates, g_lr: 0.00009732, d_lr: 0.00009732.\nDecayed learning rates, g_lr: 0.00009731, d_lr: 0.00009731.\nDecayed learning rates, g_lr: 0.00009731, d_lr: 0.00009731.\nElapsed [8:05:27], Iteration [15400/30000], Dataset [1], D/loss_real: -3.8810, D/loss_fake: 1.9818, D/loss_cls: 1.5517, D/loss_gp: 0.0123, G/loss_fake: -1.8381, G/loss_rec: 0.1515, G/loss_cls: 0.8000\nElapsed [8:05:28], Iteration [15400/30000], Dataset [2], D/loss_real: -3.9793, D/loss_fake: 2.1767, D/loss_cls: 0.6859, D/loss_gp: 0.0101, G/loss_fake: -1.4328, G/loss_rec: 0.1386, G/loss_cls: 0.3316\nElapsed [8:05:30], Iteration [15400/30000], Dataset [3], D/loss_real: -4.4347, D/loss_fake: 3.0838, D/loss_cls: 0.0027, D/loss_gp: 0.0144, G/loss_fake: -1.5515, G/loss_rec: 0.0976, G/loss_cls: 0.0003\nDecayed learning rates, g_lr: 0.00009730, d_lr: 0.00009730.\nDecayed learning rates, g_lr: 0.00009730, d_lr: 0.00009730.\nDecayed learning rates, g_lr: 0.00009729, d_lr: 0.00009729.\nDecayed learning rates, g_lr: 0.00009729, d_lr: 0.00009729.\nDecayed learning rates, g_lr: 0.00009728, d_lr: 0.00009728.\nDecayed learning rates, g_lr: 0.00009728, d_lr: 0.00009728.\nDecayed learning rates, g_lr: 0.00009727, d_lr: 0.00009727.\nDecayed learning rates, g_lr: 0.00009727, d_lr: 0.00009727.\nDecayed learning rates, g_lr: 0.00009726, d_lr: 0.00009726.\nDecayed learning rates, g_lr: 0.00009726, d_lr: 0.00009726.\nElapsed [8:08:36], Iteration [15500/30000], Dataset [1], D/loss_real: -6.4211, D/loss_fake: 4.0330, D/loss_cls: 1.2597, D/loss_gp: 0.0244, G/loss_fake: -2.9226, G/loss_rec: 0.1597, G/loss_cls: 0.7581\nElapsed [8:08:37], Iteration [15500/30000], Dataset [2], D/loss_real: -5.3798, D/loss_fake: 3.3322, D/loss_cls: 0.6968, D/loss_gp: 0.0161, G/loss_fake: -2.3723, G/loss_rec: 0.1577, G/loss_cls: 0.2241\nElapsed [8:08:39], Iteration [15500/30000], Dataset [3], D/loss_real: -7.4573, D/loss_fake: 6.0003, D/loss_cls: 0.0000, D/loss_gp: 0.0081, G/loss_fake: -5.5851, G/loss_rec: 0.0990, G/loss_cls: 0.0012\nDecayed learning rates, g_lr: 0.00009725, d_lr: 0.00009725.\nDecayed learning rates, g_lr: 0.00009725, d_lr: 0.00009725.\nDecayed learning rates, g_lr: 0.00009724, d_lr: 0.00009724.\nDecayed learning rates, g_lr: 0.00009724, d_lr: 0.00009724.\nDecayed learning rates, g_lr: 0.00009723, d_lr: 0.00009723.\nDecayed learning rates, g_lr: 0.00009723, d_lr: 0.00009723.\nDecayed learning rates, g_lr: 0.00009722, d_lr: 0.00009722.\nDecayed learning rates, g_lr: 0.00009722, d_lr: 0.00009722.\nDecayed learning rates, g_lr: 0.00009721, d_lr: 0.00009721.\nDecayed learning rates, g_lr: 0.00009721, d_lr: 0.00009721.\nElapsed [8:11:44], Iteration [15600/30000], Dataset [1], D/loss_real: -3.4173, D/loss_fake: -1.6194, D/loss_cls: 2.4288, D/loss_gp: 0.0433, G/loss_fake: 1.5645, G/loss_rec: 0.1831, G/loss_cls: 1.2130\nElapsed [8:11:45], Iteration [15600/30000], Dataset [2], D/loss_real: -5.2171, D/loss_fake: 1.5325, D/loss_cls: 1.9318, D/loss_gp: 0.0422, G/loss_fake: -4.1515, G/loss_rec: 0.1435, G/loss_cls: 0.4364\nElapsed [8:11:47], Iteration [15600/30000], Dataset [3], D/loss_real: -5.0015, D/loss_fake: 3.2897, D/loss_cls: 0.0001, D/loss_gp: 0.0101, G/loss_fake: 0.0739, G/loss_rec: 0.1022, G/loss_cls: 0.0398\nDecayed learning rates, g_lr: 0.00009720, d_lr: 0.00009720.\nDecayed learning rates, g_lr: 0.00009720, d_lr: 0.00009720.\nDecayed learning rates, g_lr: 0.00009719, d_lr: 0.00009719.\nDecayed learning rates, g_lr: 0.00009719, d_lr: 0.00009719.\nDecayed learning rates, g_lr: 0.00009718, d_lr: 0.00009718.\nDecayed learning rates, g_lr: 0.00009718, d_lr: 0.00009718.\nDecayed learning rates, g_lr: 0.00009717, d_lr: 0.00009717.\nDecayed learning rates, g_lr: 0.00009717, d_lr: 0.00009717.\nDecayed learning rates, g_lr: 0.00009716, d_lr: 0.00009716.\nDecayed learning rates, g_lr: 0.00009716, d_lr: 0.00009716.\nElapsed [8:14:53], Iteration [15700/30000], Dataset [1], D/loss_real: -8.0554, D/loss_fake: 4.2322, D/loss_cls: 1.2103, D/loss_gp: 0.0397, G/loss_fake: -2.8126, G/loss_rec: 0.1759, G/loss_cls: 0.8307\nElapsed [8:14:54], Iteration [15700/30000], Dataset [2], D/loss_real: -4.8485, D/loss_fake: 3.2855, D/loss_cls: 0.8455, D/loss_gp: 0.0311, G/loss_fake: -0.9508, G/loss_rec: 0.1490, G/loss_cls: 0.4974\nElapsed [8:14:55], Iteration [15700/30000], Dataset [3], D/loss_real: -0.2619, D/loss_fake: -1.8091, D/loss_cls: 0.0457, D/loss_gp: 0.0092, G/loss_fake: 2.9432, G/loss_rec: 0.1071, G/loss_cls: 0.0022\nDecayed learning rates, g_lr: 0.00009715, d_lr: 0.00009715.\nDecayed learning rates, g_lr: 0.00009715, d_lr: 0.00009715.\nDecayed learning rates, g_lr: 0.00009714, d_lr: 0.00009714.\nDecayed learning rates, g_lr: 0.00009714, d_lr: 0.00009714.\nDecayed learning rates, g_lr: 0.00009713, d_lr: 0.00009713.\nDecayed learning rates, g_lr: 0.00009713, d_lr: 0.00009713.\nDecayed learning rates, g_lr: 0.00009712, d_lr: 0.00009712.\nDecayed learning rates, g_lr: 0.00009712, d_lr: 0.00009712.\nDecayed learning rates, g_lr: 0.00009711, d_lr: 0.00009711.\nDecayed learning rates, g_lr: 0.00009711, d_lr: 0.00009711.\nElapsed [8:18:02], Iteration [15800/30000], Dataset [1], D/loss_real: -4.7893, D/loss_fake: 1.7942, D/loss_cls: 1.3654, D/loss_gp: 0.0228, G/loss_fake: -1.0895, G/loss_rec: 0.1543, G/loss_cls: 0.9843\nElapsed [8:18:03], Iteration [15800/30000], Dataset [2], D/loss_real: -4.8626, D/loss_fake: 2.1414, D/loss_cls: 0.9255, D/loss_gp: 0.0168, G/loss_fake: -1.5461, G/loss_rec: 0.1437, G/loss_cls: 0.3850\nElapsed [8:18:04], Iteration [15800/30000], Dataset [3], D/loss_real: -4.4538, D/loss_fake: 2.6971, D/loss_cls: 0.0000, D/loss_gp: 0.0215, G/loss_fake: -1.7124, G/loss_rec: 0.0950, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009710, d_lr: 0.00009710.\nDecayed learning rates, g_lr: 0.00009710, d_lr: 0.00009710.\nDecayed learning rates, g_lr: 0.00009709, d_lr: 0.00009709.\nDecayed learning rates, g_lr: 0.00009709, d_lr: 0.00009709.\nDecayed learning rates, g_lr: 0.00009708, d_lr: 0.00009708.\nDecayed learning rates, g_lr: 0.00009708, d_lr: 0.00009708.\nDecayed learning rates, g_lr: 0.00009707, d_lr: 0.00009707.\nDecayed learning rates, g_lr: 0.00009707, d_lr: 0.00009707.\nDecayed learning rates, g_lr: 0.00009706, d_lr: 0.00009706.\nDecayed learning rates, g_lr: 0.00009706, d_lr: 0.00009706.\nElapsed [8:21:11], Iteration [15900/30000], Dataset [1], D/loss_real: -5.6153, D/loss_fake: 3.1304, D/loss_cls: 1.2848, D/loss_gp: 0.0204, G/loss_fake: -3.1009, G/loss_rec: 0.1461, G/loss_cls: 0.7706\nElapsed [8:21:12], Iteration [15900/30000], Dataset [2], D/loss_real: -6.3249, D/loss_fake: 4.1953, D/loss_cls: 0.8051, D/loss_gp: 0.0187, G/loss_fake: -4.0557, G/loss_rec: 0.1339, G/loss_cls: 0.2508\nElapsed [8:21:13], Iteration [15900/30000], Dataset [3], D/loss_real: -7.4941, D/loss_fake: 5.4688, D/loss_cls: 0.0000, D/loss_gp: 0.0264, G/loss_fake: -4.3695, G/loss_rec: 0.0923, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009705, d_lr: 0.00009705.\nDecayed learning rates, g_lr: 0.00009705, d_lr: 0.00009705.\nDecayed learning rates, g_lr: 0.00009704, d_lr: 0.00009704.\nDecayed learning rates, g_lr: 0.00009704, d_lr: 0.00009704.\nDecayed learning rates, g_lr: 0.00009703, d_lr: 0.00009703.\nDecayed learning rates, g_lr: 0.00009703, d_lr: 0.00009703.\nDecayed learning rates, g_lr: 0.00009702, d_lr: 0.00009702.\nDecayed learning rates, g_lr: 0.00009702, d_lr: 0.00009702.\nDecayed learning rates, g_lr: 0.00009701, d_lr: 0.00009701.\nDecayed learning rates, g_lr: 0.00009701, d_lr: 0.00009701.\nElapsed [8:24:20], Iteration [16000/30000], Dataset [1], D/loss_real: -6.2380, D/loss_fake: 4.2734, D/loss_cls: 1.7639, D/loss_gp: 0.0126, G/loss_fake: -4.0824, G/loss_rec: 0.1405, G/loss_cls: 0.6237\nElapsed [8:24:21], Iteration [16000/30000], Dataset [2], D/loss_real: -6.0307, D/loss_fake: 4.7643, D/loss_cls: 0.5931, D/loss_gp: 0.0196, G/loss_fake: -3.8942, G/loss_rec: 0.1396, G/loss_cls: 0.2857\nElapsed [8:24:22], Iteration [16000/30000], Dataset [3], D/loss_real: -1.9644, D/loss_fake: 0.5565, D/loss_cls: 0.0000, D/loss_gp: 0.0126, G/loss_fake: 0.7936, G/loss_rec: 0.0935, G/loss_cls: 0.0001\nSaved real and fake images into /kaggle/working/exps/visualization/16000...\nSaved model checkpoints at iteration 16000 into /kaggle/working/exps/checkpoints...\nDecayed learning rates, g_lr: 0.00009700, d_lr: 0.00009700.\nDecayed learning rates, g_lr: 0.00009700, d_lr: 0.00009700.\nDecayed learning rates, g_lr: 0.00009699, d_lr: 0.00009699.\nDecayed learning rates, g_lr: 0.00009699, d_lr: 0.00009699.\nDecayed learning rates, g_lr: 0.00009698, d_lr: 0.00009698.\nDecayed learning rates, g_lr: 0.00009698, d_lr: 0.00009698.\nDecayed learning rates, g_lr: 0.00009697, d_lr: 0.00009697.\nDecayed learning rates, g_lr: 0.00009697, d_lr: 0.00009697.\nDecayed learning rates, g_lr: 0.00009696, d_lr: 0.00009696.\nDecayed learning rates, g_lr: 0.00009696, d_lr: 0.00009696.\nElapsed [8:27:31], Iteration [16100/30000], Dataset [1], D/loss_real: -0.5134, D/loss_fake: -2.1640, D/loss_cls: 1.2871, D/loss_gp: 0.0393, G/loss_fake: 1.4897, G/loss_rec: 0.1373, G/loss_cls: 0.8359\nElapsed [8:27:32], Iteration [16100/30000], Dataset [2], D/loss_real: -0.1203, D/loss_fake: -2.2410, D/loss_cls: 0.6782, D/loss_gp: 0.0234, G/loss_fake: 2.4185, G/loss_rec: 0.1367, G/loss_cls: 0.2952\nElapsed [8:27:33], Iteration [16100/30000], Dataset [3], D/loss_real: -1.9494, D/loss_fake: 0.2454, D/loss_cls: 0.0001, D/loss_gp: 0.0131, G/loss_fake: 0.2749, G/loss_rec: 0.0949, G/loss_cls: 0.0009\nDecayed learning rates, g_lr: 0.00009695, d_lr: 0.00009695.\nDecayed learning rates, g_lr: 0.00009695, d_lr: 0.00009695.\nDecayed learning rates, g_lr: 0.00009694, d_lr: 0.00009694.\nDecayed learning rates, g_lr: 0.00009694, d_lr: 0.00009694.\nDecayed learning rates, g_lr: 0.00009693, d_lr: 0.00009693.\nDecayed learning rates, g_lr: 0.00009693, d_lr: 0.00009693.\nDecayed learning rates, g_lr: 0.00009692, d_lr: 0.00009692.\nDecayed learning rates, g_lr: 0.00009692, d_lr: 0.00009692.\nDecayed learning rates, g_lr: 0.00009691, d_lr: 0.00009691.\nDecayed learning rates, g_lr: 0.00009691, d_lr: 0.00009691.\nElapsed [8:30:40], Iteration [16200/30000], Dataset [1], D/loss_real: -5.4512, D/loss_fake: 3.7239, D/loss_cls: 1.1749, D/loss_gp: 0.0081, G/loss_fake: -3.4037, G/loss_rec: 0.1347, G/loss_cls: 0.7207\nElapsed [8:30:41], Iteration [16200/30000], Dataset [2], D/loss_real: -5.3938, D/loss_fake: 3.8858, D/loss_cls: 0.6594, D/loss_gp: 0.0166, G/loss_fake: -3.6104, G/loss_rec: 0.1380, G/loss_cls: 0.3037\nElapsed [8:30:42], Iteration [16200/30000], Dataset [3], D/loss_real: -5.2296, D/loss_fake: 4.0633, D/loss_cls: 0.0000, D/loss_gp: 0.0064, G/loss_fake: -3.3395, G/loss_rec: 0.1021, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009690, d_lr: 0.00009690.\nDecayed learning rates, g_lr: 0.00009690, d_lr: 0.00009690.\nDecayed learning rates, g_lr: 0.00009689, d_lr: 0.00009689.\nDecayed learning rates, g_lr: 0.00009689, d_lr: 0.00009689.\nDecayed learning rates, g_lr: 0.00009688, d_lr: 0.00009688.\nDecayed learning rates, g_lr: 0.00009688, d_lr: 0.00009688.\nDecayed learning rates, g_lr: 0.00009687, d_lr: 0.00009687.\nDecayed learning rates, g_lr: 0.00009687, d_lr: 0.00009687.\nDecayed learning rates, g_lr: 0.00009686, d_lr: 0.00009686.\nDecayed learning rates, g_lr: 0.00009686, d_lr: 0.00009686.\nElapsed [8:33:49], Iteration [16300/30000], Dataset [1], D/loss_real: -6.2906, D/loss_fake: 3.5218, D/loss_cls: 1.4311, D/loss_gp: 0.0168, G/loss_fake: -2.5660, G/loss_rec: 0.1601, G/loss_cls: 0.9609\nElapsed [8:33:50], Iteration [16300/30000], Dataset [2], D/loss_real: -5.8161, D/loss_fake: 3.4917, D/loss_cls: 0.6046, D/loss_gp: 0.0174, G/loss_fake: -2.9365, G/loss_rec: 0.1498, G/loss_cls: 0.3323\nElapsed [8:33:51], Iteration [16300/30000], Dataset [3], D/loss_real: -3.6064, D/loss_fake: 1.9005, D/loss_cls: 0.0001, D/loss_gp: 0.0194, G/loss_fake: -0.1946, G/loss_rec: 0.0946, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009685, d_lr: 0.00009685.\nDecayed learning rates, g_lr: 0.00009685, d_lr: 0.00009685.\nDecayed learning rates, g_lr: 0.00009684, d_lr: 0.00009684.\nDecayed learning rates, g_lr: 0.00009684, d_lr: 0.00009684.\nDecayed learning rates, g_lr: 0.00009683, d_lr: 0.00009683.\nDecayed learning rates, g_lr: 0.00009683, d_lr: 0.00009683.\nDecayed learning rates, g_lr: 0.00009682, d_lr: 0.00009682.\nDecayed learning rates, g_lr: 0.00009682, d_lr: 0.00009682.\nDecayed learning rates, g_lr: 0.00009681, d_lr: 0.00009681.\nDecayed learning rates, g_lr: 0.00009681, d_lr: 0.00009681.\nElapsed [8:36:58], Iteration [16400/30000], Dataset [1], D/loss_real: -1.8350, D/loss_fake: -2.1380, D/loss_cls: 1.3316, D/loss_gp: 0.0443, G/loss_fake: 2.0688, G/loss_rec: 0.1680, G/loss_cls: 1.0345\nElapsed [8:36:59], Iteration [16400/30000], Dataset [2], D/loss_real: -2.1155, D/loss_fake: -0.5843, D/loss_cls: 0.7102, D/loss_gp: 0.0363, G/loss_fake: 0.5699, G/loss_rec: 0.1412, G/loss_cls: 0.2812\nElapsed [8:37:00], Iteration [16400/30000], Dataset [3], D/loss_real: -3.3490, D/loss_fake: 1.5666, D/loss_cls: 0.0000, D/loss_gp: 0.0094, G/loss_fake: -0.5823, G/loss_rec: 0.0998, G/loss_cls: 0.0043\nDecayed learning rates, g_lr: 0.00009680, d_lr: 0.00009680.\nDecayed learning rates, g_lr: 0.00009680, d_lr: 0.00009680.\nDecayed learning rates, g_lr: 0.00009679, d_lr: 0.00009679.\nDecayed learning rates, g_lr: 0.00009679, d_lr: 0.00009679.\nDecayed learning rates, g_lr: 0.00009678, d_lr: 0.00009678.\nDecayed learning rates, g_lr: 0.00009678, d_lr: 0.00009678.\nDecayed learning rates, g_lr: 0.00009677, d_lr: 0.00009677.\nDecayed learning rates, g_lr: 0.00009677, d_lr: 0.00009677.\nDecayed learning rates, g_lr: 0.00009676, d_lr: 0.00009676.\nDecayed learning rates, g_lr: 0.00009676, d_lr: 0.00009676.\nElapsed [8:40:07], Iteration [16500/30000], Dataset [1], D/loss_real: -7.4519, D/loss_fake: 4.5406, D/loss_cls: 1.3699, D/loss_gp: 0.0216, G/loss_fake: -4.9161, G/loss_rec: 0.1528, G/loss_cls: 0.6684\nElapsed [8:40:08], Iteration [16500/30000], Dataset [2], D/loss_real: -7.5305, D/loss_fake: 5.7025, D/loss_cls: 0.5617, D/loss_gp: 0.0270, G/loss_fake: -3.0944, G/loss_rec: 0.1571, G/loss_cls: 0.2416\nElapsed [8:40:09], Iteration [16500/30000], Dataset [3], D/loss_real: -5.4179, D/loss_fake: 4.5000, D/loss_cls: 0.0000, D/loss_gp: 0.0067, G/loss_fake: -2.0732, G/loss_rec: 0.0989, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009675, d_lr: 0.00009675.\nDecayed learning rates, g_lr: 0.00009675, d_lr: 0.00009675.\nDecayed learning rates, g_lr: 0.00009674, d_lr: 0.00009674.\nDecayed learning rates, g_lr: 0.00009674, d_lr: 0.00009674.\nDecayed learning rates, g_lr: 0.00009673, d_lr: 0.00009673.\nDecayed learning rates, g_lr: 0.00009673, d_lr: 0.00009673.\nDecayed learning rates, g_lr: 0.00009672, d_lr: 0.00009672.\nDecayed learning rates, g_lr: 0.00009672, d_lr: 0.00009672.\nDecayed learning rates, g_lr: 0.00009671, d_lr: 0.00009671.\nDecayed learning rates, g_lr: 0.00009671, d_lr: 0.00009671.\nElapsed [8:43:16], Iteration [16600/30000], Dataset [1], D/loss_real: -2.3942, D/loss_fake: 0.2000, D/loss_cls: 0.8688, D/loss_gp: 0.0113, G/loss_fake: -0.0404, G/loss_rec: 0.1481, G/loss_cls: 0.5284\nElapsed [8:43:17], Iteration [16600/30000], Dataset [2], D/loss_real: -2.9823, D/loss_fake: 1.1458, D/loss_cls: 0.4841, D/loss_gp: 0.0112, G/loss_fake: -1.5280, G/loss_rec: 0.1299, G/loss_cls: 0.2514\nElapsed [8:43:18], Iteration [16600/30000], Dataset [3], D/loss_real: -0.7411, D/loss_fake: -0.6881, D/loss_cls: 0.0000, D/loss_gp: 0.0125, G/loss_fake: 0.9135, G/loss_rec: 0.0900, G/loss_cls: 0.0029\nDecayed learning rates, g_lr: 0.00009670, d_lr: 0.00009670.\nDecayed learning rates, g_lr: 0.00009670, d_lr: 0.00009670.\nDecayed learning rates, g_lr: 0.00009669, d_lr: 0.00009669.\nDecayed learning rates, g_lr: 0.00009669, d_lr: 0.00009669.\nDecayed learning rates, g_lr: 0.00009668, d_lr: 0.00009668.\nDecayed learning rates, g_lr: 0.00009668, d_lr: 0.00009668.\nDecayed learning rates, g_lr: 0.00009667, d_lr: 0.00009667.\nDecayed learning rates, g_lr: 0.00009667, d_lr: 0.00009667.\nDecayed learning rates, g_lr: 0.00009666, d_lr: 0.00009666.\nDecayed learning rates, g_lr: 0.00009666, d_lr: 0.00009666.\nElapsed [8:46:25], Iteration [16700/30000], Dataset [1], D/loss_real: -1.3956, D/loss_fake: -1.3160, D/loss_cls: 1.6345, D/loss_gp: 0.0318, G/loss_fake: 1.5580, G/loss_rec: 0.1510, G/loss_cls: 0.6896\nElapsed [8:46:26], Iteration [16700/30000], Dataset [2], D/loss_real: -2.9861, D/loss_fake: -0.1804, D/loss_cls: 0.7574, D/loss_gp: 0.0207, G/loss_fake: -0.1520, G/loss_rec: 0.1354, G/loss_cls: 0.2438\nElapsed [8:46:27], Iteration [16700/30000], Dataset [3], D/loss_real: 1.7309, D/loss_fake: -2.7938, D/loss_cls: 0.0000, D/loss_gp: 0.0337, G/loss_fake: 3.1609, G/loss_rec: 0.0882, G/loss_cls: 0.0791\nDecayed learning rates, g_lr: 0.00009665, d_lr: 0.00009665.\nDecayed learning rates, g_lr: 0.00009665, d_lr: 0.00009665.\nDecayed learning rates, g_lr: 0.00009664, d_lr: 0.00009664.\nDecayed learning rates, g_lr: 0.00009664, d_lr: 0.00009664.\nDecayed learning rates, g_lr: 0.00009663, d_lr: 0.00009663.\nDecayed learning rates, g_lr: 0.00009663, d_lr: 0.00009663.\nDecayed learning rates, g_lr: 0.00009662, d_lr: 0.00009662.\nDecayed learning rates, g_lr: 0.00009662, d_lr: 0.00009662.\nDecayed learning rates, g_lr: 0.00009661, d_lr: 0.00009661.\nDecayed learning rates, g_lr: 0.00009661, d_lr: 0.00009661.\nElapsed [8:49:34], Iteration [16800/30000], Dataset [1], D/loss_real: -5.6883, D/loss_fake: 3.2972, D/loss_cls: 1.5497, D/loss_gp: 0.0182, G/loss_fake: -2.4776, G/loss_rec: 0.1406, G/loss_cls: 0.7514\nElapsed [8:49:35], Iteration [16800/30000], Dataset [2], D/loss_real: -4.0564, D/loss_fake: 3.0580, D/loss_cls: 0.9716, D/loss_gp: 0.0153, G/loss_fake: -3.0184, G/loss_rec: 0.1500, G/loss_cls: 0.2710\nElapsed [8:49:36], Iteration [16800/30000], Dataset [3], D/loss_real: -7.6454, D/loss_fake: 6.9418, D/loss_cls: 0.0000, D/loss_gp: 0.0087, G/loss_fake: -6.6664, G/loss_rec: 0.0953, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009660, d_lr: 0.00009660.\nDecayed learning rates, g_lr: 0.00009660, d_lr: 0.00009660.\nDecayed learning rates, g_lr: 0.00009659, d_lr: 0.00009659.\nDecayed learning rates, g_lr: 0.00009659, d_lr: 0.00009659.\nDecayed learning rates, g_lr: 0.00009658, d_lr: 0.00009658.\nDecayed learning rates, g_lr: 0.00009658, d_lr: 0.00009658.\nDecayed learning rates, g_lr: 0.00009657, d_lr: 0.00009657.\nDecayed learning rates, g_lr: 0.00009657, d_lr: 0.00009657.\nDecayed learning rates, g_lr: 0.00009656, d_lr: 0.00009656.\nDecayed learning rates, g_lr: 0.00009656, d_lr: 0.00009656.\nElapsed [8:52:43], Iteration [16900/30000], Dataset [1], D/loss_real: -3.7789, D/loss_fake: 1.3497, D/loss_cls: 1.1104, D/loss_gp: 0.0107, G/loss_fake: -1.9955, G/loss_rec: 0.1443, G/loss_cls: 0.7246\nElapsed [8:52:44], Iteration [16900/30000], Dataset [2], D/loss_real: -4.6895, D/loss_fake: 2.7181, D/loss_cls: 0.6001, D/loss_gp: 0.0248, G/loss_fake: -2.3696, G/loss_rec: 0.1293, G/loss_cls: 0.2297\nElapsed [8:52:45], Iteration [16900/30000], Dataset [3], D/loss_real: -3.5716, D/loss_fake: 2.4935, D/loss_cls: 0.0011, D/loss_gp: 0.0100, G/loss_fake: -1.5007, G/loss_rec: 0.0876, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009655, d_lr: 0.00009655.\nDecayed learning rates, g_lr: 0.00009655, d_lr: 0.00009655.\nDecayed learning rates, g_lr: 0.00009654, d_lr: 0.00009654.\nDecayed learning rates, g_lr: 0.00009654, d_lr: 0.00009654.\nDecayed learning rates, g_lr: 0.00009653, d_lr: 0.00009653.\nDecayed learning rates, g_lr: 0.00009653, d_lr: 0.00009653.\nDecayed learning rates, g_lr: 0.00009652, d_lr: 0.00009652.\nDecayed learning rates, g_lr: 0.00009652, d_lr: 0.00009652.\nDecayed learning rates, g_lr: 0.00009651, d_lr: 0.00009651.\nDecayed learning rates, g_lr: 0.00009651, d_lr: 0.00009651.\nElapsed [8:55:52], Iteration [17000/30000], Dataset [1], D/loss_real: -3.6822, D/loss_fake: 0.4848, D/loss_cls: 1.1203, D/loss_gp: 0.0181, G/loss_fake: -2.4500, G/loss_rec: 0.1669, G/loss_cls: 0.6726\nElapsed [8:55:53], Iteration [17000/30000], Dataset [2], D/loss_real: -6.4599, D/loss_fake: 4.6163, D/loss_cls: 0.8456, D/loss_gp: 0.0166, G/loss_fake: -4.6162, G/loss_rec: 0.1405, G/loss_cls: 0.2344\nElapsed [8:55:54], Iteration [17000/30000], Dataset [3], D/loss_real: -4.4849, D/loss_fake: 3.6874, D/loss_cls: 0.0000, D/loss_gp: 0.0107, G/loss_fake: -1.7843, G/loss_rec: 0.0974, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009650, d_lr: 0.00009650.\nDecayed learning rates, g_lr: 0.00009650, d_lr: 0.00009650.\nDecayed learning rates, g_lr: 0.00009649, d_lr: 0.00009649.\nDecayed learning rates, g_lr: 0.00009649, d_lr: 0.00009649.\nDecayed learning rates, g_lr: 0.00009648, d_lr: 0.00009648.\nDecayed learning rates, g_lr: 0.00009648, d_lr: 0.00009648.\nDecayed learning rates, g_lr: 0.00009647, d_lr: 0.00009647.\nDecayed learning rates, g_lr: 0.00009647, d_lr: 0.00009647.\nDecayed learning rates, g_lr: 0.00009646, d_lr: 0.00009646.\nDecayed learning rates, g_lr: 0.00009646, d_lr: 0.00009646.\nElapsed [8:59:01], Iteration [17100/30000], Dataset [1], D/loss_real: -1.2289, D/loss_fake: -1.7920, D/loss_cls: 1.4786, D/loss_gp: 0.0184, G/loss_fake: 1.9848, G/loss_rec: 0.1557, G/loss_cls: 0.7032\nElapsed [8:59:02], Iteration [17100/30000], Dataset [2], D/loss_real: -2.8120, D/loss_fake: 0.5973, D/loss_cls: 0.7998, D/loss_gp: 0.0142, G/loss_fake: 0.5464, G/loss_rec: 0.1309, G/loss_cls: 0.3219\nElapsed [8:59:03], Iteration [17100/30000], Dataset [3], D/loss_real: -6.8097, D/loss_fake: 4.5958, D/loss_cls: 0.0000, D/loss_gp: 0.0259, G/loss_fake: -1.4405, G/loss_rec: 0.0963, G/loss_cls: 0.0004\nDecayed learning rates, g_lr: 0.00009645, d_lr: 0.00009645.\nDecayed learning rates, g_lr: 0.00009645, d_lr: 0.00009645.\nDecayed learning rates, g_lr: 0.00009644, d_lr: 0.00009644.\nDecayed learning rates, g_lr: 0.00009644, d_lr: 0.00009644.\nDecayed learning rates, g_lr: 0.00009643, d_lr: 0.00009643.\nDecayed learning rates, g_lr: 0.00009643, d_lr: 0.00009643.\nDecayed learning rates, g_lr: 0.00009642, d_lr: 0.00009642.\nDecayed learning rates, g_lr: 0.00009642, d_lr: 0.00009642.\nDecayed learning rates, g_lr: 0.00009641, d_lr: 0.00009641.\nDecayed learning rates, g_lr: 0.00009641, d_lr: 0.00009641.\nElapsed [9:02:10], Iteration [17200/30000], Dataset [1], D/loss_real: -10.1042, D/loss_fake: 6.4801, D/loss_cls: 2.0935, D/loss_gp: 0.0385, G/loss_fake: -3.4714, G/loss_rec: 0.1584, G/loss_cls: 0.9412\nElapsed [9:02:11], Iteration [17200/30000], Dataset [2], D/loss_real: -7.9236, D/loss_fake: 4.2271, D/loss_cls: 0.6100, D/loss_gp: 0.0385, G/loss_fake: -4.7206, G/loss_rec: 0.1320, G/loss_cls: 0.2070\nElapsed [9:02:12], Iteration [17200/30000], Dataset [3], D/loss_real: -4.8050, D/loss_fake: 3.3526, D/loss_cls: 0.0000, D/loss_gp: 0.0524, G/loss_fake: 0.2201, G/loss_rec: 0.0970, G/loss_cls: 0.0003\nDecayed learning rates, g_lr: 0.00009640, d_lr: 0.00009640.\nDecayed learning rates, g_lr: 0.00009640, d_lr: 0.00009640.\nDecayed learning rates, g_lr: 0.00009639, d_lr: 0.00009639.\nDecayed learning rates, g_lr: 0.00009639, d_lr: 0.00009639.\nDecayed learning rates, g_lr: 0.00009638, d_lr: 0.00009638.\nDecayed learning rates, g_lr: 0.00009638, d_lr: 0.00009638.\nDecayed learning rates, g_lr: 0.00009637, d_lr: 0.00009637.\nDecayed learning rates, g_lr: 0.00009637, d_lr: 0.00009637.\nDecayed learning rates, g_lr: 0.00009636, d_lr: 0.00009636.\nDecayed learning rates, g_lr: 0.00009636, d_lr: 0.00009636.\nElapsed [9:05:18], Iteration [17300/30000], Dataset [1], D/loss_real: -1.0509, D/loss_fake: -1.4896, D/loss_cls: 1.1253, D/loss_gp: 0.0137, G/loss_fake: 1.7473, G/loss_rec: 0.1520, G/loss_cls: 0.4742\nElapsed [9:05:20], Iteration [17300/30000], Dataset [2], D/loss_real: -0.9886, D/loss_fake: -1.0820, D/loss_cls: 1.0004, D/loss_gp: 0.0188, G/loss_fake: 0.4876, G/loss_rec: 0.1387, G/loss_cls: 0.2980\nElapsed [9:05:21], Iteration [17300/30000], Dataset [3], D/loss_real: -4.3652, D/loss_fake: 2.5785, D/loss_cls: 0.0000, D/loss_gp: 0.0170, G/loss_fake: -0.4275, G/loss_rec: 0.0962, G/loss_cls: 0.0013\nDecayed learning rates, g_lr: 0.00009635, d_lr: 0.00009635.\nDecayed learning rates, g_lr: 0.00009635, d_lr: 0.00009635.\nDecayed learning rates, g_lr: 0.00009634, d_lr: 0.00009634.\nDecayed learning rates, g_lr: 0.00009634, d_lr: 0.00009634.\nDecayed learning rates, g_lr: 0.00009633, d_lr: 0.00009633.\nDecayed learning rates, g_lr: 0.00009633, d_lr: 0.00009633.\nDecayed learning rates, g_lr: 0.00009632, d_lr: 0.00009632.\nDecayed learning rates, g_lr: 0.00009632, d_lr: 0.00009632.\nDecayed learning rates, g_lr: 0.00009631, d_lr: 0.00009631.\nDecayed learning rates, g_lr: 0.00009631, d_lr: 0.00009631.\nElapsed [9:08:27], Iteration [17400/30000], Dataset [1], D/loss_real: -2.1005, D/loss_fake: -0.8811, D/loss_cls: 1.1915, D/loss_gp: 0.0265, G/loss_fake: 0.5126, G/loss_rec: 0.1596, G/loss_cls: 0.7082\nElapsed [9:08:29], Iteration [17400/30000], Dataset [2], D/loss_real: -2.0311, D/loss_fake: -0.7037, D/loss_cls: 0.7832, D/loss_gp: 0.0418, G/loss_fake: 0.9374, G/loss_rec: 0.1294, G/loss_cls: 0.3172\nElapsed [9:08:30], Iteration [17400/30000], Dataset [3], D/loss_real: -1.5263, D/loss_fake: -0.4365, D/loss_cls: 0.0000, D/loss_gp: 0.0192, G/loss_fake: -0.0496, G/loss_rec: 0.0970, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009630, d_lr: 0.00009630.\nDecayed learning rates, g_lr: 0.00009630, d_lr: 0.00009630.\nDecayed learning rates, g_lr: 0.00009629, d_lr: 0.00009629.\nDecayed learning rates, g_lr: 0.00009629, d_lr: 0.00009629.\nDecayed learning rates, g_lr: 0.00009628, d_lr: 0.00009628.\nDecayed learning rates, g_lr: 0.00009628, d_lr: 0.00009628.\nDecayed learning rates, g_lr: 0.00009627, d_lr: 0.00009627.\nDecayed learning rates, g_lr: 0.00009627, d_lr: 0.00009627.\nDecayed learning rates, g_lr: 0.00009626, d_lr: 0.00009626.\nDecayed learning rates, g_lr: 0.00009626, d_lr: 0.00009626.\nElapsed [9:11:36], Iteration [17500/30000], Dataset [1], D/loss_real: -3.9386, D/loss_fake: 0.6446, D/loss_cls: 1.3942, D/loss_gp: 0.0195, G/loss_fake: -2.4281, G/loss_rec: 0.1708, G/loss_cls: 0.7858\nElapsed [9:11:38], Iteration [17500/30000], Dataset [2], D/loss_real: -7.2935, D/loss_fake: 4.9157, D/loss_cls: 0.5491, D/loss_gp: 0.0167, G/loss_fake: -4.5366, G/loss_rec: 0.1551, G/loss_cls: 0.2532\nElapsed [9:11:39], Iteration [17500/30000], Dataset [3], D/loss_real: -12.9892, D/loss_fake: 11.6852, D/loss_cls: 0.0000, D/loss_gp: 0.0292, G/loss_fake: -8.8945, G/loss_rec: 0.0958, G/loss_cls: 0.0003\nDecayed learning rates, g_lr: 0.00009625, d_lr: 0.00009625.\nDecayed learning rates, g_lr: 0.00009625, d_lr: 0.00009625.\nDecayed learning rates, g_lr: 0.00009624, d_lr: 0.00009624.\nDecayed learning rates, g_lr: 0.00009624, d_lr: 0.00009624.\nDecayed learning rates, g_lr: 0.00009623, d_lr: 0.00009623.\nDecayed learning rates, g_lr: 0.00009623, d_lr: 0.00009623.\nDecayed learning rates, g_lr: 0.00009622, d_lr: 0.00009622.\nDecayed learning rates, g_lr: 0.00009622, d_lr: 0.00009622.\nDecayed learning rates, g_lr: 0.00009621, d_lr: 0.00009621.\nDecayed learning rates, g_lr: 0.00009621, d_lr: 0.00009621.\nElapsed [9:14:45], Iteration [17600/30000], Dataset [1], D/loss_real: -3.2661, D/loss_fake: 0.8002, D/loss_cls: 1.0624, D/loss_gp: 0.0178, G/loss_fake: -1.4337, G/loss_rec: 0.1308, G/loss_cls: 0.7374\nElapsed [9:14:47], Iteration [17600/30000], Dataset [2], D/loss_real: -3.9400, D/loss_fake: 3.1158, D/loss_cls: 0.8748, D/loss_gp: 0.0174, G/loss_fake: -2.0326, G/loss_rec: 0.1287, G/loss_cls: 0.1964\nElapsed [9:14:48], Iteration [17600/30000], Dataset [3], D/loss_real: -2.6353, D/loss_fake: 1.9032, D/loss_cls: 0.0000, D/loss_gp: 0.0130, G/loss_fake: 0.2988, G/loss_rec: 0.0962, G/loss_cls: 0.0157\nDecayed learning rates, g_lr: 0.00009620, d_lr: 0.00009620.\nDecayed learning rates, g_lr: 0.00009620, d_lr: 0.00009620.\nDecayed learning rates, g_lr: 0.00009619, d_lr: 0.00009619.\nDecayed learning rates, g_lr: 0.00009619, d_lr: 0.00009619.\nDecayed learning rates, g_lr: 0.00009618, d_lr: 0.00009618.\nDecayed learning rates, g_lr: 0.00009618, d_lr: 0.00009618.\nDecayed learning rates, g_lr: 0.00009617, d_lr: 0.00009617.\nDecayed learning rates, g_lr: 0.00009617, d_lr: 0.00009617.\nDecayed learning rates, g_lr: 0.00009616, d_lr: 0.00009616.\nDecayed learning rates, g_lr: 0.00009616, d_lr: 0.00009616.\nElapsed [9:17:55], Iteration [17700/30000], Dataset [1], D/loss_real: -1.3284, D/loss_fake: -0.2441, D/loss_cls: 1.2718, D/loss_gp: 0.0223, G/loss_fake: -0.0292, G/loss_rec: 0.1373, G/loss_cls: 0.7452\nElapsed [9:17:56], Iteration [17700/30000], Dataset [2], D/loss_real: -2.4891, D/loss_fake: 0.8440, D/loss_cls: 0.7360, D/loss_gp: 0.0139, G/loss_fake: -0.5321, G/loss_rec: 0.1240, G/loss_cls: 0.1804\nElapsed [9:17:57], Iteration [17700/30000], Dataset [3], D/loss_real: -0.1652, D/loss_fake: -1.0735, D/loss_cls: 0.0001, D/loss_gp: 0.0125, G/loss_fake: 2.2087, G/loss_rec: 0.0959, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009615, d_lr: 0.00009615.\nDecayed learning rates, g_lr: 0.00009615, d_lr: 0.00009615.\nDecayed learning rates, g_lr: 0.00009614, d_lr: 0.00009614.\nDecayed learning rates, g_lr: 0.00009614, d_lr: 0.00009614.\nDecayed learning rates, g_lr: 0.00009613, d_lr: 0.00009613.\nDecayed learning rates, g_lr: 0.00009613, d_lr: 0.00009613.\nDecayed learning rates, g_lr: 0.00009612, d_lr: 0.00009612.\nDecayed learning rates, g_lr: 0.00009612, d_lr: 0.00009612.\nDecayed learning rates, g_lr: 0.00009611, d_lr: 0.00009611.\nDecayed learning rates, g_lr: 0.00009611, d_lr: 0.00009611.\nElapsed [9:21:04], Iteration [17800/30000], Dataset [1], D/loss_real: -3.3962, D/loss_fake: 1.8090, D/loss_cls: 1.3867, D/loss_gp: 0.0161, G/loss_fake: -1.7352, G/loss_rec: 0.1248, G/loss_cls: 0.9189\nElapsed [9:21:05], Iteration [17800/30000], Dataset [2], D/loss_real: -3.7086, D/loss_fake: 2.1773, D/loss_cls: 0.5881, D/loss_gp: 0.0175, G/loss_fake: -1.6128, G/loss_rec: 0.1188, G/loss_cls: 0.2889\nElapsed [9:21:06], Iteration [17800/30000], Dataset [3], D/loss_real: -4.6414, D/loss_fake: 3.3138, D/loss_cls: 0.0000, D/loss_gp: 0.0148, G/loss_fake: -2.0002, G/loss_rec: 0.0907, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009610, d_lr: 0.00009610.\nDecayed learning rates, g_lr: 0.00009610, d_lr: 0.00009610.\nDecayed learning rates, g_lr: 0.00009609, d_lr: 0.00009609.\nDecayed learning rates, g_lr: 0.00009609, d_lr: 0.00009609.\nDecayed learning rates, g_lr: 0.00009608, d_lr: 0.00009608.\nDecayed learning rates, g_lr: 0.00009608, d_lr: 0.00009608.\nDecayed learning rates, g_lr: 0.00009607, d_lr: 0.00009607.\nDecayed learning rates, g_lr: 0.00009607, d_lr: 0.00009607.\nDecayed learning rates, g_lr: 0.00009606, d_lr: 0.00009606.\nDecayed learning rates, g_lr: 0.00009606, d_lr: 0.00009606.\nElapsed [9:24:13], Iteration [17900/30000], Dataset [1], D/loss_real: -3.4914, D/loss_fake: 1.2232, D/loss_cls: 1.1933, D/loss_gp: 0.0138, G/loss_fake: -0.5035, G/loss_rec: 0.1427, G/loss_cls: 0.7378\nElapsed [9:24:14], Iteration [17900/30000], Dataset [2], D/loss_real: -2.8804, D/loss_fake: 1.0939, D/loss_cls: 0.7140, D/loss_gp: 0.0115, G/loss_fake: -0.4845, G/loss_rec: 0.1293, G/loss_cls: 0.3446\nElapsed [9:24:16], Iteration [17900/30000], Dataset [3], D/loss_real: -3.1372, D/loss_fake: 1.7494, D/loss_cls: 0.0000, D/loss_gp: 0.0124, G/loss_fake: -0.8475, G/loss_rec: 0.0884, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009605, d_lr: 0.00009605.\nDecayed learning rates, g_lr: 0.00009605, d_lr: 0.00009605.\nDecayed learning rates, g_lr: 0.00009604, d_lr: 0.00009604.\nDecayed learning rates, g_lr: 0.00009604, d_lr: 0.00009604.\nDecayed learning rates, g_lr: 0.00009603, d_lr: 0.00009603.\nDecayed learning rates, g_lr: 0.00009603, d_lr: 0.00009603.\nDecayed learning rates, g_lr: 0.00009602, d_lr: 0.00009602.\nDecayed learning rates, g_lr: 0.00009602, d_lr: 0.00009602.\nDecayed learning rates, g_lr: 0.00009601, d_lr: 0.00009601.\nDecayed learning rates, g_lr: 0.00009601, d_lr: 0.00009601.\nElapsed [9:27:22], Iteration [18000/30000], Dataset [1], D/loss_real: -2.9335, D/loss_fake: 0.4958, D/loss_cls: 0.9646, D/loss_gp: 0.0154, G/loss_fake: -0.0733, G/loss_rec: 0.1439, G/loss_cls: 0.8933\nElapsed [9:27:23], Iteration [18000/30000], Dataset [2], D/loss_real: -2.6348, D/loss_fake: 1.0566, D/loss_cls: 0.6288, D/loss_gp: 0.0104, G/loss_fake: -1.1250, G/loss_rec: 0.1237, G/loss_cls: 0.2855\nElapsed [9:27:25], Iteration [18000/30000], Dataset [3], D/loss_real: -4.7726, D/loss_fake: 3.5893, D/loss_cls: 0.0000, D/loss_gp: 0.0085, G/loss_fake: -3.4918, G/loss_rec: 0.0934, G/loss_cls: 0.0015\nSaved real and fake images into /kaggle/working/exps/visualization/18000...\nSaved model checkpoints at iteration 18000 into /kaggle/working/exps/checkpoints...\nDecayed learning rates, g_lr: 0.00009600, d_lr: 0.00009600.\nDecayed learning rates, g_lr: 0.00009600, d_lr: 0.00009600.\nDecayed learning rates, g_lr: 0.00009599, d_lr: 0.00009599.\nDecayed learning rates, g_lr: 0.00009599, d_lr: 0.00009599.\nDecayed learning rates, g_lr: 0.00009598, d_lr: 0.00009598.\nDecayed learning rates, g_lr: 0.00009598, d_lr: 0.00009598.\nDecayed learning rates, g_lr: 0.00009597, d_lr: 0.00009597.\nDecayed learning rates, g_lr: 0.00009597, d_lr: 0.00009597.\nDecayed learning rates, g_lr: 0.00009596, d_lr: 0.00009596.\nDecayed learning rates, g_lr: 0.00009596, d_lr: 0.00009596.\nElapsed [9:30:33], Iteration [18100/30000], Dataset [1], D/loss_real: -4.6340, D/loss_fake: 2.0060, D/loss_cls: 1.1966, D/loss_gp: 0.0094, G/loss_fake: -3.2568, G/loss_rec: 0.1642, G/loss_cls: 0.4475\nElapsed [9:30:34], Iteration [18100/30000], Dataset [2], D/loss_real: -8.0237, D/loss_fake: 5.8833, D/loss_cls: 0.8400, D/loss_gp: 0.0217, G/loss_fake: -6.1381, G/loss_rec: 0.1438, G/loss_cls: 0.2691\nElapsed [9:30:36], Iteration [18100/30000], Dataset [3], D/loss_real: -8.4815, D/loss_fake: 6.3309, D/loss_cls: 0.0017, D/loss_gp: 0.0331, G/loss_fake: -3.9813, G/loss_rec: 0.0902, G/loss_cls: 0.0004\nDecayed learning rates, g_lr: 0.00009595, d_lr: 0.00009595.\nDecayed learning rates, g_lr: 0.00009595, d_lr: 0.00009595.\nDecayed learning rates, g_lr: 0.00009594, d_lr: 0.00009594.\nDecayed learning rates, g_lr: 0.00009594, d_lr: 0.00009594.\nDecayed learning rates, g_lr: 0.00009593, d_lr: 0.00009593.\nDecayed learning rates, g_lr: 0.00009593, d_lr: 0.00009593.\nDecayed learning rates, g_lr: 0.00009592, d_lr: 0.00009592.\nDecayed learning rates, g_lr: 0.00009592, d_lr: 0.00009592.\nDecayed learning rates, g_lr: 0.00009591, d_lr: 0.00009591.\nDecayed learning rates, g_lr: 0.00009591, d_lr: 0.00009591.\nElapsed [9:33:42], Iteration [18200/30000], Dataset [1], D/loss_real: -0.5093, D/loss_fake: -2.9420, D/loss_cls: 1.3858, D/loss_gp: 0.0141, G/loss_fake: 3.2769, G/loss_rec: 0.1695, G/loss_cls: 0.7049\nElapsed [9:33:43], Iteration [18200/30000], Dataset [2], D/loss_real: -0.0399, D/loss_fake: -2.7693, D/loss_cls: 1.0280, D/loss_gp: 0.0256, G/loss_fake: 2.7952, G/loss_rec: 0.1354, G/loss_cls: 0.1465\nElapsed [9:33:45], Iteration [18200/30000], Dataset [3], D/loss_real: 4.2773, D/loss_fake: -4.9271, D/loss_cls: 0.0000, D/loss_gp: 0.0201, G/loss_fake: 5.3088, G/loss_rec: 0.0804, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009590, d_lr: 0.00009590.\nDecayed learning rates, g_lr: 0.00009590, d_lr: 0.00009590.\nDecayed learning rates, g_lr: 0.00009589, d_lr: 0.00009589.\nDecayed learning rates, g_lr: 0.00009589, d_lr: 0.00009589.\nDecayed learning rates, g_lr: 0.00009588, d_lr: 0.00009588.\nDecayed learning rates, g_lr: 0.00009588, d_lr: 0.00009588.\nDecayed learning rates, g_lr: 0.00009587, d_lr: 0.00009587.\nDecayed learning rates, g_lr: 0.00009587, d_lr: 0.00009587.\nDecayed learning rates, g_lr: 0.00009586, d_lr: 0.00009586.\nDecayed learning rates, g_lr: 0.00009586, d_lr: 0.00009586.\nElapsed [9:36:51], Iteration [18300/30000], Dataset [1], D/loss_real: -1.4352, D/loss_fake: -1.2245, D/loss_cls: 1.3659, D/loss_gp: 0.0153, G/loss_fake: -1.1664, G/loss_rec: 0.1536, G/loss_cls: 0.6604\nElapsed [9:36:52], Iteration [18300/30000], Dataset [2], D/loss_real: -4.0679, D/loss_fake: 2.0247, D/loss_cls: 0.9233, D/loss_gp: 0.0139, G/loss_fake: -2.2249, G/loss_rec: 0.1367, G/loss_cls: 0.3240\nElapsed [9:36:54], Iteration [18300/30000], Dataset [3], D/loss_real: -3.8910, D/loss_fake: 2.6201, D/loss_cls: 0.0007, D/loss_gp: 0.0189, G/loss_fake: -0.7294, G/loss_rec: 0.0913, G/loss_cls: 0.0479\nDecayed learning rates, g_lr: 0.00009585, d_lr: 0.00009585.\nDecayed learning rates, g_lr: 0.00009585, d_lr: 0.00009585.\nDecayed learning rates, g_lr: 0.00009584, d_lr: 0.00009584.\nDecayed learning rates, g_lr: 0.00009584, d_lr: 0.00009584.\nDecayed learning rates, g_lr: 0.00009583, d_lr: 0.00009583.\nDecayed learning rates, g_lr: 0.00009583, d_lr: 0.00009583.\nDecayed learning rates, g_lr: 0.00009582, d_lr: 0.00009582.\nDecayed learning rates, g_lr: 0.00009582, d_lr: 0.00009582.\nDecayed learning rates, g_lr: 0.00009581, d_lr: 0.00009581.\nDecayed learning rates, g_lr: 0.00009581, d_lr: 0.00009581.\nElapsed [9:40:00], Iteration [18400/30000], Dataset [1], D/loss_real: 1.1004, D/loss_fake: -2.7700, D/loss_cls: 1.0977, D/loss_gp: 0.0081, G/loss_fake: 2.1020, G/loss_rec: 0.1366, G/loss_cls: 0.7149\nElapsed [9:40:01], Iteration [18400/30000], Dataset [2], D/loss_real: 0.1965, D/loss_fake: -1.8130, D/loss_cls: 0.6984, D/loss_gp: 0.0120, G/loss_fake: 1.6228, G/loss_rec: 0.1219, G/loss_cls: 0.2580\nElapsed [9:40:03], Iteration [18400/30000], Dataset [3], D/loss_real: 2.6754, D/loss_fake: -3.5550, D/loss_cls: 0.0000, D/loss_gp: 0.0207, G/loss_fake: 2.7878, G/loss_rec: 0.0928, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009580, d_lr: 0.00009580.\nDecayed learning rates, g_lr: 0.00009580, d_lr: 0.00009580.\nDecayed learning rates, g_lr: 0.00009579, d_lr: 0.00009579.\nDecayed learning rates, g_lr: 0.00009579, d_lr: 0.00009579.\nDecayed learning rates, g_lr: 0.00009578, d_lr: 0.00009578.\nDecayed learning rates, g_lr: 0.00009578, d_lr: 0.00009578.\nDecayed learning rates, g_lr: 0.00009577, d_lr: 0.00009577.\nDecayed learning rates, g_lr: 0.00009577, d_lr: 0.00009577.\nDecayed learning rates, g_lr: 0.00009576, d_lr: 0.00009576.\nDecayed learning rates, g_lr: 0.00009576, d_lr: 0.00009576.\nElapsed [9:43:09], Iteration [18500/30000], Dataset [1], D/loss_real: -0.9370, D/loss_fake: -1.4518, D/loss_cls: 1.1662, D/loss_gp: 0.0216, G/loss_fake: 0.5277, G/loss_rec: 0.1375, G/loss_cls: 0.6608\nElapsed [9:43:10], Iteration [18500/30000], Dataset [2], D/loss_real: -3.0289, D/loss_fake: 1.2431, D/loss_cls: 0.5230, D/loss_gp: 0.0154, G/loss_fake: -1.4202, G/loss_rec: 0.1315, G/loss_cls: 0.3507\nElapsed [9:43:12], Iteration [18500/30000], Dataset [3], D/loss_real: -3.1849, D/loss_fake: 2.7652, D/loss_cls: 0.0000, D/loss_gp: 0.0067, G/loss_fake: -2.3986, G/loss_rec: 0.0857, G/loss_cls: 0.0007\nDecayed learning rates, g_lr: 0.00009575, d_lr: 0.00009575.\nDecayed learning rates, g_lr: 0.00009575, d_lr: 0.00009575.\nDecayed learning rates, g_lr: 0.00009574, d_lr: 0.00009574.\nDecayed learning rates, g_lr: 0.00009574, d_lr: 0.00009574.\nDecayed learning rates, g_lr: 0.00009573, d_lr: 0.00009573.\nDecayed learning rates, g_lr: 0.00009573, d_lr: 0.00009573.\nDecayed learning rates, g_lr: 0.00009572, d_lr: 0.00009572.\nDecayed learning rates, g_lr: 0.00009572, d_lr: 0.00009572.\nDecayed learning rates, g_lr: 0.00009571, d_lr: 0.00009571.\nDecayed learning rates, g_lr: 0.00009571, d_lr: 0.00009571.\nElapsed [9:46:18], Iteration [18600/30000], Dataset [1], D/loss_real: -1.9871, D/loss_fake: -1.5225, D/loss_cls: 1.2174, D/loss_gp: 0.0156, G/loss_fake: 0.3421, G/loss_rec: 0.1530, G/loss_cls: 0.8545\nElapsed [9:46:19], Iteration [18600/30000], Dataset [2], D/loss_real: -2.8754, D/loss_fake: 0.8498, D/loss_cls: 0.7916, D/loss_gp: 0.0303, G/loss_fake: -0.1749, G/loss_rec: 0.1240, G/loss_cls: 0.2518\nElapsed [9:46:21], Iteration [18600/30000], Dataset [3], D/loss_real: -0.1255, D/loss_fake: -1.0146, D/loss_cls: 0.0000, D/loss_gp: 0.0435, G/loss_fake: 1.1378, G/loss_rec: 0.0852, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009570, d_lr: 0.00009570.\nDecayed learning rates, g_lr: 0.00009570, d_lr: 0.00009570.\nDecayed learning rates, g_lr: 0.00009569, d_lr: 0.00009569.\nDecayed learning rates, g_lr: 0.00009569, d_lr: 0.00009569.\nDecayed learning rates, g_lr: 0.00009568, d_lr: 0.00009568.\nDecayed learning rates, g_lr: 0.00009568, d_lr: 0.00009568.\nDecayed learning rates, g_lr: 0.00009567, d_lr: 0.00009567.\nDecayed learning rates, g_lr: 0.00009567, d_lr: 0.00009567.\nDecayed learning rates, g_lr: 0.00009566, d_lr: 0.00009566.\nDecayed learning rates, g_lr: 0.00009566, d_lr: 0.00009566.\nElapsed [9:49:27], Iteration [18700/30000], Dataset [1], D/loss_real: -5.7178, D/loss_fake: 1.3928, D/loss_cls: 1.7502, D/loss_gp: 0.0558, G/loss_fake: 1.0836, G/loss_rec: 0.1722, G/loss_cls: 0.7535\nElapsed [9:49:28], Iteration [18700/30000], Dataset [2], D/loss_real: -4.0162, D/loss_fake: 0.8855, D/loss_cls: 1.7474, D/loss_gp: 0.0359, G/loss_fake: 0.5766, G/loss_rec: 0.1453, G/loss_cls: 0.3317\nElapsed [9:49:30], Iteration [18700/30000], Dataset [3], D/loss_real: 0.9457, D/loss_fake: -2.0187, D/loss_cls: 0.0000, D/loss_gp: 0.0063, G/loss_fake: 2.7404, G/loss_rec: 0.0900, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009565, d_lr: 0.00009565.\nDecayed learning rates, g_lr: 0.00009565, d_lr: 0.00009565.\nDecayed learning rates, g_lr: 0.00009564, d_lr: 0.00009564.\nDecayed learning rates, g_lr: 0.00009564, d_lr: 0.00009564.\nDecayed learning rates, g_lr: 0.00009563, d_lr: 0.00009563.\nDecayed learning rates, g_lr: 0.00009563, d_lr: 0.00009563.\nDecayed learning rates, g_lr: 0.00009562, d_lr: 0.00009562.\nDecayed learning rates, g_lr: 0.00009562, d_lr: 0.00009562.\nDecayed learning rates, g_lr: 0.00009561, d_lr: 0.00009561.\nDecayed learning rates, g_lr: 0.00009561, d_lr: 0.00009561.\nElapsed [9:52:36], Iteration [18800/30000], Dataset [1], D/loss_real: -2.6470, D/loss_fake: 0.4429, D/loss_cls: 1.3647, D/loss_gp: 0.0249, G/loss_fake: -0.8533, G/loss_rec: 0.1364, G/loss_cls: 0.6901\nElapsed [9:52:37], Iteration [18800/30000], Dataset [2], D/loss_real: -3.8542, D/loss_fake: 2.2571, D/loss_cls: 0.6199, D/loss_gp: 0.0137, G/loss_fake: -1.8386, G/loss_rec: 0.1252, G/loss_cls: 0.3292\nElapsed [9:52:38], Iteration [18800/30000], Dataset [3], D/loss_real: -7.2080, D/loss_fake: 6.0956, D/loss_cls: 0.0000, D/loss_gp: 0.0118, G/loss_fake: -5.6889, G/loss_rec: 0.0899, G/loss_cls: 0.0506\nDecayed learning rates, g_lr: 0.00009560, d_lr: 0.00009560.\nDecayed learning rates, g_lr: 0.00009560, d_lr: 0.00009560.\nDecayed learning rates, g_lr: 0.00009559, d_lr: 0.00009559.\nDecayed learning rates, g_lr: 0.00009559, d_lr: 0.00009559.\nDecayed learning rates, g_lr: 0.00009558, d_lr: 0.00009558.\nDecayed learning rates, g_lr: 0.00009558, d_lr: 0.00009558.\nDecayed learning rates, g_lr: 0.00009557, d_lr: 0.00009557.\nDecayed learning rates, g_lr: 0.00009557, d_lr: 0.00009557.\nDecayed learning rates, g_lr: 0.00009556, d_lr: 0.00009556.\nDecayed learning rates, g_lr: 0.00009556, d_lr: 0.00009556.\nElapsed [9:55:45], Iteration [18900/30000], Dataset [1], D/loss_real: -4.4106, D/loss_fake: 1.8293, D/loss_cls: 1.3497, D/loss_gp: 0.0087, G/loss_fake: -2.0292, G/loss_rec: 0.1367, G/loss_cls: 0.8027\nElapsed [9:55:46], Iteration [18900/30000], Dataset [2], D/loss_real: -4.9247, D/loss_fake: 3.3090, D/loss_cls: 0.6993, D/loss_gp: 0.0177, G/loss_fake: -2.5281, G/loss_rec: 0.1150, G/loss_cls: 0.2267\nElapsed [9:55:47], Iteration [18900/30000], Dataset [3], D/loss_real: -6.7355, D/loss_fake: 5.8304, D/loss_cls: 0.0000, D/loss_gp: 0.0248, G/loss_fake: -3.5030, G/loss_rec: 0.0855, G/loss_cls: 0.0002\nDecayed learning rates, g_lr: 0.00009555, d_lr: 0.00009555.\nDecayed learning rates, g_lr: 0.00009555, d_lr: 0.00009555.\nDecayed learning rates, g_lr: 0.00009554, d_lr: 0.00009554.\nDecayed learning rates, g_lr: 0.00009554, d_lr: 0.00009554.\nDecayed learning rates, g_lr: 0.00009553, d_lr: 0.00009553.\nDecayed learning rates, g_lr: 0.00009553, d_lr: 0.00009553.\nDecayed learning rates, g_lr: 0.00009552, d_lr: 0.00009552.\nDecayed learning rates, g_lr: 0.00009552, d_lr: 0.00009552.\nDecayed learning rates, g_lr: 0.00009551, d_lr: 0.00009551.\nDecayed learning rates, g_lr: 0.00009551, d_lr: 0.00009551.\nElapsed [9:58:54], Iteration [19000/30000], Dataset [1], D/loss_real: -4.0159, D/loss_fake: 2.0814, D/loss_cls: 1.3336, D/loss_gp: 0.0085, G/loss_fake: -2.2337, G/loss_rec: 0.1380, G/loss_cls: 0.8288\nElapsed [9:58:55], Iteration [19000/30000], Dataset [2], D/loss_real: -4.1604, D/loss_fake: 2.5809, D/loss_cls: 0.7227, D/loss_gp: 0.0116, G/loss_fake: -1.9563, G/loss_rec: 0.1177, G/loss_cls: 0.2062\nElapsed [9:58:57], Iteration [19000/30000], Dataset [3], D/loss_real: -2.7652, D/loss_fake: 0.9826, D/loss_cls: 0.0000, D/loss_gp: 0.0115, G/loss_fake: 0.4372, G/loss_rec: 0.0887, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009550, d_lr: 0.00009550.\nDecayed learning rates, g_lr: 0.00009550, d_lr: 0.00009550.\nDecayed learning rates, g_lr: 0.00009549, d_lr: 0.00009549.\nDecayed learning rates, g_lr: 0.00009549, d_lr: 0.00009549.\nDecayed learning rates, g_lr: 0.00009548, d_lr: 0.00009548.\nDecayed learning rates, g_lr: 0.00009548, d_lr: 0.00009548.\nDecayed learning rates, g_lr: 0.00009547, d_lr: 0.00009547.\nDecayed learning rates, g_lr: 0.00009547, d_lr: 0.00009547.\nDecayed learning rates, g_lr: 0.00009546, d_lr: 0.00009546.\nDecayed learning rates, g_lr: 0.00009546, d_lr: 0.00009546.\nElapsed [10:02:03], Iteration [19100/30000], Dataset [1], D/loss_real: -0.3876, D/loss_fake: -1.5916, D/loss_cls: 0.9649, D/loss_gp: 0.0158, G/loss_fake: 0.6263, G/loss_rec: 0.1505, G/loss_cls: 0.7866\nElapsed [10:02:04], Iteration [19100/30000], Dataset [2], D/loss_real: -2.0328, D/loss_fake: 0.3966, D/loss_cls: 0.6535, D/loss_gp: 0.0102, G/loss_fake: -0.5563, G/loss_rec: 0.1206, G/loss_cls: 0.1998\nElapsed [10:02:06], Iteration [19100/30000], Dataset [3], D/loss_real: -1.1558, D/loss_fake: -1.0070, D/loss_cls: 0.0001, D/loss_gp: 0.0178, G/loss_fake: 1.9023, G/loss_rec: 0.0852, G/loss_cls: 0.0004\nDecayed learning rates, g_lr: 0.00009545, d_lr: 0.00009545.\nDecayed learning rates, g_lr: 0.00009545, d_lr: 0.00009545.\nDecayed learning rates, g_lr: 0.00009544, d_lr: 0.00009544.\nDecayed learning rates, g_lr: 0.00009544, d_lr: 0.00009544.\nDecayed learning rates, g_lr: 0.00009543, d_lr: 0.00009543.\nDecayed learning rates, g_lr: 0.00009543, d_lr: 0.00009543.\nDecayed learning rates, g_lr: 0.00009542, d_lr: 0.00009542.\nDecayed learning rates, g_lr: 0.00009542, d_lr: 0.00009542.\nDecayed learning rates, g_lr: 0.00009541, d_lr: 0.00009541.\nDecayed learning rates, g_lr: 0.00009541, d_lr: 0.00009541.\nElapsed [10:05:12], Iteration [19200/30000], Dataset [1], D/loss_real: -5.0252, D/loss_fake: 2.5301, D/loss_cls: 1.1540, D/loss_gp: 0.0126, G/loss_fake: -3.8183, G/loss_rec: 0.1388, G/loss_cls: 0.7241\nElapsed [10:05:13], Iteration [19200/30000], Dataset [2], D/loss_real: -6.1850, D/loss_fake: 5.2257, D/loss_cls: 0.6241, D/loss_gp: 0.0194, G/loss_fake: -4.8857, G/loss_rec: 0.1300, G/loss_cls: 0.1776\nElapsed [10:05:15], Iteration [19200/30000], Dataset [3], D/loss_real: -5.3921, D/loss_fake: 5.0979, D/loss_cls: 0.0263, D/loss_gp: 0.0099, G/loss_fake: -4.2052, G/loss_rec: 0.1052, G/loss_cls: 0.0000\nDecayed learning rates, g_lr: 0.00009540, d_lr: 0.00009540.\nDecayed learning rates, g_lr: 0.00009540, d_lr: 0.00009540.\nDecayed learning rates, g_lr: 0.00009539, d_lr: 0.00009539.\nDecayed learning rates, g_lr: 0.00009539, d_lr: 0.00009539.\nDecayed learning rates, g_lr: 0.00009538, d_lr: 0.00009538.\nDecayed learning rates, g_lr: 0.00009538, d_lr: 0.00009538.\nDecayed learning rates, g_lr: 0.00009537, d_lr: 0.00009537.\nDecayed learning rates, g_lr: 0.00009537, d_lr: 0.00009537.\nDecayed learning rates, g_lr: 0.00009536, d_lr: 0.00009536.\nDecayed learning rates, g_lr: 0.00009536, d_lr: 0.00009536.\nElapsed [10:08:21], Iteration [19300/30000], Dataset [1], D/loss_real: -2.5667, D/loss_fake: 0.7860, D/loss_cls: 1.1263, D/loss_gp: 0.0138, G/loss_fake: -0.3422, G/loss_rec: 0.1416, G/loss_cls: 0.6625\nElapsed [10:08:22], Iteration [19300/30000], Dataset [2], D/loss_real: -2.5122, D/loss_fake: 0.9122, D/loss_cls: 0.6606, D/loss_gp: 0.0081, G/loss_fake: -0.4485, G/loss_rec: 0.1338, G/loss_cls: 0.4141\nElapsed [10:08:24], Iteration [19300/30000], Dataset [3], D/loss_real: -5.2240, D/loss_fake: 4.1781, D/loss_cls: -0.0000, D/loss_gp: 0.0533, G/loss_fake: -2.5145, G/loss_rec: 0.0933, G/loss_cls: 0.0001\nDecayed learning rates, g_lr: 0.00009535, d_lr: 0.00009535.\nDecayed learning rates, g_lr: 0.00009535, d_lr: 0.00009535.\nDecayed learning rates, g_lr: 0.00009534, d_lr: 0.00009534.\nDecayed learning rates, g_lr: 0.00009534, d_lr: 0.00009534.\nDecayed learning rates, g_lr: 0.00009533, d_lr: 0.00009533.\nDecayed learning rates, g_lr: 0.00009533, d_lr: 0.00009533.\nDecayed learning rates, g_lr: 0.00009532, d_lr: 0.00009532.\nDecayed learning rates, g_lr: 0.00009532, d_lr: 0.00009532.\nDecayed learning rates, g_lr: 0.00009531, d_lr: 0.00009531.\nDecayed learning rates, g_lr: 0.00009531, d_lr: 0.00009531.\nElapsed [10:11:30], Iteration [19400/30000], Dataset [1], D/loss_real: -3.7722, D/loss_fake: 1.8963, D/loss_cls: 1.1352, D/loss_gp: 0.0117, G/loss_fake: -2.3346, G/loss_rec: 0.1261, G/loss_cls: 0.6088\nElapsed [10:11:31], Iteration [19400/30000], Dataset [2], D/loss_real: -4.8782, D/loss_fake: 3.7701, D/loss_cls: 0.7805, D/loss_gp: 0.0171, G/loss_fake: -2.6174, G/loss_rec: 0.1195, G/loss_cls: 0.2226\nElapsed [10:11:33], Iteration [19400/30000], Dataset [3], D/loss_real: -1.9323, D/loss_fake: 1.0096, D/loss_cls: 0.0001, D/loss_gp: 0.0071, G/loss_fake: -0.2934, G/loss_rec: 0.0855, G/loss_cls: 0.0097\nDecayed learning rates, g_lr: 0.00009530, d_lr: 0.00009530.\nDecayed learning rates, g_lr: 0.00009530, d_lr: 0.00009530.\nDecayed learning rates, g_lr: 0.00009529, d_lr: 0.00009529.\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r checkpoints20k_3dataset.zip /kaggle/working/exps/checkpoints/20000-G.ckpt /kaggle/working/exps/checkpoints/20000-D.ckpt\n","metadata":{"id":"52gU98vNQ0Hf","outputId":"2d470265-b876-4ba3-c191-b87312a4ef26","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r visual20k_3dataset.zip /kaggle/working/exps/visualization","metadata":{"id":"kbYiGeD9vGP7"},"execution_count":null,"outputs":[]}]}