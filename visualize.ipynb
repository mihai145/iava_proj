{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177119f3-03be-47a3-99cf-fd557a7c1f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mihai145/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from generic_dataset import GenericDataset, VisualizationDataset, CELEBA_FORMAT_DATASET, RAFD_FORMAT_DATASET, get_loader\n",
    "from custom_solver import CustomSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ade9c83d-fab1-47cb-8e73-24b517454f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from pathlib import Path\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e79b89a-8c62-4bbf-a13d-e9e265266faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_selected_attrs1 = [\"Male\", \"Young\", \"Black_Hair\", \"Blond_Hair\", \"Brown_Hair\"]\n",
    "celeba_selected_attrs2 = [\"Smiling\", \"Arched_Eyebrows\", \"Bangs\"]\n",
    "selected_attrs = celeba_selected_attrs1 + celeba_selected_attrs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afa6f9c-1da7-4940-a36c-57907fde5385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing CelebA-format dataset at data/celeba: 198548 train images, 4051 test images\n"
     ]
    }
   ],
   "source": [
    "vis_celeba = GenericDataset(\"data/celeba\", CELEBA_FORMAT_DATASET, selected_attrs, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e55e5b95-f586-4382-b7fe-a2215fbe89ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing CelebA-format dataset at data/celeba: 198548 train images, 4051 test images\n",
      "Finished preprocessing CelebA-format dataset at data/celeba: 198548 train images, 4051 test images\n",
      "Finished preprocessing RAFD-format dataset at data/comics: 0 train images, 0 test images\n",
      "sum_label_size: 10, mask_vector_size: 3\n",
      "Zero padding left: [0, 5, 8]\n",
      "Zero padding right: [5, 2, 0]\n",
      "Workdir set at 75k\n",
      "Generator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(16, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (10): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (11): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (12): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (13): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (14): ResidualBlock(\n",
      "      (main): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (22): Tanh()\n",
      "  )\n",
      ")\n",
      "G\n",
      "The number of parameters: 8455616\n",
      "Discriminator(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (11): LeakyReLU(negative_slope=0.01)\n",
      "  )\n",
      "  (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(2048, 10, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
      ")\n",
      "D\n",
      "The number of parameters: 44803008\n"
     ]
    }
   ],
   "source": [
    "# Build solver\n",
    "celeba1 = GenericDataset(\"data/celeba\", CELEBA_FORMAT_DATASET, celeba_selected_attrs1, \"train\")\n",
    "celeba2 = GenericDataset(\"data/celeba\", CELEBA_FORMAT_DATASET, celeba_selected_attrs2, \"train\")\n",
    "comics = GenericDataset(\"data/comics\", RAFD_FORMAT_DATASET, [\"faces\", \"comics\"], \"train\")\n",
    "visualization_ds = VisualizationDataset(\"data/visualization\")\n",
    "\n",
    "solver = CustomSolver([celeba1, celeba2, comics], visualization_ds, \"75k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a9713b-0719-4c2b-8c52-83afe09dd270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(solver, restore_iters, dataset, save_dir, toggle=False):\n",
    "    solver.restore_model(restore_iters)\n",
    "    \n",
    "    save_dir = Path(save135e38ce020d2314b840dc62463b085d0aeecb48_dir)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    d1, outside_d1 = [0, 1, 2, 3, 4], [5, 6, 7, 8, 9]\n",
    "    d2, outside_d2 = [5, 6, 7], [0, 1, 2, 3, 4, 8, 9]\n",
    "    d3, outside_d3 = [9], [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    \n",
    "    dataloader = get_loader(dataset, 6, \"test\", num_workers=2)\n",
    "    with torch.no_grad():\n",
    "        for j, (x, label) in enumerate(dataloader):\n",
    "            x = x.to(solver.device)\n",
    "            x_fake_list = [x]\n",
    "\n",
    "            for b in range(0, 9+1):\n",
    "                if b == 8:     # skip dataset 3 \"faces\"\n",
    "                    continue\n",
    "\n",
    "                # clone original label\n",
    "                target = label.clone()\n",
    "                target = torch.cat([target, torch.zeros(label.size(0), 5)], dim=1)\n",
    "                \n",
    "                # clean vector mask\n",
    "                target[:, 10] = 0\n",
    "                target[:, 11] = 0\n",
    "                target[:, 12] = 0\n",
    "\n",
    "                # clean hair colors\n",
    "                if b in [2, 3, 4]:\n",
    "                    target[:, 2] = 0\n",
    "                    target[:, 3] = 0\n",
    "                    target[:, 4] = 0\n",
    "\n",
    "                # clean unknown attributes\n",
    "                if b in d1:\n",
    "                    target[:, 10] = 1\n",
    "                    for bb in outside_d1:\n",
    "                        target[:, bb] = 0\n",
    "                elif b in d2:\n",
    "                    target[:, 11] = 1\n",
    "                    for bb in outside_d2:\n",
    "                        target[:, bb] = 0\n",
    "                else:\n",
    "                    target[:, 12] = 1\n",
    "                    for bb in outside_d3:\n",
    "                        target[:, bb] = 0\n",
    "\n",
    "                # set target attribute on\n",
    "                if not toggle:\n",
    "                    target[:, b] = 1\n",
    "                else:\n",
    "                    for bs in range(label.size(0)):\n",
    "                        target[bs, b] = 1 - target[bs, b]\n",
    "\n",
    "                x_fake_list.append(solver.G(x, target))\n",
    "            \n",
    "            x_concat = torch.cat(x_fake_list, dim=3)\n",
    "            vis_path = save_dir / f'{j+1}.jpg'\n",
    "            save_image(solver.denorm(x_concat.data.cpu()), vis_path, nrow=1, padding=0)\n",
    "\n",
    "            # generate at most 100 images\n",
    "            if j >= 100:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef3a4b3b-ec0f-4501-9c92-12e8ce52c6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 75000...\n"
     ]
    }
   ],
   "source": [
    "visualize(solver, 75000, vis_celeba, \"save_vis_nontoggle\", toggle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4429f40d-66c3-4c5b-b57f-7272344c1ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 75000...\n"
     ]
    }
   ],
   "source": [
    "visualize(solver, 75000, vis_celeba, \"save_vis_toggle\", toggle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1410d8f-ec6b-4db2-909c-6323b6e028e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preprocessing CelebA-format dataset at data/authors: 12 train images, 0 test images\n"
     ]
    }
   ],
   "source": [
    "authors = GenericDataset(\"data/authors\", CELEBA_FORMAT_DATASET, selected_attrs, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eff8bcf-c857-400a-810f-bf8729112151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 75000...\n"
     ]
    }
   ],
   "source": [
    "visualize(solver, 75000, authors, \"authors_nontoggle\", toggle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c15fb23a-2b7d-4f2f-b022-1f9182b2c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained models from step 75000...\n"
     ]
    }
   ],
   "source": [
    "visualize(solver, 75000, authors, \"authors_toggle\", toggle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bf7f2f-c666-446f-b5b9-038114dd4759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33b50d5-4ced-4d31-b742-39c35ea58c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1849af-b883-47b5-b4cf-546a04ee4270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb588117-258c-4c4a-9214-a01eb9bb7296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
